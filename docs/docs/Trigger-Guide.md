**NOTICE:** This software (or technical data) was produced for the U.S. Government under contract,
and is subject to the Rights in Data-General Clause 52.227-14, Alt. IV (DEC 2007). Copyright 2023
The MITRE Corporation. All Rights Reserved.


# Trigger Overview

The `TRIGGER` property enables pipelines that use [feed forward](Feed-Forward-Guide) to have
pipeline stages that only process certain tracks based on their track properties. It can be used
to select the best algorithm when there are multiple similar algorithms that each perform better
under certain circumstances. It can also be used to iteratively filter down tracks at each stage of
a pipeline.


# Syntax

The syntax for the `TRIGGER` property is: `<prop_name>=<prop_value1>[;<prop_value2>...]`.
The left hand side of the equals sign is the name of track property that will be used to determine
if a track matches the trigger. The right hand side specifies the required value for the specified
track property. More than one value can be specified by separating them with a semicolon. When
multiple properties are specified the track property must match any one of the specified values.
If the value should match a track property that contains a semicolon or backslash,
they must be escaped with a leading backslash. For example, `CLASSIFICATION=dog;cat` will match
"dog" or "cat". `CLASSIFICATION=dog\;cat` will match "dog;cat". `CLASSIFICATION=dog\\cat` will
match "dog\cat". When specifying a trigger in JSON it will need to [doubly escaped](#json-escaping).


# Multiple Flows Using Triggers

To describe the way that the Workflow Manager applies the trigger, we will use the example pipeline
defined below. Note that this is a hypothetical pipeline and not tested in a real deployment:

1. WHISPER SPEECH LANGUAGE DETECTION ACTION
    - (No TRIGGER)
2. SPHINX SPEECH DETECTION ACTION
    - TRIGGER: `ISO_LANGUAGE=eng`
3. WHISPER SPEECH DETECTION ACTION
    - TRIGGER: `ISO_LANGUAGE=spa`
4. ARGOS TRANSLATION (WITH FF REGION) ACTION
    - TRIGGER: `ISO_LANGUAGE=spa`
5. KEYWORD TAGGING (WITH FF REGION) ACTION
    - (No TRIGGER)

We can represent this as a flow chart:

![Triggers Dynamic Speech Full Diagram](img/triggers-dynamic-speech-full.png "Triggers Dynamic Speech Full Diagram")

The goal of this pipeline is to determine if someone in an audio file, or the audio of a video file,
says a keyword we're interested in. The complication is that the input file could either be in
English, Spanish, or another language we're not interested in. Spanish audio must be translated to
English before looking for keywords. We want to use Sphinx for decoding English audio (because we're
pretending that Sphinx performs better than Whisper on English audio for this example) and Whisper
for decoding Spanish audio.

Execution flows from top to bottom, starting with stage 1, the 
`WHISPER SPEECH LANGUAGE DETECTION ACTION`. The first stage should not have a trigger condition. If
one is set, it will be ignored.

The Workflow Manager will take all of the tracks generated by stage 1 and determine if the trigger
condition for stage 2 is met. This trigger condition is shown by the topmost orange diamond. In this
case, if stage 1 detected the language as `eng` (English), then those tracks are fed into the second
stage. This is shown by the green arrow pointing to the stage 2 box. Specifically, those tracks will
have an `ISO_LANGUAGE` track property with the value `eng`.

If any of the Whisper tracks do not meet this condition for the stage 2, they are later considered
as possible inputs to stage 3. This is shown by the red arrow coming out of the stage 2 trigger
diamond pointing down to the stage 3 trigger diamond.

The Workflow Manager will take all of the tracks generated by stage 2, the
`SPHINX SPEECH DETECTION ACTION`, as well as the tracks that didn't satisfy the stage 2 trigger, and
determine if the trigger condition for stage 3 is met.

Note that the Sphinx component does not generate tracks with the `ISO_LANGUAGE` property, so
it's not possible for tracks coming out of stage 2 to satisfy the stage 3 trigger. They will later
flow down to the stage 4 trigger, and because it has the same condition as the stage 3 trigger, the
Sphinx tracks cannot satisfy that trigger either. 

Even if the Sphinx component did generate tracks with the `ISO_LANGUAGE` property, it would be set
to `eng` and would not satisfy the `spa` condition (they are mutually exclusive). Either way,
eventually the tracks from stage 2 will flow into stage 5.

The Workflow Manager will take all of the tracks generated by stage 3, the
`WHISPER SPEECH DETECTION ACTION`, as well as the tracks that didn't satisfy the stage 3 trigger,
and determine if the trigger condition for stage 4 is met. Tracks generated by stage 3 retain the
`ISO_LANGUAGE` property from the tracks fed into that stage due to how the Whisper component works,
so it's guaranteed that all tracks that satisfy the stage 3 trigger will also satisfy the stage 4
trigger.

The Workflow Manager will take all of the tracks generated by stage 4, the 
`ARGOS TRANSLATION (WITH FF REGION) ACTION`, as well as the tracks that didn't satisfy the stage 4
trigger, and determine if the trigger condition for stage 5 is met. Stage 5 has no trigger
condition, so all of those tracks flow into stage 5 by default.

The above diagram can be simplified as follows:

![Triggers Dynamic Speech Simple Diagram](img/triggers-dynamic-speech-simple.png "Triggers Dynamic Speech Simple Diagram")

In this diagram we removed the trigger diamonds and replaced them with the orange boxes at the top
of each stage. Also, we removed all of the arrows for flows that aren't logically possible, leaving
only arrows that flow from one stage to another.

What remains shows that this pipeline has three main flows of execution:

1. `eng` audio is decoded by the Sphinx component and then processed by keyword tagging.
2. `spa` audio is decoded by the Whisper component, translated by the Argos component, and then
   processed by keyword tagging.
3. All other languages are not decoded and those tracks pass directly to keyword tagging. Since
   there is no transcript to look at, keyword tagging essentially ignores them.


## Further Understanding

In general, triggers work as a mechanism to decide which tracks are passed forward to later stages
of a pipeline. It's important to note that not only are the tracks from the previous stage
considered, but also tracks from stages that were not fed into the previous stage.

For example, if only the Sphinx tracks from stage 2 were passed to Whisper stage 3, then stage 3
would never be triggered. This is because Sphinx tracks don't have an `ISO_LANGUAGE` property. Even
if they did have that property, it would be set to `eng`, not `spa`, which would not satisfy the
stage 3 trigger. This is mutual exclusion is by design. Both stages perform speech-to-text. Tracks
from stage 1 should only be processed by one speech-to-text algorithm (a.k.a. one `SPEECH DETECTION`
stage). Both algorithms should be considered, but only one should be selected based on the language.
To accomplish this, tracks from stage 1 that don't trigger stage 2 are considered as possible inputs
to stage 3.

Additionally, it's important to note that when a stage is triggered, the tracks passed into that
stage are no longer considered for later stages. Instead, the tracks generated by that stage can be
passed to later stages.

For example, the Argos algorithm in stage 4 should only accept tracks with Spanish transcripts. If
all of the tracks generated in prior stages could be passed to stage 4, then the `spa` tracks
generated in stage 1 would trigger stage 4. Since those have not passed through the Whisper
speech-to-text stage 3 they would not have a transcript to translate.


# Filtering Using Triggers

The pipeline in the previous section shows an example of how triggers can be used to conditionally
execute or skip stages in a pipeline. Triggers can also be useful when all stages get triggered. In
cases like that, the individual triggers are logically `AND`ed together. This allows you to produce
pipelines that search for very specific things.

Consider the example pipeline defined below. Again, note that this is a hypothetical pipeline and
not tested in a real deployment:

1. OCV YOLO OBJECT DETECTION ACTION
    - (No TRIGGER)
2. CAFFE GOOGLENET DETECTION ACTION
    - TRIGGER: `CLASSIFICATION=truck`
    - FEED_FORWARD_TYPE: `REGION`
3. TENSORFLOW VEHICLE COLOR DETECTION ACTION
    - TRIGGER: `CLASSIFICATION=ice cream, icecream;ice lolly, lolly, lollipop, popsicle`
    - FEED_FORWARD_TYPE: `REGION`
4. OALPR LICENSE PLATE TEXT DETECTION ACTION
    - TRIGGER: `CLASSIFICATION=blue`
    - FEED_FORWARD_TYPE: `REGION`

We can represent this as a flow chart:

![Triggers YOLO Full Diagram](img/triggers-yolo-full.png "Triggers YOLO Full Diagram")

The goal of this pipeline is to extract the license plate numbers for all blue trucks that have
photos of ice cream or popsicles on their exterior.

Note that stage 2 and 3 don't generate new detection regions due to how those components work.
Instead, they generate tracks using the same detection regions in the feed-forward tracks.
Specifically, if YOLO generates `truck` tracks in stage 1, then those tracks will be fed into stage
2. In that stage, GoogLeNet will process the truck region to determine the ImageNet class with the
highest confidence. If that class corresponds to ice cream or popsicle, those tracks will be fed
into stage 3, which will operate on the same truck region to determine the vehicle color. Tracks
corresponding to `blue` trucks will be fed into stage 4, which will try to detect the license plate
region and text. OALPR will operate on the same truck region passed forward all of the way from YOLO
in stage 1.

Tracks generated by any stage in the pipeline that don't meet the three trigger criteria do not
flow into the final license plate detection stage, and are therefore unused.

It's important to note that the possible `CLASSIFICATION` values generated by stages 1, 2, and 3 are
mutually exclusive. This means, for example, that YOLO will not generate a `blue` track in stage 1
that will later satisfy the trigger for stage 4.

Also, note that stages 1, 2, and 3 can all accept an optional `WHITELIST_FILE` property that can be
used to discard tracks with a `CLASSIFICATION` not listed in that file. It's possible to recreate
the behavior of the above pipeline without using triggers and instead only using whitelist files to
ensure each of those stages can only generate the track types we're interested in. The disadvantage
of the whitelist approach is that the final JSON output object will not contain all of the YOLO
tracks, only `truck` tracks. Maybe we want to know about those other track types, or maybe we want
to create a version of this pipeline where `person` tracks from YOLO are fed into OpenCV face
detection. `person` is just an example of one other type of YOLO track we might be interested in.


The above diagram can be simplified as follows:

![Triggers YOLO Simple Diagram](img/triggers-yolo-simple.png "Triggers YOLO Simple Diagram")

Removing all of the flows that aren't logically possible, or result in unused tracks, only
leaves one flow that passes through all of the stages. Again, this flow essentially `AND`s the
trigger conditions together.


# JSON escaping

Many times job properties are defined using JSON and track properties appear in the JSON output
object. JSON also uses backslash as its escape character. Since the `TRIGGER` property and JSON both
use backslash as the escape character, when specifying the `TRIGGER` property in JSON, the string
must be doubly escaped.

If the job request contains this JSON fragment:
```json
{ "algorithmProperties": { "DNNCV": {"TRIGGER": "CLASS=dog;cat"} } }
```
it will match either "dog" or "cat", but not "dog;cat".


This JSON fragment:
```json
{ "algorithmProperties": { "DNNCV": {"TRIGGER": "CLASS=dog\\;cat"} } }
```
would only match "dog;cat".

This JSON fragment:
```json
{ "algorithmProperties": { "DNNCV": {"TRIGGER": "CLASS=dog\\\\cat"} } }
```
would only match "dog\cat". The track property in the JSON output object would appear as:
```json
{ "trackProperties": { "CLASSIFICATION": "dog\\cat" } }
```
