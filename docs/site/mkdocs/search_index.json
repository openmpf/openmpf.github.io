{
    "docs": [
        {
            "location": "/", 
            "text": "NOTICE:\n This software (or technical data) was produced for the U.S. Government under contract, and is subject to the Rights in Data-General Clause 52.227-14, Alt. IV (DEC 2007). Copyright 2017 The MITRE Corporation. All Rights Reserved.\n\n\n\n\nOverview\n\n\nThere are numerous video and image exploitation capabilities available today. The Open Media Processing Framework (OpenMPF) provides a framework for chaining, combining, or replacing individual components for the purpose of experimentation and comparison.\n\n\nOpenMPF is a non-proprietary, scalable framework that permits practitioners and researchers to construct video, imagery, and audio exploitation capabilities using the available third-party components. Using OpenMPF, one can extract targeted entities in large-scale data environments, such as face and object detection.\n\n\nFor those developing new exploitation capabilities, OpenMPF exposes a set of Application Program Interfaces (APIs) for extending media analytics functionality. The APIs allow integrators to introduce new algorithms capable of detecting new targeted entity types. For example, a backpack detection algorithm could be integrated into an OpenMPF instance. OpenMPF does not restrict the number of algorithms that can operate on a given media file, permitting researchers, practitioners, and developers to explore arbitrarily complex composites of exploitation algorithms.\n\n\nA list of open source algorithms currently integrated into the OpenMPF as distributed processing components is shown here:\n\n\n\n\n\n\n\n\nOperation\n\n\nObject Type\n\n\nFramework\n\n\n\n\n\n\n\n\n\n\nDetection/Tracking\n\n\nFace\n\n\nOpenCV\n\n\n\n\n\n\nDetection/Tracking\n\n\nFace\n\n\nDlib\n\n\n\n\n\n\nDetection/Tracking\n\n\nText\n\n\nOpenALPR\n\n\n\n\n\n\nDetection/Tracking\n\n\nMotion\n\n\nOpenCV w/ STRUCT\n\n\n\n\n\n\nDetection/Tracking\n\n\nPerson\n\n\nOpenCV\n\n\n\n\n\n\nDetection\n\n\nSpeech\n\n\nSphinx\n\n\n\n\n\n\nDetection\n\n\nClassification\n\n\nCaffe\n\n\n\n\n\n\n\n\nThe OpenMPF exposes data processing and job management web services via a User Interface (UI). These services allow users to upload media, create media processing jobs, determine the status of jobs, and retrieve the artifacts associated with completed jobs. The web services give application developers flexibility to use the OpenMPF in their preferred environment and programming language.", 
            "title": "Home"
        }, 
        {
            "location": "/#overview", 
            "text": "There are numerous video and image exploitation capabilities available today. The Open Media Processing Framework (OpenMPF) provides a framework for chaining, combining, or replacing individual components for the purpose of experimentation and comparison.  OpenMPF is a non-proprietary, scalable framework that permits practitioners and researchers to construct video, imagery, and audio exploitation capabilities using the available third-party components. Using OpenMPF, one can extract targeted entities in large-scale data environments, such as face and object detection.  For those developing new exploitation capabilities, OpenMPF exposes a set of Application Program Interfaces (APIs) for extending media analytics functionality. The APIs allow integrators to introduce new algorithms capable of detecting new targeted entity types. For example, a backpack detection algorithm could be integrated into an OpenMPF instance. OpenMPF does not restrict the number of algorithms that can operate on a given media file, permitting researchers, practitioners, and developers to explore arbitrarily complex composites of exploitation algorithms.  A list of open source algorithms currently integrated into the OpenMPF as distributed processing components is shown here:     Operation  Object Type  Framework      Detection/Tracking  Face  OpenCV    Detection/Tracking  Face  Dlib    Detection/Tracking  Text  OpenALPR    Detection/Tracking  Motion  OpenCV w/ STRUCT    Detection/Tracking  Person  OpenCV    Detection  Speech  Sphinx    Detection  Classification  Caffe     The OpenMPF exposes data processing and job management web services via a User Interface (UI). These services allow users to upload media, create media processing jobs, determine the status of jobs, and retrieve the artifacts associated with completed jobs. The web services give application developers flexibility to use the OpenMPF in their preferred environment and programming language.", 
            "title": "Overview"
        }, 
        {
            "location": "/Release-Notes/", 
            "text": "NOTICE:\n This software (or technical data) was produced for the U.S. Government under contract, and is subject to the Rights in Data-General Clause 52.227-14, Alt. IV (DEC 2007). Copyright 2017 The MITRE Corporation. All Rights Reserved.\n\n\n\n\nOpenMPF Version 0.9:  April 2017\n\n\n\n\nWARNING:\n MPFImageReader has been disabled in this version of OpenMPF. Component developers should use MPFVideoCapture instead. This affects components developed against previous versions of OpenMPF and components developed against this version of OpenMPF. Please refer to the \nKnown Issues\n section for more information.\n\n\nWARNING:\n The OALPR Text Detection Component has been renamed to OALPR \nLicense Plate\n Text Detection Component. This affects the name of the component package and the name of the actions, tasks, and pipelines. When upgrading from R0.8 to R0.9, if the old OALPR Text Detection Component is installed in R0.8 then you will be prompted to install it again at the end of the upgrade path script. We recommend declining this prompt because the old component will conflict with the new component.\n\n\nWARNING:\n Action, task, and pipeline names that started with \"MOTION DETECTION PREPROCESSOR\" have been renamed \"MOG MOTION DETECTION PREPROCESSOR\". Similarly, \"WITH MOTION PREPROCESSOR\" has changed to \"WITH MOG MOTION PREPROCESSOR\".\n\n\n\n\nDocumentation\n\n\n\n\nUpdated the \nREST API\n to reflect job properties, algorithm-specific properties, and media-specific properties.\n\n\nStreamlined the \nC++ Component API\n document for clarity and simplicity.\n\n\nCompleted the \nJava Component API\n document.\n\n\nUpdated the \nAdmin Manual\n and \nUser Guide\n to reflect web UI changes.\n\n\nUpdated the \nBuild Guide\n with instructions for GitHub repositories.\n\n\n\n\nWorkflow Manager\n\n\n\n\nAdded support for job properties, which will override pre-defined pipeline properties.\n\n\nAdded support for algorithm-specific properties, which will apply to a single stage of the pipeline and will override job properties and pre-defined pipeline properties.\n\n\nAdded support for media-specific properties, which will apply to a single piece and media and will override job properties, algorithm-specific properties, and pre-defined pipeline properties.\n\n\nComponents can now be automatically registered and installed when the web application starts in Tomcat.\n\n\n\n\nWeb User Interface\n\n\n\n\nThe \"Close All\" button on pop-up notifications now dismisses all notifications from the queue, not just the visible ones.\n\n\nJob completion notifications now only appear for jobs created during the current login session instead of all jobs.\n\n\nThe ROTATION, HORIZONTAL_FLIP, and SEARCH_REGION_* properties can be set using the web interface when creating a job. Once files are selected for a job, these properties can be set individually or by groups of files.\n\n\nThe Node and Process Status page has been merged into the Node Configuration page for simplicity and ease of use.\n\n\nThe Media Markup results page has been merged into the Job Status page for simplicity and ease of use.\n\n\nThe File Manager UI has been improved to handle large numbers of files and symbolic links.\n\n\nThe side navigation menu is now replaced by a top navigation bar.\n\n\n\n\nREST API\n\n\n\n\nAdded an optional jobProperties object to the /rest/jobs/ request which contains String key-value pairs which override the pipeline's pre-configured job properties.\n\n\nAdded an optional algorithmProperties object to the /rest/jobs/ request which can be used to configure properties for specific algorithms in the pipeline. These properties override the pipeline's pre-configured job properties. They also override the values in the jobProperties object.\n\n\nUpdated the /rest/jobs/ request to add more detail to media, replacing a list of mediaUri Strings with a list of media objects, each of which contains a mediaUri and an optional mediaProperties map. The mediaProperties map can be used to configure properties for the specific piece of media. These properties override the pipeline's pre-configured job properties, values in the jobProperties object, and values in the algorithmProperties object.\n\n\nStreamlined the actions, tasks, and pipelines endpoints that are used by the web UI.\n\n\n\n\nFlipping, Rotation, and Region of Interest\n\n\n\n\nThe ROTATION, HORIZONTAL_FLIP, and SEARCH_REGION_* properties will no longer appear in the detectionProperties map in the JSON detection output object. When applied to an algorithm these properties now appear in the pipeline.stages.actions.properties element. When applied to a piece of media these properties will now appear in the the media.mediaProperties element.\n\n\nThe OpenMPF now supports multiple regions of interest in a single media file.  Each region will produce tracks separately, and the tracks for each region will be listed in the JSON output as if from a separate media file.\n\n\n\n\nComponent API\n\n\n\n\nJava Component API is functionally complete for third-party development, with the exception of Component Adapter and frame transformation utilities classes.\n\n\nRe-architected the Java component API to use a more traditional Java method structure of returning track lists and throwing exceptions (rather than modifying input track lists and returning statuses), and encapsulating job properties into MPFJob objects:\n\n\nList\nMPFVideoTrack\n getDetections(MPFVideoJob job) throws MPFComponentDetectionError\n\n\nList\nMPFAudioTrack\n getDetections(MPFAudioJob job) throws MPFComponentDetectionError\n\n\nList\nMPFImageLocation\n getDetections(MPFImageJob job) throws MPFComponentDetectionError\n\n\n\n\n\n\nCreated examples for the Java Component API.\n\n\nReorganized the Java and C++ component source code to enable component development without the OpenMPF core, which will simplify component development and streamline the code base.\n\n\n\n\nJSON Output Objects\n\n\n\n\nThe JSON output object for the job now contains a jobProperties map which contains all properties defined for the job in the job request.  For example, if the job request specifies a CONFIDENCE_THRESHOLD of then the jobProperties map in the output will also list a CONFIDENCE_THRESHOLD of 5.\n\n\nThe JSON output object for the job now contains a algorithmProperties element which contains all algorithm-specific properties defined for the job in the job request.  For example, if the job request specifies a FRAME_INTERVAL of 2 for FACECV then the algorithmProperties element in the output will contain an entry for \"FACECV\" and that entry will list a FRAME_INTERVAL of 2.\n\n\nEach JSON media output object now contains a mediaProperties map which contains all media-specific properties defined by the job request.  For example, if the job request specifies a ROTATION of 90 degrees for a single piece of media then the mediaProperties map for that piece of piece will list a ROTATION of 90.\n\n\nThe content of JSON output objects are now organized by detection type (e.g. MOTION, FACE, PERSON, TEXT, etc.) rather than action type.\n\n\n\n\nCaffe Component\n\n\n\n\nAdded support for flip, rotation, and cropping to regions of interest.\n\n\nAdded support for returning multiple classifications per detection based on user-defined settings. The classification list is in order of decreasing confidence value.\n\n\n\n\nNew Pipelines\n\n\n\n\nNew SuBSENSE motion preprocessor pipelines have been added to components that perform detection on video.\n\n\n\n\nPackaging and Deployment\n\n\n\n\nActions.xml, Algorithms.xml, nodeManagerConfig.xml, nodeServicesPalette.json, Pipelines.xml, and Tasks.xml are no longer stored within the Workflow Manager WAR file. They are now stored under \n$MPF_HOME/data\n. This makes it easier to upgrade the Workflow Manager and makes it easier for users to access these files.\n\n\nEach component can now be optionally installed and registered during deployment. Components not registered are set to the UPLOADED state. They can then be removed or registered through the Component Registration page.\n\n\nJava components are now packaged as tar.gz files instead of RPMs, bringing them into alignment with C++ components.\n\n\nOpenMPF R0.9 can be installed over OpenMPF R0.8. The deployment scripts will determine that an upgrade should take place.\n\n\nAfter the upgrade, user-defined actions, tasks, and pipelines will have \"CUSTOM\" prepended to their name.\n\n\nThe job_request table in the mySQL database will have a new \"output_object_version\" column. This column will have \"1.0\" for jobs created using OpenMPF R0.8 and \"2.0\" for jobs created using OpenMPF R0.9. The JSON output object schema has changed between these versions.\n\n\n\n\n\n\nReorganized source code repositories so that component SDKs can be downloaded separately from the OpenMPF core and so that components are grouped by license and maturity. Build scripts have been created to streamline and simplify the build process across the various repositories.\n\n\n\n\nUpgrade to OpenCV 3.1\n\n\n\n\nThe OpenMPF software has been ported to use OpenCV 3.1, including all of the C++ detection components and the markup component. For the OpenALPR license plate detection component, the versions of the openalpr, tesseract, and leptonica libraries were also upgraded to openalpr-2.3.0, tesseract-3.0.4, and leptonica-1.7.2.  For the SuBSENSE motion component, the version of the SuBSENSE library was upgraded to use the code found at this location: \nhttps://bitbucket.org/pierre_luc_st_charles/subsense/src\n.\n\n\n\n\nBug Fixes\n\n\n\n\nMOG motion detection always detected motion in frame 0 of a video. Because motion can only be detected between two adjacent frames, frame 1 is now the first frame in which motion can be detected.\n\n\nMOG motion detection never detected motion in the first frame of a video segment (other than the first video segment because of the frame 0 bug described above). Now, motion is detected using the first frame before the start of a segment, rather than the first frame of the segment.\n\n\nThe above bugs were also present in SuBSENSE motion detection and have been fixed.\n\n\nSuBSENSE motion detection generated tracks where the frame numbers were off by one. Corrected the frame index logic.\n\n\nVery large video files caused an out of memory error in the system during Workflow Manager media inspection.\n\n\nA job would fail when processing images with an invalid metadata tag for the camera flash setting.\n\n\nUsers were permitted to select invalid file types using the File Manager UI.\n\n\n\n\nKnown Issues\n\n\n\n\nMPFImageReader does not work reliably with the current release version of OpenCV 3.1\n: In OpenCV 3.1, new functionality was introduced to interpret EXIF information when reading jpeg files.\n\n\nThere are two issues with this new functionality that impact our ability to use the OpenCV \nimread()\n function with MPFImageReader:\n\n\nFirst, because of a bug in the OpenCV code, reading a jpeg file that contains exif information could cause it to hang. (See \nhttps://github.com/opencv/opencv/issues/6665\n.)\n\n\nSecond, it is not possible to tell the \nimread()\nfunction to ignore the EXIF data, so the image it returns is automatically rotated. (See \nhttps://github.com/opencv/opencv/issues/6348\n.) This results in the MPFImageReader applying a second rotation to the image due to the EXIF information.\n\n\n\n\n\n\nTo address these issues, we developed the following workarounds:\n\n\nCreated a version of the MPFVideoCapture that works with an MPFImageJob. The new MPFVideoCapture can pull frames from both video files and images. MPFVideoCapture leverages cv::VideoCapture, which does not have the two issues described above.\n\n\nDisabled the use of MPFImageReader to prevent new users from trying to develop code leveraging this previous functionality.", 
            "title": "Release Notes"
        }, 
        {
            "location": "/Release-Notes/#openmpf-version-09-april-2017", 
            "text": "WARNING:  MPFImageReader has been disabled in this version of OpenMPF. Component developers should use MPFVideoCapture instead. This affects components developed against previous versions of OpenMPF and components developed against this version of OpenMPF. Please refer to the  Known Issues  section for more information.  WARNING:  The OALPR Text Detection Component has been renamed to OALPR  License Plate  Text Detection Component. This affects the name of the component package and the name of the actions, tasks, and pipelines. When upgrading from R0.8 to R0.9, if the old OALPR Text Detection Component is installed in R0.8 then you will be prompted to install it again at the end of the upgrade path script. We recommend declining this prompt because the old component will conflict with the new component.  WARNING:  Action, task, and pipeline names that started with \"MOTION DETECTION PREPROCESSOR\" have been renamed \"MOG MOTION DETECTION PREPROCESSOR\". Similarly, \"WITH MOTION PREPROCESSOR\" has changed to \"WITH MOG MOTION PREPROCESSOR\".", 
            "title": "OpenMPF Version 0.9:  April 2017"
        }, 
        {
            "location": "/Release-Notes/#documentation", 
            "text": "Updated the  REST API  to reflect job properties, algorithm-specific properties, and media-specific properties.  Streamlined the  C++ Component API  document for clarity and simplicity.  Completed the  Java Component API  document.  Updated the  Admin Manual  and  User Guide  to reflect web UI changes.  Updated the  Build Guide  with instructions for GitHub repositories.", 
            "title": "Documentation"
        }, 
        {
            "location": "/Release-Notes/#workflow-manager", 
            "text": "Added support for job properties, which will override pre-defined pipeline properties.  Added support for algorithm-specific properties, which will apply to a single stage of the pipeline and will override job properties and pre-defined pipeline properties.  Added support for media-specific properties, which will apply to a single piece and media and will override job properties, algorithm-specific properties, and pre-defined pipeline properties.  Components can now be automatically registered and installed when the web application starts in Tomcat.", 
            "title": "Workflow Manager"
        }, 
        {
            "location": "/Release-Notes/#web-user-interface", 
            "text": "The \"Close All\" button on pop-up notifications now dismisses all notifications from the queue, not just the visible ones.  Job completion notifications now only appear for jobs created during the current login session instead of all jobs.  The ROTATION, HORIZONTAL_FLIP, and SEARCH_REGION_* properties can be set using the web interface when creating a job. Once files are selected for a job, these properties can be set individually or by groups of files.  The Node and Process Status page has been merged into the Node Configuration page for simplicity and ease of use.  The Media Markup results page has been merged into the Job Status page for simplicity and ease of use.  The File Manager UI has been improved to handle large numbers of files and symbolic links.  The side navigation menu is now replaced by a top navigation bar.", 
            "title": "Web User Interface"
        }, 
        {
            "location": "/Release-Notes/#rest-api", 
            "text": "Added an optional jobProperties object to the /rest/jobs/ request which contains String key-value pairs which override the pipeline's pre-configured job properties.  Added an optional algorithmProperties object to the /rest/jobs/ request which can be used to configure properties for specific algorithms in the pipeline. These properties override the pipeline's pre-configured job properties. They also override the values in the jobProperties object.  Updated the /rest/jobs/ request to add more detail to media, replacing a list of mediaUri Strings with a list of media objects, each of which contains a mediaUri and an optional mediaProperties map. The mediaProperties map can be used to configure properties for the specific piece of media. These properties override the pipeline's pre-configured job properties, values in the jobProperties object, and values in the algorithmProperties object.  Streamlined the actions, tasks, and pipelines endpoints that are used by the web UI.", 
            "title": "REST API"
        }, 
        {
            "location": "/Release-Notes/#flipping-rotation-and-region-of-interest", 
            "text": "The ROTATION, HORIZONTAL_FLIP, and SEARCH_REGION_* properties will no longer appear in the detectionProperties map in the JSON detection output object. When applied to an algorithm these properties now appear in the pipeline.stages.actions.properties element. When applied to a piece of media these properties will now appear in the the media.mediaProperties element.  The OpenMPF now supports multiple regions of interest in a single media file.  Each region will produce tracks separately, and the tracks for each region will be listed in the JSON output as if from a separate media file.", 
            "title": "Flipping, Rotation, and Region of Interest"
        }, 
        {
            "location": "/Release-Notes/#component-api", 
            "text": "Java Component API is functionally complete for third-party development, with the exception of Component Adapter and frame transformation utilities classes.  Re-architected the Java component API to use a more traditional Java method structure of returning track lists and throwing exceptions (rather than modifying input track lists and returning statuses), and encapsulating job properties into MPFJob objects:  List MPFVideoTrack  getDetections(MPFVideoJob job) throws MPFComponentDetectionError  List MPFAudioTrack  getDetections(MPFAudioJob job) throws MPFComponentDetectionError  List MPFImageLocation  getDetections(MPFImageJob job) throws MPFComponentDetectionError    Created examples for the Java Component API.  Reorganized the Java and C++ component source code to enable component development without the OpenMPF core, which will simplify component development and streamline the code base.", 
            "title": "Component API"
        }, 
        {
            "location": "/Release-Notes/#json-output-objects", 
            "text": "The JSON output object for the job now contains a jobProperties map which contains all properties defined for the job in the job request.  For example, if the job request specifies a CONFIDENCE_THRESHOLD of then the jobProperties map in the output will also list a CONFIDENCE_THRESHOLD of 5.  The JSON output object for the job now contains a algorithmProperties element which contains all algorithm-specific properties defined for the job in the job request.  For example, if the job request specifies a FRAME_INTERVAL of 2 for FACECV then the algorithmProperties element in the output will contain an entry for \"FACECV\" and that entry will list a FRAME_INTERVAL of 2.  Each JSON media output object now contains a mediaProperties map which contains all media-specific properties defined by the job request.  For example, if the job request specifies a ROTATION of 90 degrees for a single piece of media then the mediaProperties map for that piece of piece will list a ROTATION of 90.  The content of JSON output objects are now organized by detection type (e.g. MOTION, FACE, PERSON, TEXT, etc.) rather than action type.", 
            "title": "JSON Output Objects"
        }, 
        {
            "location": "/Release-Notes/#caffe-component", 
            "text": "Added support for flip, rotation, and cropping to regions of interest.  Added support for returning multiple classifications per detection based on user-defined settings. The classification list is in order of decreasing confidence value.", 
            "title": "Caffe Component"
        }, 
        {
            "location": "/Release-Notes/#new-pipelines", 
            "text": "New SuBSENSE motion preprocessor pipelines have been added to components that perform detection on video.", 
            "title": "New Pipelines"
        }, 
        {
            "location": "/Release-Notes/#packaging-and-deployment", 
            "text": "Actions.xml, Algorithms.xml, nodeManagerConfig.xml, nodeServicesPalette.json, Pipelines.xml, and Tasks.xml are no longer stored within the Workflow Manager WAR file. They are now stored under  $MPF_HOME/data . This makes it easier to upgrade the Workflow Manager and makes it easier for users to access these files.  Each component can now be optionally installed and registered during deployment. Components not registered are set to the UPLOADED state. They can then be removed or registered through the Component Registration page.  Java components are now packaged as tar.gz files instead of RPMs, bringing them into alignment with C++ components.  OpenMPF R0.9 can be installed over OpenMPF R0.8. The deployment scripts will determine that an upgrade should take place.  After the upgrade, user-defined actions, tasks, and pipelines will have \"CUSTOM\" prepended to their name.  The job_request table in the mySQL database will have a new \"output_object_version\" column. This column will have \"1.0\" for jobs created using OpenMPF R0.8 and \"2.0\" for jobs created using OpenMPF R0.9. The JSON output object schema has changed between these versions.    Reorganized source code repositories so that component SDKs can be downloaded separately from the OpenMPF core and so that components are grouped by license and maturity. Build scripts have been created to streamline and simplify the build process across the various repositories.", 
            "title": "Packaging and Deployment"
        }, 
        {
            "location": "/Release-Notes/#upgrade-to-opencv-31", 
            "text": "The OpenMPF software has been ported to use OpenCV 3.1, including all of the C++ detection components and the markup component. For the OpenALPR license plate detection component, the versions of the openalpr, tesseract, and leptonica libraries were also upgraded to openalpr-2.3.0, tesseract-3.0.4, and leptonica-1.7.2.  For the SuBSENSE motion component, the version of the SuBSENSE library was upgraded to use the code found at this location:  https://bitbucket.org/pierre_luc_st_charles/subsense/src .", 
            "title": "Upgrade to OpenCV 3.1"
        }, 
        {
            "location": "/Release-Notes/#bug-fixes", 
            "text": "MOG motion detection always detected motion in frame 0 of a video. Because motion can only be detected between two adjacent frames, frame 1 is now the first frame in which motion can be detected.  MOG motion detection never detected motion in the first frame of a video segment (other than the first video segment because of the frame 0 bug described above). Now, motion is detected using the first frame before the start of a segment, rather than the first frame of the segment.  The above bugs were also present in SuBSENSE motion detection and have been fixed.  SuBSENSE motion detection generated tracks where the frame numbers were off by one. Corrected the frame index logic.  Very large video files caused an out of memory error in the system during Workflow Manager media inspection.  A job would fail when processing images with an invalid metadata tag for the camera flash setting.  Users were permitted to select invalid file types using the File Manager UI.", 
            "title": "Bug Fixes"
        }, 
        {
            "location": "/Release-Notes/#known-issues", 
            "text": "MPFImageReader does not work reliably with the current release version of OpenCV 3.1 : In OpenCV 3.1, new functionality was introduced to interpret EXIF information when reading jpeg files.  There are two issues with this new functionality that impact our ability to use the OpenCV  imread()  function with MPFImageReader:  First, because of a bug in the OpenCV code, reading a jpeg file that contains exif information could cause it to hang. (See  https://github.com/opencv/opencv/issues/6665 .)  Second, it is not possible to tell the  imread() function to ignore the EXIF data, so the image it returns is automatically rotated. (See  https://github.com/opencv/opencv/issues/6348 .) This results in the MPFImageReader applying a second rotation to the image due to the EXIF information.    To address these issues, we developed the following workarounds:  Created a version of the MPFVideoCapture that works with an MPFImageJob. The new MPFVideoCapture can pull frames from both video files and images. MPFVideoCapture leverages cv::VideoCapture, which does not have the two issues described above.  Disabled the use of MPFImageReader to prevent new users from trying to develop code leveraging this previous functionality.", 
            "title": "Known Issues"
        }, 
        {
            "location": "/Contributor-Guide/", 
            "text": "NOTICE:\n This software (or technical data) was produced for the U.S. Government under contract, and is subject to the Rights in Data-General Clause 52.227-14, Alt. IV (DEC 2007). Copyright 2017 The MITRE Corporation. All Rights Reserved.\n\n\n\n\nHigh-level Overview\n\n\nWe're excited that you're considering contributing to the OpenMPF project! If you have any questions about the process or how to get involved, please feel free to send us an \ne-mail\n with your question.\n\n\nWe encourage you to read the remainder of the guide as well as review the project's \nLicense\n and other \nDocumentation\n.\n\n\nThe OpenMPF project consists of the following repositories:\n\n\n\n\nopenmpf/openmpf\n\n\nopenmpf/openmpf-components\n\n\nopenmpf/openmpf-contrib-components\n\n\nopenmpf/openmpf-build-tools\n\n\nopenmpf/openmpf-cpp-component-sdk\n\n\nopenmpf/openmpf-java-component-sdk\n\n\nopenmpf/openmpf-projects\n\n\n\n\nWork across the project is tracked using our board on \noverv.io\n.\n\n\nContribution Guidelines\n\n\nWe welcome all contributions that are made in a good faith effort to meet the following criteria:\n\n\n\n\nIn line with the spirit of the project. Refer to the \nOpenMPF Overview\n.\n\n\nAddresses an issue in the issue tracker. If an issue doesn't exist yet, create one so that it can be discussed among the OpenMPF community.\n\n\nFunctionally correct and logically sound. All code must pass a code review and round of regression tests.\n\n\nDesigned to use existing interfaces, super classes, and utilities\n\n\nMakes use of well-known design patterns, polymorphism, and encapsulation where possible\n\n\nEmploys best practices for integrating with the OpenMPF architecture. Refer to the \nC++ Component API\n and \nJava Component API\n.\n\n\nEmploys \nstandard coding style\n that is consistent with the rest of the project\n\n\nSufficiently commented and, if necessary, comes with appropriate documentation\n\n\nComes with sufficient test cases\n\n\nDoes not introduce software vulnerabilities\n\n\n\n\nCode Merging Workflow\n\n\nContributor Instructions\n\n\nPerform the following instructions to create a feature branch off of develop, commit your changes, push your branch, and create a pull request. Before the pull request is accepted a Jenkins build must pass and an OpenMPF project administrator must review the changes. We do not have a public Jenkins server so a project administrator will have to start the build for you.\n\n\n\n\nCreate a feature branch off of the latest version of develop\n\n\n\n\ncd /path/to/repo\ngit checkout develop\ngit pull\ngit checkout -b \nmy-new-feature\n\n\n\n\n\n\n\nMake Commits\n\n\n\n\ngit add .\ngit commit\n\n\n\n\n\n\nPush your feature branch.\n\n\n\n\ngit push -u origin \nmy-new-feature\n\n\n\n\n\n\n\nCreate a pull request.\n\n\nGo to GitHub page for repo.\n\n\nClick \"New pull request\"\n\n\nChange the dropdown that says \"base: master\" to develop\n\n\nChange the dropdown that says \"compare: master\" to your feature branch\n\n\nIf a message saying \"Can\u2019t automatically merge.\" appears to the right of the dropdowns, pull the latest version of develop, merge your feature branch with develop, and push it again:\n\n\n\n\ngit checkout develop\ngit pull\ngit checkout \nmy-new-feature\n\ngit merge develop\n\n# Fix conflicts\ngit add .\ngit commit\ngit push\n\n\n\n\n\n\nClick on the gear next to \"Reviewers\" and select a reviewer\n\n\nClick \"Create pull request\"\n\n\nGet approval\n\n\nAfter creating the pull request you will see that the pull request says \"Review required\" and \"Some checks haven't completed yet.\"\n\n\nAn OpenMPF project administrator will start a Jenkins build. Once the build completes, Jenkins will post a status check to the pull request.\n\n\nIf the Jenkins build passes, the pull request page will say \"All checks have passed\"\n\n\nIf the Jenkins build fails, a project administrator will provide further guidance.\n\n\n\n\n\n\nAn OpenMPF project administrator will review the pull request.\n\n\nIf the reviewer approves the changes, the reviewer will merge the change in to develop and close the pull request.\n\n\nIf the reviewer requests changes, you will need to make changes to your feature branch and push them. After you push your changes, the Jenkins status check will be reset. A project administrator will run another Jenkins build that will contain your most recent changes.\n\n\n\n\n\n\n\n\nIn order to be accepted and merged, pull requests need to comply with the \nContribution Guidelines\n. In cases where an issue is found, please refer to the reviewer's comments for more information on how to update your code. This review and acceptance process applies to all of the OpenMPF repositories, including the OpenMPF core and all of the OpenMPF components.\n\n\nLarge pull requests should be split up into smaller pull requests where possible. This will make it easier to review the code. In general, each pull request should add new functionality, update an existing feature, or fix a bug. We strive to keep the develop branch stable. If merging a smaller pull request will break the system before additional pull requests can be merged, then it's generally a better idea to merge one larger pull request.\n\n\nNote that GitHub has a 100 MB file size limitation. There is currently no way to push files to any of the OpenMPF repositories that are larger than this size.\n\n\nReviewer Instructions\n\n\n\n\nGo to the GitHub page for the pull request\n\n\nClick on the \"Files changed\"\n\n\nReview the code before you start a Jenkins build. You don't need to post your review comments immediately, but the Jenkins machine is on an internal network so for security you must review the code before you start the Jenkins build.\n\n\nAfter you have looked at the code, start an instance of the openmpf-github-with-pull-request Jenkins build.\n\n\nIf the Jenkins build fails, you will need to work with the developer to get the tests to pass.\n\n\nCheckout their branch locally to test it\n\n\n\n\ngit fetch\ngit checkout \nnew-feature\n\n\n\n\n\n\n\nOn the pull request page click \"Add your review\"\n\n\nAdd comments\n\n\nClick the green \"Review changes\" dropdown\n\n\nIf changes are necessary, click the radio button to \"Request changes\"\n\n\nAfter the developer makes the necessary changes, go back to the pull request page\n\n\nReview the changes\n\n\nStart another instance of the openmpf-github-with-pull-request Jenkins build.\n\n\nIf you are satisfied with the changes, click the \"Review changes\" dropdown\n\n\nSelect the \"Approve\" radio button, and click \"Submit review\"\n\n\nClick \"Squash and merge\" on the pull request page\n\n\nIf you don't see a \"Squash and merge\" button, find the button that says \"Merge pull request\", click the upside down triangle on the right side of the button, select \"Squash and merge\"\n\n\nA text box showing the commit message will appear above the \"Squash and merge button\". Edit message if necessary.\n\n\nClick \"Confirm squash and merge\"\n\n\nA message will pop up saying \"Pull request successfully merged and closed. You\u2019re all set\u2014the \n branch can be safely deleted.\"\n\n\nClick \"Delete branch\"\n\n\nUpdate the openmpf-projects' develop branch with the new changes:\n\n\n\n\ncd openmpf-projects\ngit checkout develop\ngit pull\ngit submodule foreach 'git checkout develop'\ngit submodule foreach 'git pull'\ngit add .\ngit commit\ngit push\n\n\n\n\nVersioning a New Release\n\n\nWhen the OpenMPF team agrees that it's time to version a new release of the system, a project administrator will merge the develop branch into the master branch for each repository. The master branch commit of each repository will then be tagged with the release number. The decision to version a new release is based on the following factors:\n\n\n\n\nThe system has been updated with major features and/or enhancements\n\n\nThe system has been updated to work with new versions of critical system dependencies, such as OpenCV and Spring\n\n\nThe packaging and/or deployment process has changed significantly\n\n\nIt's been a long time since the last release and many small updates have been made to the system\n\n\n\n\nAdding New Components\n\n\nIn general, a new component will initially go in the \nopenmpf-contrib-components\n repository. That is a holding ground until it can be transitioned to the \nopenmpf-components\n repository. To be a candidate for transition, it must meet the following criteria:\n\n\n\n\nIs strongly in line with the spirit of the project and there is a commitment to maintain and update the code as the project evolves\n\n\nFully licensed under Apache 2.0 or a compatible license. All source code must be provided\n\n\nComes with sufficient unit, system, and/or integration tests with a strong focus on regression testing\n\n\n\n\nNote that new components should have a README.md file, LICENSE file, COPYING file, and optionally a NOTICE file. The LICENSE file should contain information about all of the licenses in the code base, including those licenses for code you didn't write.\n\n\nCoding Style\n\n\nThe following list of style guides provide a comprehensive explanation of some of the best coding practices for the programming languages used in the OpenMPF project:\n\n\n\n\nGoogle C++ Style Guide\n\n\nGoogle Java Style Guide\n\n\nGoogle JavaScript Style Guide\n\n\nGoogle Python Style Guide\n\n\n\n\nGenerally speaking, when writing new code, please refer to existing code in the repositories and match the style. Most style issues boil down to inconsistency. Not all of our code adheres to these style guidelines, but we are striving to improve it.", 
            "title": "Contributor Guide"
        }, 
        {
            "location": "/Contributor-Guide/#high-level-overview", 
            "text": "We're excited that you're considering contributing to the OpenMPF project! If you have any questions about the process or how to get involved, please feel free to send us an  e-mail  with your question.  We encourage you to read the remainder of the guide as well as review the project's  License  and other  Documentation .  The OpenMPF project consists of the following repositories:   openmpf/openmpf  openmpf/openmpf-components  openmpf/openmpf-contrib-components  openmpf/openmpf-build-tools  openmpf/openmpf-cpp-component-sdk  openmpf/openmpf-java-component-sdk  openmpf/openmpf-projects   Work across the project is tracked using our board on  overv.io .", 
            "title": "High-level Overview"
        }, 
        {
            "location": "/Contributor-Guide/#contribution-guidelines", 
            "text": "We welcome all contributions that are made in a good faith effort to meet the following criteria:   In line with the spirit of the project. Refer to the  OpenMPF Overview .  Addresses an issue in the issue tracker. If an issue doesn't exist yet, create one so that it can be discussed among the OpenMPF community.  Functionally correct and logically sound. All code must pass a code review and round of regression tests.  Designed to use existing interfaces, super classes, and utilities  Makes use of well-known design patterns, polymorphism, and encapsulation where possible  Employs best practices for integrating with the OpenMPF architecture. Refer to the  C++ Component API  and  Java Component API .  Employs  standard coding style  that is consistent with the rest of the project  Sufficiently commented and, if necessary, comes with appropriate documentation  Comes with sufficient test cases  Does not introduce software vulnerabilities", 
            "title": "Contribution Guidelines"
        }, 
        {
            "location": "/Contributor-Guide/#code-merging-workflow", 
            "text": "", 
            "title": "Code Merging Workflow"
        }, 
        {
            "location": "/Contributor-Guide/#contributor-instructions", 
            "text": "Perform the following instructions to create a feature branch off of develop, commit your changes, push your branch, and create a pull request. Before the pull request is accepted a Jenkins build must pass and an OpenMPF project administrator must review the changes. We do not have a public Jenkins server so a project administrator will have to start the build for you.   Create a feature branch off of the latest version of develop   cd /path/to/repo\ngit checkout develop\ngit pull\ngit checkout -b  my-new-feature    Make Commits   git add .\ngit commit   Push your feature branch.   git push -u origin  my-new-feature    Create a pull request.  Go to GitHub page for repo.  Click \"New pull request\"  Change the dropdown that says \"base: master\" to develop  Change the dropdown that says \"compare: master\" to your feature branch  If a message saying \"Can\u2019t automatically merge.\" appears to the right of the dropdowns, pull the latest version of develop, merge your feature branch with develop, and push it again:   git checkout develop\ngit pull\ngit checkout  my-new-feature \ngit merge develop\n\n# Fix conflicts\ngit add .\ngit commit\ngit push   Click on the gear next to \"Reviewers\" and select a reviewer  Click \"Create pull request\"  Get approval  After creating the pull request you will see that the pull request says \"Review required\" and \"Some checks haven't completed yet.\"  An OpenMPF project administrator will start a Jenkins build. Once the build completes, Jenkins will post a status check to the pull request.  If the Jenkins build passes, the pull request page will say \"All checks have passed\"  If the Jenkins build fails, a project administrator will provide further guidance.    An OpenMPF project administrator will review the pull request.  If the reviewer approves the changes, the reviewer will merge the change in to develop and close the pull request.  If the reviewer requests changes, you will need to make changes to your feature branch and push them. After you push your changes, the Jenkins status check will be reset. A project administrator will run another Jenkins build that will contain your most recent changes.     In order to be accepted and merged, pull requests need to comply with the  Contribution Guidelines . In cases where an issue is found, please refer to the reviewer's comments for more information on how to update your code. This review and acceptance process applies to all of the OpenMPF repositories, including the OpenMPF core and all of the OpenMPF components.  Large pull requests should be split up into smaller pull requests where possible. This will make it easier to review the code. In general, each pull request should add new functionality, update an existing feature, or fix a bug. We strive to keep the develop branch stable. If merging a smaller pull request will break the system before additional pull requests can be merged, then it's generally a better idea to merge one larger pull request.  Note that GitHub has a 100 MB file size limitation. There is currently no way to push files to any of the OpenMPF repositories that are larger than this size.", 
            "title": "Contributor Instructions"
        }, 
        {
            "location": "/Contributor-Guide/#reviewer-instructions", 
            "text": "Go to the GitHub page for the pull request  Click on the \"Files changed\"  Review the code before you start a Jenkins build. You don't need to post your review comments immediately, but the Jenkins machine is on an internal network so for security you must review the code before you start the Jenkins build.  After you have looked at the code, start an instance of the openmpf-github-with-pull-request Jenkins build.  If the Jenkins build fails, you will need to work with the developer to get the tests to pass.  Checkout their branch locally to test it   git fetch\ngit checkout  new-feature    On the pull request page click \"Add your review\"  Add comments  Click the green \"Review changes\" dropdown  If changes are necessary, click the radio button to \"Request changes\"  After the developer makes the necessary changes, go back to the pull request page  Review the changes  Start another instance of the openmpf-github-with-pull-request Jenkins build.  If you are satisfied with the changes, click the \"Review changes\" dropdown  Select the \"Approve\" radio button, and click \"Submit review\"  Click \"Squash and merge\" on the pull request page  If you don't see a \"Squash and merge\" button, find the button that says \"Merge pull request\", click the upside down triangle on the right side of the button, select \"Squash and merge\"  A text box showing the commit message will appear above the \"Squash and merge button\". Edit message if necessary.  Click \"Confirm squash and merge\"  A message will pop up saying \"Pull request successfully merged and closed. You\u2019re all set\u2014the   branch can be safely deleted.\"  Click \"Delete branch\"  Update the openmpf-projects' develop branch with the new changes:   cd openmpf-projects\ngit checkout develop\ngit pull\ngit submodule foreach 'git checkout develop'\ngit submodule foreach 'git pull'\ngit add .\ngit commit\ngit push", 
            "title": "Reviewer Instructions"
        }, 
        {
            "location": "/Contributor-Guide/#versioning-a-new-release", 
            "text": "When the OpenMPF team agrees that it's time to version a new release of the system, a project administrator will merge the develop branch into the master branch for each repository. The master branch commit of each repository will then be tagged with the release number. The decision to version a new release is based on the following factors:   The system has been updated with major features and/or enhancements  The system has been updated to work with new versions of critical system dependencies, such as OpenCV and Spring  The packaging and/or deployment process has changed significantly  It's been a long time since the last release and many small updates have been made to the system", 
            "title": "Versioning a New Release"
        }, 
        {
            "location": "/Contributor-Guide/#adding-new-components", 
            "text": "In general, a new component will initially go in the  openmpf-contrib-components  repository. That is a holding ground until it can be transitioned to the  openmpf-components  repository. To be a candidate for transition, it must meet the following criteria:   Is strongly in line with the spirit of the project and there is a commitment to maintain and update the code as the project evolves  Fully licensed under Apache 2.0 or a compatible license. All source code must be provided  Comes with sufficient unit, system, and/or integration tests with a strong focus on regression testing   Note that new components should have a README.md file, LICENSE file, COPYING file, and optionally a NOTICE file. The LICENSE file should contain information about all of the licenses in the code base, including those licenses for code you didn't write.", 
            "title": "Adding New Components"
        }, 
        {
            "location": "/Contributor-Guide/#coding-style", 
            "text": "The following list of style guides provide a comprehensive explanation of some of the best coding practices for the programming languages used in the OpenMPF project:   Google C++ Style Guide  Google Java Style Guide  Google JavaScript Style Guide  Google Python Style Guide   Generally speaking, when writing new code, please refer to existing code in the repositories and match the style. Most style issues boil down to inconsistency. Not all of our code adheres to these style guidelines, but we are striving to improve it.", 
            "title": "Coding Style"
        }, 
        {
            "location": "/Build-Environment-Setup-Guide/", 
            "text": "NOTICE:\n This software (or technical data) was produced for the U.S. Government under contract, and is subject to the Rights in Data-General Clause 52.227-14, Alt. IV (DEC 2007). Copyright 2017 The MITRE Corporation. All Rights Reserved.\n\n\n\n\nGeneral Information\n\n\nThe Open Media Processing Framework (OpenMPF) software is distributed to interested parties as a raw source code package. This is to avoid any potential licensing issues that may arise from distributing a pre-compiled executable that is linked to dependencies that are licensed under a copyleft license or have patent restrictions. Generally, it is acceptable build and execute software with these dependencies for non-commercial in-house use.\n\n\nBy distributing the OpenMPF software as raw source code the development team is able to keep most of the software clean from copyleft and patent issues so that it can be published under a more open Apache license and freely distributed to interested parties.\n\n\n\n\nIMPORTANT:\n It is the responsibility of the end users who follow this guide, and otherwise build the OpenMPF software to create an executable, to abide by all of the non-commercial and re-distribution restrictions imposed by the dependencies that the OpenMPF software uses. Building the OpenMPF and linking in these dependencies at build time or run time results in creating a derivative work under the terms of the GNU General Public License. Refer to the About page within the OpenMPF for more information about these dependencies.\n\n\n\n\nIn general, it is only acceptable to use and distribute the executable form of the OpenMPF \"in house\", which is loosely defined as internally with an organization. The OpenMPF should only be distributed to third parties in raw source code form and those parties will be responsible for creating their own executable.\n\n\nThis guide provides comprehensive instructions for setting up a build environment and generating an OpenMPF deployment package that contains the executable form of the software. This package is self-contained so that it can be installed on a minimal CentOS 7 system without Internet connectivity. This package can be freely distributed and installed in-house, but not distributed to third parties.\n\n\nSet Up the Minimal CentOS 7 VM\n\n\nThe following instructions are for setting up a VM for building an OpenMPF deployment package. This VM is not necessarily a machine on which the OpenMPF will be deployed and run. Those machines may have other requirements. For more information refer to the \nOpenMPF Installation Guide\n.\n\n\n\n\nThis guide assumes a starting point of CentOS 7 with a minimal installation.\n\n\nAt the time of writing this, the available minimal .iso file is CentOS-7-x86_64-Minimal-1611.iso. It should be downloaded from \nhttps://www.centos.org/download/\n prior to starting these steps.\n\n\n\n\nOracle Virtual Box 5.0.20-106931 is used as the virtualization platform. Another platform such as VMware or a physical system can be used but are not supported.\n\n\n\n\n\n\nCreate a new VM with these settings:\n\n\n\n\nName\n: \u2019OpenMPF Build\u2019. (This guide assumes the name \u2018OpenMPF Build\u2019, but any name can be used.)\n\n\nType\n: Linux\n\n\nVersion\n: Red Hat (64-bit)\n\n\n\n\n\n\n\n\nThe recommended minimum virtual system specifications are:\n\n\n\n\nMemory\n: 8192MB\n\n\nCPU\n: 4\n\n\nDisk\n: 40GB on a SSD.\n\n\n\n\n\n\n\n\nNetwork settings may vary based on your local environment. Connectivity to the public Internet is assumed. The network settings used in this guide are:\n\n\n\n\nAttached to\n: NAT\n\n\nAdvanced -\n Adapter Type\n: Intel PRO/1000 MT Desktop (82540EM)\n\n\nCable Connected\n: Checked\n\n\n\n\n\n\n\n\nInstalling CentOS 7\n\n\n\n\nNOTE:\n If your build environment is behind a proxy server, please read the appendix section \nProxy Configuration\n for instructions to configure the yum package manager before continuing.\n\n\n\n\n\n\nOpen the \u2018Settings\u2019 for the OpenMPF Build VM.\n\n\nSelect the \u2018Storage\u2019 menu item.\n\n\nIn the \u2018Storage Tree\u2019 section under the \u2018Controller: IDE\u2019 item, select the optical disc icon.\n\n\nUnder the \u2018Attributes\u2019 section, select the optical disc icon with a small black arrow. This will bring up a menu.\n\n\nSelect \u2018Choose Virtual Optical Disc file\u2026\u2019\n\n\nChoose the \u2018CentOS-7-x86_64-Minimal-1611.iso\u2019 file.\n\n\nPress the \u2018OK\u2019 button to exit the OpenMPF Build VM settings.\n\n\nRight click on the OpenMPF Build VM and select \u2018Start\u2019 and \u2018Normal Start\u2019. A new window will open with the running VM.\n\n\nOn the \u2018CentOS 7\u2019 screen, select \u2018Install CentOS 7\u2019 with the keyboard and press the Enter key.\n\n\nSelect the appropriate language and press the \u2018Continue\u2019 button.\n\n\nOn the \u2018Installation Summary\u2019 screen, select the \u2018Installation Destination\u2019 icon.\n\n\nPress the \u2018Done\u2019 button to accept the defaults.\n\n\nOn the \u2018Installation Summary\u2019 screen, select the \u2018Network \n Host Name\u2019 icon. There should be one interface listed.\n\n\nSet the slider switch to \u2018On\u2019.\n\n\nPress the \u2018Configure\u2019 button, select the \u2018General\u2019 tab, and check the box for \u2018Automatically connect to this network when available\u2019.\n\n\nPress the 'Save' button.\n\n\nEach interface should show its status as \u2018Connected\u2019 with an IPv4 address.\n\n\nLeave the hostname as \u2018localhost.localdomain\u2019.\n\n\nPress the \u2018Done\u2019 button.\n\n\nUse the default values for everything else and press 'Begin Installation'.\n\n\nSet a password for the root account.\n\n\nUnder \u2018User Creation\u2019, create a new user:\n\n\nFull Name\n: mpf\n\n\nUser Name\n: mpf\n\n\nCheck the box for \u2018Make this user administrator\u2019\n\n\n\n\n\n\nPassword\n: mpf\n\n\n\n\n\n\nWhen installation is finished, press the \u2018Finish Configuration\u2019 button.\n\n\nWhen configuration is finished, press the \u2018Reboot\u2019 button.\n\n\nAt the login prompt, login as user \u2018mpf\u2019 and password \u2018mpf\u2019.\n\n\nInstall the epel repository and Delta RPM:\n    \n \nsudo yum install -y epel-release deltarpm\n\n\nPerform an initial system update:\n    \n \nsudo yum update -y\n\n\nInstall Gnome Desktop Environment and some packages needed for the Virtual Box Guest Additions:\n    \n \nsudo yum groups install -y \"GNOME Desktop\"\n\n\nInstall packages needed for the Virtual Box Guest Additions:\n    \n \nsudo yum install gcc kernel-devel bzip2\n\n\nNOTE:\n You may have to specify a kernel version when installing \u2018kernel-devel\u2018 as a Virtual Box guest addition. For example: \nsudo yum install kernel-devel-3.10.0-327.el7.x86_64\n.\n\n\n\n\n\n\nReboot the system:\n    \n \nsudo reboot now\n\n\nFollow the on screen instructions to accept the license agreement.\n\n\nAt the login prompt, login as user \u2018mpf\u2019 and password \u2018mpf\u2019.\n\n\nSwitch user to root with this command:\n    \n \nsudo su -\n\n\nOn your host system in the Virtual Box Application, select the OpenMPF Build VM menu item \u2018Devices\u2019 and then \u2018Insert Guest Additions CD image\u2026\u2019\n\n\nInstall the Virtual Box Guest Additions:\n\n\nmount /dev/cdrom /mnt\n\n\ncd /mnt\n\n\n./VBoxLinuxAdditions.run\n\n\n\n\n\n\nsystemctl set-default graphical.target\n\n\nreboot now\n\n\nAt the graphical login screen, select the 'mpf' user.\n\n\nEnter 'mpf' as the password.\n\n\nA welcome screen will come up on the first launch of the Gnome desktop environment. Press the 'Next' button on the 'Language' page.\n\n\nPress the 'Next' button on the 'Typing' page.\n\n\nPress the 'Skip' button on the 'Online Accounts' page.\n\n\nPress the 'Start using CentOS Linux' button.\n\n\nClose the 'Getting Started' window that appears.\n\n\nOn the desktop, right click the 'VBOXADDITIONS_5.0.22_108108' icon and select 'Eject'.\n\n\nOn your host system in the Virtual Box Application, select the OpenMPF Build VM menu item \u2018Devices\u2019, then \u2018Shared Clipboard\u2019, then \"Bidirectional\". This will enable the ability to copy and paste commands from this document into the VM.\n\n\nOn your host system in the Virtual Box Application, select the OpenMPF Build VM menu item \u2018Devices\u2019, then \u2018Drag and Drop\u2019, then \"Bidirectional\". This will enable the ability to drag files from the host system to the guest VM.\n\n\n\n\nSet Up the OpenMPF Build Environment\n\n\n\n\nNOTE:\n If your build environment is behind a proxy server, please read the appendix section \nProxy Configuration\n for instructions to configure the yum package manager before continuing.\n\n\n\n\nAt the time of writing, all URLs provided in this section were verified as working.\n\n\nConfigure Additional Repositories\n\n\n\n\nInstall the Oracle MySQL Community Release Repository:\n\n\nwget -P /home/mpf/Downloads \"http://dev.mysql.com/get/mysql-community-release-el7-5.noarch.rpm\"\n\n\nsudo rpm -ivh /home/mpf/Downloads/mysql-community-release-el7-5.noarch.rpm\n\n\n\n\n\n\nInstall the Remi Repo for Redis:\n\n\nwget -P /home/mpf/Downloads \"http://rpms.remirepo.net/RPM-GPG-KEY-remi\"\n\n\nwget -P /home/mpf/Downloads \"http://rpms.famillecollet.com/enterprise/remi-release-7.rpm\"\n\n\nsudo rpm --import /home/mpf/Downloads/RPM-GPG-KEY-remi\n\n\nsudo rpm -Uvh /home/mpf/Downloads/remi-release-7.rpm\n\n\nsudo yum-config-manager --enable remi\n\n\n\n\n\n\nCreate an \u2018/apps\u2019 directory and package subdirectories:\n\n\nsudo mkdir -p /apps/install/lib\n\n\nsudo mkdir -p /apps/bin/apache\n\n\nsudo mkdir /apps/ansible\n\n\nsudo mkdir -p /apps/source/cmake_sources\n\n\nsudo mkdir /apps/source/apache_sources\n\n\nsudo mkdir /apps/source/google_sources\n\n\nsudo mkdir /apps/source/opencv_sources\n\n\nsudo mkdir /apps/source/ffmpeg_sources\n\n\nsudo mkdir /apps/source/dlib-sources\n\n\nsudo mkdir /apps/source/openalpr_sources\n\n\nsudo mkdir /apps/source/ansible_sources\n\n\nsudo chown -R mpf:mpf /apps\n\n\nsudo chmod -R 755 /apps\n\n\n\n\n\n\nAdd /apps/install/bin to the system PATH variable:\n\n\nsudo sh -c 'echo \"PATH=\\$PATH:/apps/install/bin\" \n /etc/profile.d/mpf.sh'\n\n\n. /etc/profile.d/mpf.sh\n\n\n\n\n\n\nCreate the OpenMPF ldconfig file:\n    \nsudo touch /etc/ld.so.conf.d/mpf-x86_64.conf\n\n\nAdd /apps/install/lib to the OpenMPF ldconfig file:\n    \nsudo sh -c 'echo \"/apps/install/lib\" \n /etc/ld.so.conf.d/mpf-x86_64.conf'\n\n\nUpdate the shared library cache:\n    \nsudo ldconfig\n\n\n\n\nRPM Dependencies\n\n\nThe following RPM packages will need to be downloaded and installed. Use of the yum package manager is recommended:\n\n\nsudo yum install -y asciidoc autoconf automake boost boost-devel cmake3 curl freetype-devel gcc-c++ git graphviz gstreamer-plugins-base-devel gtk2-devel gtkglext-devel gtkglext-libs jasper jasper-devel libavc1394-devel libcurl-devel libdc1394-devel libffi-devel libICE-devel libjpeg-turbo-devel libpng-devel libSM-devel libtiff-devel libtool libv4l-devel libXinerama-devel libXmu-devel libXt-devel log4cplus log4cplus-devel log4cxx log4cxx-devel make mercurial mesa-libGL-devel mesa-libGLU-devel mysql-community-client mysql-community-server nasm ncurses-devel numpy pangox-compat pangox-compat-devel perl-CPAN-Meta-YAML perl-DBD-MySQL perl-DBI perl-Digest-MD5 perl-File-Find-Rule perl-File-Find-Rule-Perl perl-JSON perl-JSON-PP perl-List-Compare perl-Number-Compare perl-Params-Util perl-Parse-CPAN-Meta php pkgconfig python-devel python-httplib2 python-jinja2 python-keyczar python2-paramiko python2-pip python-setuptools python-six PyYAML qt qt-devel qt-x11 redis rpm-build sshpass tbb tbb-devel tree unzip uuid-devel wget yasm yum-utils zlib-devel\n\n\nGet the OpenMPF Source Code\n\n\nOpen a terminal window and perform the following steps:\n\n\n\n\n\n\nClone the OpenMPF repository\n\n\n\n\ncd /home/mpf\n\n\ngit clone https://github.com/openmpf/openmpf-projects.git --recursive\n\n\n(Optional) The HTTPS repository URL requires configuring your Github account with a certificate pair. The HTTP URL may be used without any certificates:\n    \ngit clone http://github.com/openmpf/openmpf-projects.git --recursive\n\n\n\n\n\n\n\n\nCopy the mpf user profile script from the extracted source code:\n    \n \nsudo cp /home/mpf/openmpf-projects/openmpf/trunk/mpf-install/src/main/scripts/mpf-profile.sh /etc/profile.d/mpf.sh\n\n\n\n\n\n\nBinary Packages\n\n\n\n\nNOTE:\n If your environment is behind a proxy server that performs SSL inspection, please read the appendix section \nSSL Inspection\n before continuing.\n\n\n\n\nThe following binary packages will need to be downloaded and installed:\n\n\n\n\n\n\nOracle JDK:\n    \nFor reference only: \nhttp://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html\n\n\n\n\ncd /home/mpf\n\n\nwget --no-cookies --header \"Cookie: oraclelicense=accept-securebackup-cookie\" \"http://download.oracle.com/otn-pub/java/jdk/8u60-b27/jdk-8u60-linux-x64.rpm\" -O /apps/bin/jdk-8u60-linux-x64.rpm\n\n\nsudo yum -y localinstall --nogpgcheck /apps/bin/jdk-8u60-linux-x64.rpm\n\n\nsudo alternatives --install /usr/bin/java java /usr/java/jdk1.8.0_60/jre/bin/java 20000\n\n\nsudo alternatives --install /usr/bin/jar jar /usr/java/jdk1.8.0_60/bin/jar 20000\n\n\nsudo alternatives --install /usr/bin/javac javac /usr/java/jdk1.8.0_60/bin/javac 20000\n\n\nsudo alternatives --install /usr/bin/javaws javaws /usr/java/jdk1.8.0_60/jre/bin/javaws 20000\n\n\nsudo alternatives --set java /usr/java/jdk1.8.0_60/jre/bin/java\n\n\nsudo alternatives --set javaws /usr/java/jdk1.8.0_60/jre/bin/javaws\n\n\nsudo alternatives --set javac /usr/java/jdk1.8.0_60/bin/javac\n\n\nsudo alternatives --set jar /usr/java/jdk1.8.0_60/bin/jar\n\n\nNOTE:\n If this command to set the \njar\n alternative fails with the following error:\n\n\nfailed to read link /usr/bin/jar: No such file or directory\n\n\nYou should run the following commands again:\n- \nsudo alternatives --install /usr/bin/jar jar /usr/java/jdk1.8.0_60/bin/jar 20000\n\n- \nsudo alternatives --set jar /usr/java/jdk1.8.0_60/bin/jar\n\n\n\n\n\n\n. /etc/profile.d/mpf.sh\n\n\n\n\n\n\n\n\nApache ActiveMQ 5.13.0:\n    \nFor reference only: \nhttp://activemq.apache.org\n\n\n\n\ncd /apps/bin/apache\n\n\nwget -O /apps/bin/apache/apache-activemq-5.13.0-bin.tar.gz \"https://archive.apache.org/dist/activemq/5.13.0/apache-activemq-5.13.0-bin.tar.gz\"\n\n\nsudo tar xvzf apache-activemq-5.13.0-bin.tar.gz -C /opt/\n\n\nsudo chown -R mpf:mpf /opt/apache-activemq-5.13.0\n\n\nsudo chmod -R 755 /opt/apache-activemq-5.13.0\n\n\nsudo ln -s /opt/apache-activemq-5.13.0 /opt/activemq\n\n\n\n\n\n\nApache Tomcat 7.0.72:\n    \nFor reference only: \nhttp://tomcat.apache.org\n\n\ncd /apps/bin/apache\n\n\nwget -O /apps/bin/apache/apache-tomcat-7.0.72.tar.gz \"http://archive.apache.org/dist/tomcat/tomcat-7/v7.0.72/bin/apache-tomcat-7.0.72.tar.gz\"\n\n\ntar xzvf apache-tomcat-7.0.72.tar.gz\n\n\nsudo mkdir -p /usr/share/apache-tomcat\n\n\nsudo cp -Rf /apps/bin/apache/apache-tomcat-7.0.72/* /usr/share/apache-tomcat/\n\n\nsudo chown -R mpf:mpf /usr/share/apache-tomcat\n\n\nsudo chmod -R 755 /usr/share/apache-tomcat\n\n\nsudo ln -s /usr/share/apache-tomcat /opt/apache-tomcat\n\n\nsudo perl -i -p0e 's/\n!--\\n    \nManager pathname=\"\" \\/\n\\n      --\n.*?/\n!-- --\n\\n    \nManager pathname=\"\" \\/\n/s' /opt/apache-tomcat/conf/context.xml\n\n\nsudo rm -rf /opt/apache-tomcat/webapps/*\n\n\n\n\n\n\nApache Ant 1.9.6:\n    \nFor reference only: \nhttp://ant.apache.org\n\n\ncd /apps/bin/apache\n\n\nwget -O /apps/bin/apache/apache-ant-1.9.6-bin.tar.gz \"https://archive.apache.org/dist/ant/binaries/apache-ant-1.9.6-bin.tar.gz\"\n\n\ntar xzvf apache-ant-1.9.6-bin.tar.gz\n\n\nsudo cp -R /apps/bin/apache/apache-ant-1.9.6 /apps/install/\n\n\nsudo chown -R mpf:mpf /apps/install/apache-ant-1.9.6\n\n\nsudo sed -i '/^PATH/s/$/:\\/apps\\/install\\/apache-ant-1.9.6\\/bin/' /etc/profile.d/mpf.sh\n\n\n. /etc/profile.d/mpf.sh\n\n\n\n\n\n\nApache Maven 3.3.3:\n    \nFor reference only: \nhttps://maven.apache.org\n\n\ncd /apps/bin/apache\n\n\nwget -O /apps/bin/apache/apache-maven-3.3.3-bin.tar.gz \"https://archive.apache.org/dist/maven/maven-3/3.3.3/binaries/apache-maven-3.3.3-bin.tar.gz\"\n\n\ntar xzvf apache-maven-3.3.3-bin.tar.gz\n\n\nsudo mkdir /opt/apache-maven\n\n\nsudo cp -Rf /apps/bin/apache/apache-maven-3.3.3/* /opt/apache-maven/\n\n\nsudo chown -R mpf:mpf /opt/apache-maven\n\n\nsudo sed -i '/^PATH/s/$/:\\/opt\\/apache-maven\\/bin/' /etc/profile.d/mpf.sh\n\n\nsudo sh -c 'echo \"M2_HOME=/opt/apache-maven\" \n /etc/profile.d/mpf.sh'\n\n\n. /etc/profile.d/mpf.sh\n\n\n\n\n\n\n\n\nPython Packages\n\n\n\n\nC Foreign Function Interface (CFFI):\n\n\ncd /home/mpf\n\n\nsudo -E easy_install -U cffi\n\n\n\n\n\n\nOpenMPF Administrative Tools:\n    \n \nsudo -E pip install /home/mpf/openmpf-projects/openmpf/trunk/bin/mpf-scripts\n\n\n\n\nBuilding Dependencies\n\n\n\n\nNOTE:\n If your build environment is behind a proxy server, please read the appendix section \nProxy Configuration\n for instructions to configure git before continuing.\n\n\n\n\nThe following source packages will need to be downloaded, built, and installed:\n\n\n\n\nCmake 2.8.12.2:\n    \nFor reference only: \nhttps://cmake.org\n\n\ncd /apps/source/cmake_sources\n\n\nwget -O /apps/source/cmake_sources/cmake-2.8.12.2.tar.gz \"https://cmake.org/files/v2.8/cmake-2.8.12.2.tar.gz\"\n\n\ntar xvzf cmake-2.8.12.2.tar.gz\n\n\ncd cmake-2.8.12.2\n\n\nchmod +x *\n\n\n./configure --prefix=/apps/install\n\n\nmake -j\n\n\nsudo make install\n\n\nsudo ldconfig\n\n\nsudo ln -s /apps/install/bin/cmake /usr/local/bin/cmake\n\n\n\n\n\n\n\n\n\n\nNOTE:\n FFmpeg can be built with different encoders and modules that are individually licensed. It is recommended to check each developer\u2019s documentation for the most up-to-date licensing information.    \n\n\n\n\n\n\nFFmpeg 2.6.3:\n\n\nxvidcore:\n    \nFor reference only: \nhttps://labs.xvid.com\n\n\ncd /apps/source/ffmpeg_sources\n\n\nwget -O /apps/source/ffmpeg_sources/xvidcore-1.3.2.tar.gz \"http://downloads.xvid.org/downloads/xvidcore-1.3.2.tar.gz\"\n\n\ntar zxvf xvidcore-1.3.2.tar.gz\n\n\ncd xvidcore/build/generic\n\n\n./configure --prefix=\"/apps/install\"\n\n\nmake\n\n\nsudo make install\n\n\nmake distclean\n\n\nsudo ldconfig\n\n\n\n\n\n\nlibx264:\n    \nFor reference only: \nhttp://www.videolan.org/developers/x264.html\n\n\ncd /apps/source/ffmpeg_sources\n\n\nwget -O /apps/source/ffmpeg_sources/x264-snapshot-20140223-2245-stable.tar.bz2 \"ftp://ftp.videolan.org/pub/videolan/x264/snapshots/x264-snapshot-20140223-2245-stable.tar.bz2\"\n\n\ntar xvjf x264-snapshot-20140223-2245-stable.tar.bz2\n\n\ncd x264-snapshot-20140223-2245-stable\n\n\nPKG_CONFIG_PATH=\"/apps/install/lib/pkgconfig\" ./configure --prefix=\"/apps/install\" --bindir=\"/apps/install\" --enable-shared\n\n\nsudo sed -i '/^PATH/s/$/:\\/apps\\/install\\/lib\\/pkgconfig/' /etc/profile.d/mpf.sh\n\n\nsudo sh -c 'echo \"export PKG_CONFIG_PATH=/apps/install/lib/pkgconfig\" \n /etc/profile.d/mpf.sh'\n\n\n. /etc/profile.d/mpf.sh\n\n\nmake\n\n\nsudo make install\n\n\nmake distclean\n\n\nsudo ldconfig\n\n\n\n\n\n\nopencore-amr:\n    \nFor reference only: \nhttps://sourceforge.net/projects/opencore-amr\n\n\ncd /apps/source/ffmpeg_sources\n\n\nwget -O /apps/source/ffmpeg_sources/opencore-amr-0.1.3.tar.gz \"http://downloads.sourceforge.net/project/opencore-amr/opencore-amr/opencore-amr-0.1.3.tar.gz?r=https%3A%2F%2Fsourceforge.net%2Fprojects%2Fopencore-amr%2Ffiles%2Fopencore-amr%2F\nts=1467223123\nuse_mirror=tenet\"\n\n\ntar xvzf opencore-amr-0.1.3.tar.gz\n\n\ncd opencore-amr-0.1.3\n\n\nautoreconf -fiv\n\n\n./configure --prefix=\"/apps/install\" --enable-shared\n\n\nmake\n\n\nsudo make install\n\n\nmake distclean\n\n\nsudo ldconfig\n\n\n\n\n\n\nlibmp3lame:\n    \nFor reference only: \nhttp://lame.sourceforge.net\n\n\ncd /apps/source/ffmpeg_sources\n\n\nwget -O /apps/source/ffmpeg_sources/lame-3.99.5.tar.gz \"http://downloads.sourceforge.net/project/lame/lame/3.99/lame-3.99.5.tar.gz\"\n\n\ntar xzvf lame-3.99.5.tar.gz\n\n\ncd lame-3.99.5\n\n\n./configure --prefix=\"/apps/install\" --bindir=\"/apps/install/bin\" --enable-shared --enable-nasm\n\n\nmake\n\n\nsudo make install\n\n\nmake distclean\n\n\nsudo ldconfig\n\n\n\n\n\n\nlibogg:\n    \nFor reference only: \nhttps://www.xiph.org/ogg\n\n\ncd /apps/source/ffmpeg_sources\n\n\nwget -O /apps/source/ffmpeg_sources/libogg-1.3.2.tar.gz \"http://downloads.xiph.org/releases/ogg/libogg-1.3.2.tar.gz\"\n\n\ntar xvzf libogg-1.3.2.tar.gz\n\n\ncd libogg-1.3.2\n\n\n./configure --prefix=\"/apps/install\" --enable-shared\n\n\nmake\n\n\nsudo make install\n\n\nmake distclean\n\n\nsudo ldconfig\n\n\n\n\n\n\nlibvorbis:\n    \nFor reference only: \nhttps://xiph.org/vorbis\n\n\ncd /apps/source/ffmpeg_sources\n\n\nwget -O /apps/source/ffmpeg_sources/libvorbis-1.3.4.tar.gz \"http://downloads.xiph.org/releases/vorbis/libvorbis-1.3.4.tar.gz\"\n\n\ntar xzvf libvorbis-1.3.4.tar.gz\n\n\ncd libvorbis-1.3.4\n\n\nLDFLAGS=\"-L/apps/install/lib\" CPPFLAGS=\"-I/apps/install/include\" ./configure --prefix=\"/apps/install\" --with-ogg=\"/apps/install\" --enable-shared\n\n\nmake\n\n\nsudo make install\n\n\nmake distclean\n\n\nsudo ldconfig\n\n\n\n\n\n\nlibtheora:\n    \nFor reference only: \nhttps://www.theora.org\n\n\ncd /apps/source/ffmpeg_sources\n\n\nwget -O /apps/source/ffmpeg_sources/libtheora-1.1.1.tar.bz2 \"http://downloads.xiph.org/releases/theora/libtheora-1.1.1.tar.bz2\"\n\n\ntar -xvjf libtheora-1.1.1.tar.bz2\n\n\ncd libtheora-1.1.1\n\n\n./configure --prefix=\"/apps/install\" --enable-shared\n\n\nmake\n\n\nsudo make install\n\n\nmake distclean\n\n\nsudo ldconfig\n\n\n\n\n\n\nFFmpeg:\n    \nFor reference only: \nhttps://ffmpeg.org\n\n\ncd /apps/source/ffmpeg_sources\n\n\ngit clone https://git.ffmpeg.org/ffmpeg.git ffmpeg\n\n\ncd ffmpeg\n\n\ngit checkout af5917698bd44f136fd0ff00a9e5f8b5f92f2d58\n\n\nPKG_CONFIG_PATH=\"/apps/install/lib/pkgconfig\" ./configure --prefix=\"/apps/install\" --extra-cflags=\"-I/apps/install/include\" --extra-ldflags=\"-L/apps/install/lib\" --bindir=\"/apps/install/bin\" --enable-gpl --enable-nonfree --enable-libtheora --enable-libfreetype --enable-libmp3lame --enable-libvorbis --enable-libx264 --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-version3 --enable-shared --disable-libsoxr --enable-avresample\n\n\nmake\n\n\nsudo make install\n\n\nmake distclean\n\n\nsudo ln -s /apps/install/bin/ffmpeg /usr/bin/ffmpeg\n\n\nsudo sh -c 'echo \"PATH=\\$PATH:/apps/install/bin\" \n /etc/profile.d/mpf.sh'\n\n\nsudo sh -c 'echo \"export CXXFLAGS=-isystem\\ /apps/install/include\" \n /etc/profile.d/mpf.sh'\n\n\n. /etc/profile.d/mpf.sh\n\n\nsudo ldconfig\n\n\n\n\n\n\n\n\n\n\nGoogle protocol buffers 2.5.0:\n    \nFor reference only: \nhttps://developers.google.com/protocol-buffers\n\n\ncd /apps/source/google_sources\n\n\nwget -O /apps/source/google_sources/protobuf-2.5.0.tar.gz \"https://github.com/google/protobuf/releases/download/v2.5.0/protobuf-2.5.0.tar.gz\"\n\n\ntar xvzf protobuf-2.5.0.tar.gz\n\n\ncd protobuf-2.5.0\n\n\n./configure --prefix=/apps/install\n\n\nmake -j8\n\n\nsudo make install\n\n\nmake distclean\n\n\nsudo ldconfig\n\n\nsudo sh -c 'echo \"export CXXFLAGS=-isystem\\ /apps/install/include\" \n /etc/profile.d/mpf.sh'\n\n\nsudo ln -s /apps/install/bin/protoc /usr/local/bin/protoc\n\n\nsudo ln -s /usr/lib64/libuuid.so.1.3.0 /usr/lib64/libuuid.so\n\n\n\n\n\n\nApr 1.5.2:\n    \nFor reference only: \nhttps://apr.apache.org\n\n\ncd /apps/source/apache_sources\n\n\nwget -O /apps/source/apache_sources/apr-1.5.2.tar.gz \"http://archive.apache.org/dist/apr/apr-1.5.2.tar.gz\"\n\n\ntar -zxvf apr-1.5.2.tar.gz\n\n\ncd /apps/source/apache_sources/apr-1.5.2\n\n\n./configure --prefix=/apps/install\n\n\nmake -j8\n\n\nsudo make install\n\n\nmake distclean\n\n\nsudo ldconfig\n\n\n\n\n\n\nApr-util 1.5.4:\n    \nFor reference only: \nhttps://apr.apache.org\n\n\ncd /apps/source/apache_sources\n\n\nwget -O /apps/source/apache_sources/apr-util-1.5.4.tar.gz \"http://archive.apache.org/dist/apr/apr-util-1.5.4.tar.gz\"\n\n\ntar -xzvf apr-util-1.5.4.tar.gz\n\n\ncd /apps/source/apache_sources/apr-util-1.5.4\n\n\n./configure --with-apr=/apps/install --prefix=/apps/install\n\n\nmake -j8\n\n\nsudo make install\n\n\nmake distclean\n\n\nsudo ldconfig\n\n\n\n\n\n\nActivemqcpp 3.9.0:\n    \nFor reference only: \nhttp://activemq.apache.org/cms\n\n\ncd /apps/source/apache_sources\n\n\nwget -O /apps/source/apache_sources/activemq-cpp-library-3.9.0-src.tar.gz \"https://archive.apache.org/dist/activemq/activemq-cpp/3.9.0/activemq-cpp-library-3.9.0-src.tar.gz\"\n\n\ntar zxvf activemq-cpp-library-3.9.0-src.tar.gz\n\n\ncd /apps/source/apache_sources/activemq-cpp-library-3.9.0\n\n\n./autogen.sh\n\n\n./configure --disable-ssl --prefix=/apps/install\n\n\nmake -j8\n\n\nsudo make install\n\n\nmake distclean\n\n\nsudo ldconfig\n\n\nsudo ln -s /apps/install/lib/libactivemq-cpp.so.19.0.0 /usr/lib/libactivemq-cpp.so\n\n\n\n\n\n\nOpenCV 3.2.0:\n    \nFor reference only: \nhttp://opencv.org\n\n\ncd /apps/source/opencv_sources\n\n\ngit clone https://github.com/opencv/opencv.git\n\n\ncd opencv\n\n\ngit checkout 26e9b42a44a62e00e0c1237f778040169162116c\n\n\ncd ..\n\n\ngit clone https://github.com/opencv/opencv_contrib.git\n\n\ncd opencv_contrib\n\n\ngit checkout 009d2efb75fbb0eded127864cb1ca932d58d1738\n\n\ncd ..\n\n\ncd opencv\n\n\nmkdir release\n\n\ncd release\n\n\nPKG_CONFIG_PATH=\"/apps/install/lib/pkgconfig\" cmake3 -D CMAKE_BUILD_TYPE=Release -D -DWITH_GSTREAMER:BOOL=\"0\" -DWITH_OPENMP:BOOL=\"1\" -DBUILD_opencv_apps:BOOL=\"0\" -DWITH_OPENCLAMDBLAS:BOOL=\"0\" -DWITH_CUDA:BOOL=\"0\" -DCLAMDFFT_ROOT_DIR:PATH=\"CLAMDFFT_ROOT_DIR-NOTFOUND\" -DBUILD_opencv_aruco:BOOL=\"0\" -DCMAKE_INSTALL_PREFIX:PATH=\"/apps/install/opencv3.2.0\" -DWITH_WEBP:BOOL=\"0\" -DBZIP2_LIBRARIES:FILEPATH=\"BZIP2_LIBRARIES-NOTFOUND\" -DWITH_GIGEAPI:BOOL=\"0\" -DOPENCV_EXTRA_MODULES_PATH:PATH=\"/apps/source/opencv_sources/opencv_contrib/modules\" -DWITH_JPEG:BOOL=\"1\" -DWITH_CUFFT:BOOL=\"0\" -DWITH_IPP:BOOL=\"0\" -DWITH_V4L:BOOL=\"1\" -DWITH_GDAL:BOOL=\"0\" -DWITH_OPENCLAMDFFT:BOOL=\"0\" -DWITH_GPHOTO2:BOOL=\"0\" -DWITH_VTK:BOOL=\"0\" -DWITH_GTK_2_X:BOOL=\"0\" -DBUILD_opencv_world:BOOL=\"0\" -DWITH_TIFF:BOOL=\"1\" -DWITH_1394:BOOL=\"0\" -DWITH_EIGEN:BOOL=\"0\" -DWITH_LIBV4L:BOOL=\"0\" -DBUILD_opencv_ts:BOOL=\"0\" -DWITH_MATLAB:BOOL=\"0\" -DWITH_OPENCL:BOOL=\"0\" -DWITH_PVAPI:BOOL=\"0\" ..\n\n\nmake -j4\n\n\nsudo make install\n\n\nsudo sh -c 'echo \"/apps/install/opencv3.2.0/lib\" \n /etc/ld.so.conf.d/mpf-x86_64.conf'\n\n\nsudo ln -sf /apps/install/opencv3.2.0 /opt/opencv-3.2.0\n\n\nsudo ln -sf /apps/install/opencv3.2.0/include/opencv2 /usr/local/include/opencv2\n\n\nsudo ln -sf /apps/install/opencv3.2.0/include/opencv /usr/local/include/opencv\n\n\nsudo ldconfig\n\n\nexport OpenCV_DIR=/opt/opencv-3.2.0/share/OpenCV\n\n\n\n\n\n\nLeptonica 1.72:\n    \nFor reference only: \nhttps://github.com/DanBloomberg/leptonica\n\n\ncd /apps/source/openalpr_sources\n\n\nwget -O /apps/source/openalpr_sources/leptonica-1.72.tar.gz \"https://github.com/DanBloomberg/leptonica/archive/v1.72.tar.gz\"\n\n\ntar xvzf leptonica-1.72.tar.gz\n\n\nsudo mkdir /usr/local/src/openalpr\n    \n\n\nsudo cp -R /apps/source/openalpr_sources/leptonica-1.72 /usr/local/src/openalpr/\n\n\nsudo chown -R mpf:mpf /usr/local/src/openalpr\n\n\nsudo chmod -R 755 /usr/local/src/openalpr\n\n\ncd /usr/local/src/openalpr/leptonica-1.72\n\n\n./configure --prefix=/usr/local\n\n\nmake --directory /usr/local/src/openalpr/leptonica-1.72 -j\n\n\nsudo make --directory /usr/local/src/openalpr/leptonica-1.72 install\n\n\nmake --directory /usr/local/src/openalpr/leptonica-1.72 distclean\n\n\nsudo ldconfig\n\n\n\n\n\n\nTesseract 3.04.00:\n    \nFor reference only: \nhttps://github.com/tesseract-ocr\n\n\ncd /apps/source/openalpr_sources\n\n\nwget -O /apps/source/openalpr_sources/tesseract-3.04.00.tar.gz \"https://github.com/tesseract-ocr/tesseract/archive/3.04.00.tar.gz\"\n\n\ntar xvzf tesseract-3.04.00.tar.gz\n\n\nwget -O /apps/source/openalpr_sources/tessdata-3.04.00.tar.gz https://github.com/tesseract-ocr/tessdata/archive/3.04.00.tar.gz\n\n\ntar xvzf tessdata-3.04.00.tar.gz\n\n\nsudo mkdir -p /usr/local/src/openalpr/tesseract-ocr\n\n\nsudo cp -a /apps/source/openalpr_sources/tessdata-3.04.00/. /usr/local/src/openalpr/tesseract-ocr/tessdata/\n\n\nsudo cp -a /apps/source/openalpr_sources/tesseract-3.04.00/. /usr/local/src/openalpr/tesseract-ocr/\n\n\nsudo chown -R mpf:mpf /usr/local/src/openalpr\n\n\nsudo chmod -R 755 /usr/local/src/openalpr\n\n\ncd /usr/local/src/openalpr/tesseract-ocr\n\n\nsh autogen.sh\n\n\n./configure\n\n\nmake --directory /usr/local/src/openalpr/tesseract-ocr -j\n\n\nsudo make --directory /usr/local/src/openalpr/tesseract-ocr install\n\n\nsudo ldconfig\n\n\n\n\n\n\nOpenALPR 2.3.0:\n    \nFor reference only: \nhttps://github.com/openalpr/openalpr\n\n\ncd /apps/source/openalpr_sources\n\n\ngit clone https://github.com/openalpr/openalpr.git\n\n\ncd openalpr\n\n\ngit checkout 469c4fd6d782ac63a55246d1073b0f88edd0d230\n\n\ncp -a /apps/source/openalpr_sources/openalpr /usr/local/src/openalpr/\n\n\nmkdir -p /usr/local/src/openalpr/openalpr/src/build\n\n\ncd /usr/local/src/openalpr/openalpr/src/build\n\n\ncmake3 -j --DCmake3 -j_INSTALL_PREFIX:PATH=/usr -D WITH_DAEMON=OFF ../\n\n\nmake --directory /usr/local/src/openalpr/openalpr/src/build -j\n\n\nsudo make --directory /usr/local/src/openalpr/openalpr/src/build install\n\n\nsudo ln -sf /usr/local/src/openalpr/openalpr /usr/share/openalpr\n\n\nsudo cp -a /usr/local/lib/libopenalpr.so /usr/lib/libopenalpr.so\n\n\nsudo cp /usr/local/lib/libopenalpr.so.2 /usr/lib/libopenalpr.so.2\n\n\nsudo sh -c 'echo \"export TESSDATA_PREFIX=/usr/local/src/openalpr/openalpr/runtime_data/ocr\" \n /etc/profile.d/mpf.sh'\n\n\nsudo ldconfig\n\n\n. /etc/profile.d/mpf.sh\n\n\n\n\n\n\ndlib:\n    \nFor reference only: \nhttp://dlib.net\n\n\ncd /apps/source\n\n\nwget -O /apps/source/config4cpp.tar.gz \"http://www.config4star.org/download/config4cpp.tar.gz\"\n\n\ntar xvzf config4cpp.tar.gz\n\n\ncd config4cpp\n\n\nmake\n\n\ncd /apps/source/dlib-sources\n\n\nwget -O /apps/source/dlib-sources/dlib-18.18.tar.bz2 \"http://dlib.net/files/dlib-18.18.tar.bz2\"\n\n\ntar xvjf dlib-18.18.tar.bz2\n\n\ncd dlib-18.18/dlib\n\n\nmkdir build\n\n\ncd build\n\n\ncmake3 ../\n\n\ncmake3 --build . --config Release\n\n\nMake sure libdlib.so and libdlib.so.18.18.0 are present in /apps/source/dlib-sources/dlib-18.18/dlib/build\n\n\nsudo make install\n\n\n\n\n\n\nAnsible:\n    \nFor reference only: \nhttps://github.com/ansible/ansible\n\n\ncd /apps/source/ansible_sources\n\n\ngit clone https://github.com/ansible/ansible.git --recursive\n\n\ncd ansible\n\n\ngit checkout e71cce777685f96223856d5e6cf506a9ea2ef3ff\n\n\ngit pull --rebase\n\n\ngit submodule update --init --recursive\n\n\ncd /apps/source/ansible_sources/ansible/lib/ansible/modules/core\n\n\ngit checkout 36f512abc1a75b01ae7207c74cdfbcb54a84be54\n\n\ncd /apps/source/ansible_sources/ansible/lib/ansible/modules/extras\n\n\ngit checkout 32338612b38d1ddfd0d42b1245c597010da02970\n\n\ncd /apps/source/ansible_sources/ansible\n\n\nmake rpm\n\n\nsudo rpm -Uvh ./rpm-build/ansible-*.noarch.rpm\n\n\n\n\n\n\n\n\nConfiguring MySQL\n\n\n\n\nsudo systemctl start mysqld\n\n\nmysql -u root --execute \"UPDATE mysql.user SET Password=PASSWORD('password') WHERE User='root';flush privileges;\"\n\n\nmysql -u root -ppassword --execute \"create database mpf\"\n\n\nmysql -u root -ppassword --execute \"create user 'mpf'@'%' IDENTIFIED by 'mpf';flush privileges;\"\n\n\nmysql -u root -ppassword --execute \"create user 'mpf'@'$(hostname)' IDENTIFIED by 'mpf';flush privileges;\"\n\n\nmysql -u root -ppassword --execute \"create user 'mpf'@'localhost' IDENTIFIED by 'mpf';flush privileges;\"\n\n\nmysql -u root -ppassword --execute \"grant all privileges on mpf.* to 'mpf';flush privileges;\"\n\n\nsudo systemctl enable mysqld.service\n\n\nsudo chkconfig --level 2345 mysqld on\n\n\n\n\nConfiguring ActiveMQ\n\n\nSome additional manual configuration of ActiveMQ is required. For each step, open the specified file in a text editor, make the change, and save the file. If ActiveMQ is running, please stop it before making these changes.\n\n\nUse Additional Memory\n\n\nIn \n/opt/activemq/bin/env\n (line 27), comment out the line:\n\n\nACTIVEMQ_OPTS_MEMORY=\n-Xms64M -Xmx1G\n\n\n\n\n\nso that it reads:\n\n\n#ACTIVEMQ_OPTS_MEMORY=\n-Xms64M -Xmx1G\n\n\n\n\n\nDisable Persistence\n\n\nIn \n/opt/activemq/conf/activemq.xml\n (line 40), change the line:\n\n\nbroker xmlns=\nhttp://activemq.apache.org/schema/core\n brokerName=\nlocalhost\n dataDirectory=\n${activemq.data}\n\n\n\n\n\nso that it reads:\n\n\nbroker xmlns=\nhttp://activemq.apache.org/schema/core\n brokerName=\nlocalhost\n dataDirectory=\n${activemq.data}\n persistent=\nfalse\n\n\n\n\n\nRespect Priorities\n\n\nIn \n/opt/activemq/conf/activemq.xml\n (line 44) under the line:\n\n\npolicyEntries\n\n\n\n\n\nadd the line:\n\n\npolicyEntry queue=\n prioritizedMessages=\ntrue\n useCache=\nfalse\n expireMessagesPeriod=\n0\n queuePrefetch=\n1\n /\n\n\n\n\n\nEnable JMX\n\n\nIn \n/opt/activemq/conf/activemq.xml\n (line 71), change the line:\n\n\nmanagementContext createConnector=\nfalse\n/\n\n\n\n\n\nso that it reads:\n\n\nmanagementContext createConnector=\ntrue\n/\n\n\n\n\n\nChange Log Conversion Pattern\n\n\nIn \n/opt/activemq/conf/log4j.properties\n (line 52), change the line:\n\n\nlog4j.appender.logfile.layout.ConversionPattern=%d | %-5p | %m | %c | %t%n\n\n\n\n\nso that it reads:\n\n\nlog4j.appender.logfile.layout.ConversionPattern=%d %p [%t] %c - %m%n\n\n\n\n\nConfiguring Redis\n\n\nRedis should be set to run in the background (i.e. as a daemon process).\n\n\nIn \n/etc/redis.conf\n (line 128), change the line:\n\n\ndaemonize no\n\n\n\n\nso that it reads:\n\n\ndaemonize yes\n\n\n\n\nHTTPS Configuration\n\n\nGenerate a self-signed certificate and keystore\n\n\n\n\nNOTE:\n  A valid keystore is required to run the OpenMPF with HTTPS support. These instructions will generate a keystore that should be used for local builds only. When deploying OpenMPF, a keystore containing a valid certificate trust chain should be used.\n\n\n\n\n\n\nOpen a new terminal window.\n\n\nsudo systemctl stop tomcat7\n\n\ncd /home/mpf\n\n\n$JAVA_HOME/bin/keytool -genkey -alias tomcat -keyalg RSA\n\n\nAt the prompt, enter a keystore password of: \nmpf123\n\n\nRe-enter the keystore password of: \nmpf123\n\n\nAt the \nWhat is your first and last name?\n prompt, press the Enter key for a blank value.\n\n\nAt the \nWhat is the name of your organizational unit?\n , press the Enter key for a blank value.\n\n\nAt the \nWhat is the name of your organization?\n prompt, press the Enter key for a blank value.\n\n\nAt the \nWhat is the name of your City or Locality?\n prompt, press the Enter key for a blank value.\n\n\nAt the \nWhat is the name of your State or Province?\n prompt, press the Enter key for a blank value.\n\n\nAt the \nWhat is the two-letter country code for this unit?\n prompt, press the Enter key for a blank value.\n\n\nAt the \nIs CN=Unknown, OU=Unknown, O=Unknown, L=Unknown, ST=Unknown, C=Unknown correct?\n prompt, type \nyes\n and press the Enter key to accept the values.\n\n\nAt the \nEnter key password for \ntomcat\n prompt, press the Enter key for a blank value.\n\n\nVerify the file \n/home/mpf/.keystore\n was created at the current time.\n\n\n\n\nTomcat Configuration\n\n\n\n\nOpen the file \n/opt/apache-tomcat/conf/server.xml\n in a text editor.\n\n\nBelow the commented out section on lines 87 through 90, add the following lines:\n\nConnector SSLEnabled=\"true\" acceptCount=\"100\" clientAuth=\"false\"\n    disableUploadTimeout=\"true\" enableLookups=\"false\" maxThreads=\"25\"\n    port=\"8443\" keystoreFile=\"/home/mpf/.keystore\" keystorePass=\"mpf123\"\n    protocol=\"org.apache.coyote.http11.Http11NioProtocol\" scheme=\"https\"\n    secure=\"true\" sslProtocol=\"TLS\" /\n\n\nSave and close the file.\n\n\nCreate the file \n/opt/apache-tomcat/bin/setenv.sh\n and open it in a text editor.\n\n\nAdd the following line:\n\nexport CATALINA_OPTS=\"-server -Xms256m -XX:PermSize=512m -XX:MaxPermSize=512m -Djgroups.tcp.port=7800 -Djava.library.path=$LD_LIBRARY_PATH -Djgroups.tcpping.initial_hosts='$ALL_MPF_NODES' -Dtransport.guarantee='CONFIDENTIAL' -Dweb.rest.protocol='https'\"\n\n\nSave and close the file.\n\n\n\n\nUsing an IDE\n\n\nIf running Tomcat from an IDE, such as IntelliJ, then \n-Dtransport.guarantee=\"CONFIDENTIAL\" -Dweb.rest.protocol=\"https\"\n should be added at the end of the Tomcat VM arguments for your Tomcat run configuration. It is not necessary to add these arguments when running tomcat from the command line or a systemd command because of configured \nCATALINA_OPTS\n variable.\n\n\n(Optional) HTTP Configuration\n\n\nThe OpenMPF can also be run using HTTP instead of HTTPS.\n\n\n\n\nOpen the file \n/opt/apache-tomcat/conf/server.xml\n in a text editor.\n\n\nBelow the commented out section on lines 87 through 90, remove the following lines if they exist:\n\nConnector SSLEnabled=\"true\" acceptCount=\"100\" clientAuth=\"false\"\n    disableUploadTimeout=\"true\" enableLookups=\"false\" maxThreads=\"25\"\n    port=\"8443\" keystoreFile=\"/home/mpf/.keystore\" keystorePass=\"mpf123\"\n    protocol=\"org.apache.coyote.http11.Http11NioProtocol\" scheme=\"https\"\n    secure=\"true\" sslProtocol=\"TLS\" /\n\n\nSave and close the file.\n\n\nCreate the file \n/opt/apache-tomcat/bin/setenv.sh\n and open it in a text editor.\n\n\nAdd the following line:\n\nexport CATALINA_OPTS=\"-server -Xms256m -XX:PermSize=512m -XX:MaxPermSize=512m -Djgroups.tcp.port=7800 -Djava.library.path=$LD_LIBRARY_PATH -Djgroups.tcpping.initial_hosts='$ALL_MPF_NODES' -Dtransport.guarantee='NONE' -Dweb.rest.protocol='http'\"\n\n\nSave and close the file.\n\n\n\n\nAdding Additional Maven Dependencies\n\n\nSome Maven dependencies needed for the OpenMPF were not publicly available at the time this guide was written. These have been provided with the the OpenMPF source code located here \nhttps://github.com/openmpf/openmpf-build-tools/blob/master/mpf-maven-deps.tar.gz\n. These steps assume the archive \nmpf-maven-deps.tar.gz\n is at \n/home/mpf/openmpf-projects/openmpf-build-tools/mpf-maven-deps.tar.gz\n.\n\n\n\n\nSet up the local Maven repository:\n\n\ncd /home/mpf\n\n\nmkdir -p .m2/repository\n\n\n\n\n\n\nExtract the archive to the local Maven repository:\n\ntar xvzf /home/mpf/openmpf-projects/openmpf-build-tools/mpf-maven-deps.tar.gz -C /home/mpf/.m2/repository/\n\n\n\n\nBuilding and Packaging the OpenMPF\n\n\nThe OpenMPF uses Apache Maven to automate software builds. The \nmvn\n commands in this guide are assumed to be run at the command line.\n\n\nBuild Environment\n\n\nThe OpenMPF packaging script makes use of a directory /mpfdata with the following structure:\n\n\n  mpfdata - the top level directory containing the structure and non-source code artifacts to be packaged for distribution.\n  \u251c\u2500\u2500 ansible\n  \u2502   \u2514\u2500\u2500 install\n  \u2502       \u2514\u2500\u2500 repo\n  \u2502           \u251c\u2500\u2500 files - Any other uncategorized files needed by the OpenMPF.\n  \u2502           \u251c\u2500\u2500 pip - Dependency packages needed for the OpenMPF administration scripts. Installed with Python pip during deployment.\n  \u2502           \u251c\u2500\u2500 rpms - Contains all of the RPM packages needed for installing and running the OpenMPF. Installed with the yum package manager during deployment.\n  \u2502           \u2502   \u251c\u2500\u2500 management - RPM  packages needed for the OpenMPF deployment process.\n  \u2502           \u2502   \u251c\u2500\u2500 mpf - The OpenMPF RPM packages.\n  \u2502           \u2502   \u2514\u2500\u2500 mpf-deps - RPM packages needed by the OpenMPF.\n  \u2502           \u2514\u2500\u2500 tars - Binary packages in tar archives needed by the OpenMPF.\n  \u2514\u2500\u2500 releases - Contains the release package(s) that will be built.\n\n\n\n\nCreate the build environment structure:\n\n\n\n\nsudo mkdir -p /mpfdata/ansible/install/repo/rpms/management\n\n\nsudo mkdir /mpfdata/ansible/install/repo/rpms/mpf\n\n\nsudo mkdir /mpfdata/ansible/install/repo/rpms/mpf-deps\n\n\nsudo mkdir /mpfdata/ansible/install/repo/files\n\n\nsudo mkdir /mpfdata/ansible/install/repo/pip\n\n\nsudo mkdir /mpfdata/ansible/install/repo/tars\n\n\nsudo mkdir /mpfdata/releases\n\n\nsudo chown -R mpf:mpf /mpfdata\n\n\n\n\nThird-party RPMs, Tars, and Python Pip packages included with an OpenMPF Package\n\n\nAs with the OpenMPF Build VM, the OpenMPF deployment package is targeted for a minimal install of CentOS 7. The \nPackage Lists\n section lists required third-party dependencies that are packaged with the OpenMPF installation files by the \nCreateCustomPackage.pl\n script. Depending on which dependencies are already installed on your target system(s), some or all of these dependencies may not be needed. The script will only add the dependencies present in the \n/mpfdata/ansible/install/repo/\n directory to the package.\n\n\nThe following commands can be used to populate the dependency packages into the \n/mpfdata/ansible/install/repo\n directory:\n\n\n\n\nyumdownloader --exclude=*.i?86 --archlist=x86_64 adwaita-cursor-theme adwaita-icon-theme at-spi2-atk at-spi2-core cairo-gobject colord-libs createrepo deltarpm ebtables gcc glibc glibc-common glibc-devel glibc-headers gtk3 httpd httpd-tools json-glib kernel-headers lcms2 libffi-devel libgusb libmng libselinux-python libtomcrypt libtommath libXevie libxml2 libxml2-python libXtst libyaml mailcap mpfr openssh openssh-askpass openssh-clients openssh-server pciutils py-bcrypt python python2-crypto python-babel python-backports python-backports-ssl_match_hostname python-cffi python-chardet python-crypto python-deltarpm python-devel python-ecdsa python-httplib2 python-jinja2 python-keyczar python-kitchen python-libs python-markupsafe python-paramiko python-passlib python-pip python-ply python-ptyprocess python-pyasn1 python-pycparser python-setuptools python-simplejson python-six python-slip python-slip-dbus PyYAML qt qt-settings qt-x11 rest sshpass yum-utils --destdir /mpfdata/ansible/install/repo/rpms/management -C\n\n\nyumdownloader --exclude=*.i?86 --archlist=x86_64 apr apr-util apr-util-ldap atk avahi-libs cairo cdparanoia-libs cpp cups-libs fontconfig fontpackages-filesystem gdk-pixbuf2 graphite2 gsm gstreamer gstreamer1 gstreamer1-plugins-base gstreamer-plugins-base gstreamer-tools gtk2 gtk3 harfbuzz hicolor-icon-theme iso-codes jasper-libs jbigkit-libs jemalloc libdc1394 libICE libjpeg-turbo libmng libmpc libogg libpng libraw1394 libSM libthai libtheora libtiff libusbx libv4l libvisual libvorbis libvpx libX11 libX11-common libXau libxcb libXcomposite libXcursor libXdamage libXext libXfixes libXft libXi libXinerama libxml2 libXrandr libXrender libxshmfence libXv libXxf86vm log4cxx mesa-libEGL mesa-libgbm mesa-libGL mesa-libglapi mesa-libGLU mysql-community-client mysql-community-common mysql-community-libs mysql-community-server mysql-connector-python MySQL-python net-tools openjpeg-libs openssh openssh-clients openssh-server opus orc pango perl perl-Carp perl-Compress-Raw-Bzip2 perl-Compress-Raw-Zlib perl-constant perl-Data-Dumper perl-DBD-MySQL perl-DBI perl-Encode perl-Exporter perl-File-Path perl-File-Temp perl-Filter perl-Getopt-Long perl-HTTP-Tiny perl-IO-Compress perl-libs perl-macros perl-Net-Daemon perl-parent perl-PathTools perl-PlRPC perl-Pod-Escapes perl-podlators perl-Pod-Perldoc perl-Pod-Simple perl-Pod-Usage perl-Scalar-List-Utils perl-Socket perl-Storable perl-Text-ParseWords perl-threads perl-threads-shared perl-Time-HiRes perl-Time-Local pixman redis SDL speex unzip xml-common --destdir /mpfdata/ansible/install/repo/rpms/mpf-deps -C\n\n\ncp /apps/source/ansible_sources/ansible/rpm-build/ansible-*.noarch.rpm /mpfdata/ansible/install/repo/rpms/management/\n\n\nwget --no-cookies --header \"Cookie: oraclelicense=accept-securebackup-cookie\" \"http://download.oracle.com/otn-pub/java/jdk/8u60-b27/jdk-8u60-linux-x64.rpm\" -O /mpfdata/ansible/install/repo/rpms/mpf-deps/jdk-8u60-linux-x64.rpm\n\n\nNOTE:\n Oracle may require an account to download archived versions of the JRE.\n\n\n\n\n\n\nDownload jre-8u60-linux-x64.rpm and place it in \n/mpfdata/ansible/install/repo/rpms/mpf-deps\n : \nhttp://www.oracle.com/technetwork/java/javase/downloads/java-archive-javase8-2177648.html#jre-8u60-oth-JPR\n\n\nwget -O /mpfdata/ansible/install/repo/tars/apache-activemq-5.13.0-bin.tar.gz \"https://archive.apache.org/dist/activemq/5.13.0/apache-activemq-5.13.0-bin.tar.gz\"\n\n\nwget -O /mpfdata/ansible/install/repo/tars/apache-tomcat-7.0.72.tar.gz \"http://archive.apache.org/dist/tomcat/tomcat-7/v7.0.72/bin/apache-tomcat-7.0.72.tar.gz\"\n\n\ncd /mpfdata/ansible/install/repo/pip\n\n\npip install --download . argcomplete argh bcrypt cffi pycparser PyMySQL six\n\n\n\n\nBuild the Open Source OpenMPF Package\n\n\nFollow the instructions in the \nBuild the OpenMPF Package\n section below. Use the following value for \nconfigFile\n:\n\n/home/mpf/openmpf-projects/openmpf/trunk/jenkins/scripts/config_files/mpf-open-source-package.json\n\n\nBuild the OpenMPF Package\n\n\n\n\nNOTE:\n If your build environment is behind a proxy server, please read the appendix section \nProxy Configuration\n for instructions to configure Maven before continuing.\n\n\n\n\nIn the instructions below, provide a positive integer value for \nbuildNum\n. If this is your first build, provide a \"1\". If this is your second build then provide a \"2\", so on and so forth. The build number will be displayed on the login screen.\n\n\n\n\n\n\nRemove the development properties file:\n\n\n\n\ncd /home/mpf/openmpf-projects/openmpf\n\n\nrm -f trunk/workflow-manager/src/main/resources/properties/mpf-private.properties\n\n\n\n\n\n\n\n\n(Optional) run maven clean if there has been a previous software build:\n    \n \nmvn clean\n\n\n\n\nRun the Perl \nPackageRPMS.pl\n script. This will compile the code artifacts, place them in the local maven repository, and create the necessary component RPMs and tar files.\n\n\ncd /home/mpf/openmpf-projects/openmpf/trunk/jenkins/scripts\n\n\nperl PackageRPMS.pl /home/mpf/openmpf-projects/openmpf master 0 \nbuildNum\n \nconfigFile\n\n\n\n\n\n\nAfter the build is complete, the final package is created by running the Perl script \nCreateCustomPackage.pl\n:\n\n\ncd /home/mpf/openmpf-projects/openmpf/trunk/jenkins/scripts\n\n\nperl CreateCustomPackage.pl /home/mpf/openmpf-projects/openmpf master \nbuildNum\n \nconfigFile\n\n\n\n\n\n\nThe package \nopenmpf-*+master-0.tar.gz\n will be under \n/mpfdata/releases/\n.\n\n\n(Optional) Copy the development properties file back if you wish to run the OpenMPF on the OpenMPF Build VM:\n\ncp /home/mpf/openmpf-projects/openmpf/trunk/workflow-manager/src/main/resources/properties/mpf-private-example.properties /home/mpf/openmpf-projects/openmpf/trunk/workflow-manager/src/main/resources/properties/mpf-private.properties\n\n\n\n\n(Optional) Testing the OpenMPF\n\n\n\n\nNOTE:\n If your build environment is behind a proxy server, please read the appendix section \nProxy Configuration\n for instructions to configure Firefox before continuing.\n\n\n\n\nRun these commands to build the OpenMPF and run the integration tests:\n\n\n\n\ncd /home/mpf/openmpf-projects/openmpf\n\n\n\n\nCopy the development properties file into place:\n\n\ncp trunk/workflow-manager/src/main/resources/properties/mpf-private-example.properties trunk/workflow-manager/src/main/resources/properties/mpf-private.properties\n\n\n\n\n\n\nOpen the file \n/etc/ansible/hosts\n in a text editor. \nsudo\n is required to edit this file.\n\n\n\n\n\n\nIf they do not already exist, add these two lines above \n# Ex 1: Ungrouped hosts, specify before any group headers.\n (line 11):\n\n\n[mpf-child]\nlocalhost.localdomain\n\n\n\n\n\n\nSave and close the file.\n\n\n\n\nmvn clean install -DskipTests -Dmaven.test.skip=true -DskipITs -Dmaven.tomcat.skip=true -Dcomponents.build.package.json=\nconfigFile\n -Dcomponents.build.dir=/home/mpf/openmpf-projects/openmpf/mpf-component-build -Dstartup.auto.registration.skip=false\n\n\nsudo cp /home/mpf/openmpf-projects/openmpf/trunk/install/libexec/node-manager /etc/init.d/\n\n\nsudo systemctl daemon-reload\n\n\nmpf start --xtc\n (This command will start ActiveMQ, MySQL, Redis, and node-manager; not Tomcat.)\n\n\nmvn verify -Dtransport.guarantee=\"NONE\" -Dweb.rest.protocol=\"http\" -Dcomponents.build.package.json=\nconfigFile\n -Dstartup.auto.registration.skip=false -Dcomponents.build.dir=/home/mpf/openmpf-projects/openmpf/mpf-component-build\n\n\nmpf stop --xtc\n (This command will stop node-manager, Redis, MySQL, and ActiveMQ; not Tomcat.)\n\n\n\n\n\n\nNOTE:\n Please see the appendix section \nKnown Issues\n regarding any \njava.lang.InterruptedException: null\n warning log messages observed when running the tests.\n\n\n\n\n(Optional) Building and running the web application\n\n\n\n\nNOTE:\n If your build environment is behind a proxy server, please read the appendix section \nProxy Configuration\n for instructions to configure Firefox before continuing.\n\n\n\n\nRun these commands to build the OpenMPF and launch the web application:\n\n\n\n\ncd /home/mpf/openmpf-projects/openmpf\n\n\n\n\nCopy the development properties file into place:\n\n\ncp trunk/workflow-manager/src/main/resources/properties/mpf-private-example.properties trunk/workflow-manager/src/main/resources/properties/mpf-private.properties\n\n\n\n\n\n\nOpen the file \n/etc/ansible/hosts\n in a text editor. \nsudo\n is required to edit this file.\n\n\n\n\n\n\nIf they do not already exist, add these two lines above \n# Ex 1: Ungrouped hosts, specify before any group headers.\n (line 11):\n\n\n[mpf-child]\nlocalhost.localdomain\n\n\n\n\n\n\nSave and close the file.\n\n\n\n\nmvn clean install -DskipTests -Dmaven.test.skip=true -DskipITs -Dmaven.tomcat.skip=true  -Dcomponents.build.package.json=\nconfigFile\n -Dstartup.auto.registration.skip=false -Dcomponents.build.dir=/home/mpf/openmpf-projects/openmpf/mpf-component-build\n\n\ncd /home/mpf/openmpf-projects/openmpf/trunk/workflow-manager\n\n\nrm -rf /opt/apache-tomcat/webapps/workflow-manager*\n\n\ncp target/workflow-manager.war /opt/apache-tomcat/webapps/workflow-manager.war\n\n\ncd ../..\n\n\nsudo cp trunk/install/libexec/node-manager /etc/init.d/\n\n\nsudo systemctl daemon-reload\n\n\nmpf start\n\n\n\n\nThe web application should start running in the background as a daemon. Look for this log message in the Tomcat log (\n/opt/apache-tomcat/logs/catalina.out\n) with a time value indicating the workflow-manager has finished starting:\n\n\nINFO: Server startup in 39030 ms\n\n\n\n\nAfter startup, the workflow-manager will be available at \nhttp://localhost:8080/workflow-manager\n. Connect to this URL with FireFox. Chrome is also supported, but is not pre-installed on the VM.\n\n\nIf you want to test regular user capabilities, log in as 'mpf'. Please see the \nOpenMPF User Guide\n for more information. Alternatively, if you want to test admin capabilities then log in as 'admin'. Please see the \nOpenMPF Admin Manual\n for more information. When finished testing using the browser (or other external clients), go back to the terminal window used to launch Tomcat and enter the stop command \nmpf stop\n.\n\n\n\n\nNOTE:\n Through the use of port forwarding, the workflow-manager can also be accessed from your guest operating system. Please see the Virtual Box documentation \nhttps://www.virtualbox.org/manual/ch06.html#natforward\n for configuring port forwarding.\n\n\n\n\nThe preferred method to start and stop services for OpenMPF is with the \nmpf start\n and \nmpf stop\n commands. For additional information on these commands, please see the \nCommand Line Tools\n section of the \nOpenMPF Admin Manual\n. These will start and stop ActiveMQ, MySQL, Redis, node-manager, and Tomcat, respectively. Alternatively, to perform these actions manually, the following commands can be used in a terminal window:\n\n\nStarting\n\n\n/opt/activemq/bin/activemq start\nsudo systemctl start mysqld\nsudo redis-server /etc/redis.conf\nsudo systemctl start node-manager\n/opt/apache-tomcat/bin/catalina.sh run\n\n\n\n\nStopping\n\n\n/opt/apache-tomcat/bin/catalina.sh run\n# Wait 60 seconds for tomcat to stop.\nsudo systemctl stop node-manager\nredis-cli flushall\nredis-cli shutdown\nsudo systemctl stop mysqld\n/opt/activemq/bin/activemq stop\n\n\n\n\n\n\nNOTE:\n For debugging purposes, it may be helpful to manually start the Tomcat service in a separate terminal window. This will display the log output directly to the terminal. Wait at least one minute for Tomcat to exit and the node manager to perform some cleanup tasks. If the node manager is stopped too early after quitting Tomcat, some of the processes it was responsible for launching may continue to run.\n\n\n\n\nDefault Credentials\n\n\n\n\nRegular User\n\n\nusername:\n mpf\n\n\npassword:\n mpf123\n\n\n\n\n\n\nAdministrator\n\n\nusername:\n admin\n\n\npassword:\n mpfadm\n\n\n\n\n\n\n\n\nDeploying the OpenMPF\n\n\nPlease see the \nOpenMPF Installation Guide\n.\n\n\n\n\nAppendices\n\n\nKnown Issues\n\n\nThe following are known issues that are related to setting up and running the OpenMPF on a build VM. For a more complete list of known issues, please see the OpenMPF Release Notes.\n\n\nTest Exceptions\n\n\nWhen running the tests, you may observe warning log messages similar to this:\n\n\n//2016-07-25 16:16:27,848 WARN [Time-limited test] org.mitre.mpf.mst.TestSystem - Exception occurred while waiting. Assuming that the job has completed (but failed)\njava.lang.InterruptedException: null\n    at java.lang.Object.wait(Native Method) ~[na:1.8.0_60]\n    at java.lang.Object.wait(Object.java:502) ~[na:1.8.0_60]\n    at org.mitre.mpf.mst.TestSystem.waitFor(TestSystem.java:209) [test-classes/:na]\n    at org.mitre.mpf.mst.TestSystem.runPipelineOnMedia(TestSystem.java:201) [test-classes/:na]\n    at org.mitre.mpf.mst.TestSystemOnDiff.runSpeechSphinxDetectAudio(TestSystemOnDiff.java:250) [test-classes/:na]\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_60]\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_60]\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_60]\n    at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_60]\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) [junit-4.12.jar:4.12]\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.12.jar:4.12]\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) [junit-4.12.jar:4.12]\n    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.12.jar:4.12]\n    at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:75) [spring-test-4.2.5.RELEASE.jar:4.2.5.RELEASE]\n    at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:86) [spring-test-4.2.5.RELEASE.jar:4.2.5.RELEASE]\n    at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:84) [spring-test-4.2.5.RELEASE.jar:4.2.5.RELEASE]\n    at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298) [junit-4.12.jar:4.12]\n    at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292) [junit-4.12.jar:4.12]\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_60]\n    at java.lang.Thread.run(Thread.java:745) [na:1.8.0_60]//\n\n\n\n\nThis does not necessarily indicate any type of software bug. The most likely cause for this message is that a test has timed out. Increasing the available system resources or increasing the test timeout values may help.\n\n\nTime Differences Between OpenMPF Nodes\n\n\nWhen installing OpenMPF on multiple nodes, an NTP service should be set up on each of the systems in the cluster so that their times are synchronized. Otherwise, the log viewer may behave incorrectly when it updates in real time.\n\n\nProxy Configuration\n\n\nYum Package Manager Proxy Configuration\n\n\nBefore using the yum package manager,  it may be necessary to configure it to work with your environment's proxy settings. If credentials are not required, it is not necessary to add them to the yum configuration.\n\n\n\n\nsudo bash -c 'echo \"proxy=\naddress\n:\nport\n\" \n /etc/yum.conf'\n\n\nsudo bash -c 'echo \"proxy_username=\nusername\n\" \n /etc/yum.conf'\n\n\nsudo bash -c 'echo \"proxy_password=\npassword\n\" \n /etc/yum.conf'\n\n\n\n\nProxy Environment Variables\n\n\nIf your build environment is behind a proxy server, some applications and tools will need to be configured to use it. To configure an HTTP and HTTPS proxy, run the following commands. If credentials are not required, leave those fields blank.\n\n\n\n\nsudo bash -c 'echo \"export http_proxy=\nusername\n:\npassword\n@\nurl\n:\nport\n\" \n /etc/profile.d/mpf.sh\n\n\n. /etc/profile.d/mpf.sh\n\n\nsudo bash -c 'echo \"export https_proxy='${http_proxy}'\" \n /etc/profile.d/mpf.sh'\n\n\nsudo bash -c 'echo \"export HTTP_PROXY='${http_proxy}'\" \n /etc/profile.d/mpf.sh'\n\n\nsudo bash -c 'echo \"export HTTPS_PROXY='${http_proxy}'\" \n /etc/profile.d/mpf.sh'\n\n\n. /etc/profile.d/mpf.sh\n\n\n\n\nGit Proxy Configuration\n\n\nIf your build environment is behind a proxy server, git will need to be configured to use it. The following command will set the git global proxy. If the environment variable \n$http_proxy\n is not set, use the full proxy server address, port, and credentials (if needed).\n   \n \ngit config --global http.proxy $http_proxy\n\n\nFirefox Proxy Configuration\n\n\nBefore running the integration tests and the web application, it may be necessary to configure Firefox with your environment's proxy settings.\n\n\n\n\nIn a new terminal window, type \nfirefox\n and press enter. This will launch a new Firefox window.\n\n\nIn the new Firefox window, enter \nabout:preferences#advanced\n in the URL text box and press enter.\n\n\nIn the left sidebar click 'Advanced', then click the \nNetwork\n tab, and in the \nConnection\n section press the 'Settings...' button.\n\n\nEnter the proxy settings for your environment.\n\n\nIn the 'No Proxy for:' text box, verify that \nlocalhost\n is included.\n\n\nPress the 'OK' button.\n\n\nClose all open Firefox instances.\n\n\n\n\nMaven Proxy Configuration\n\n\nBefore using Maven, it may be necessary to configure it to work with your environment's proxy settings. Open a new terminal window and run these commands. Afterwards, continue with adding the additional maven dependencies.\n\n\n\n\ncd /home/mpf\n\n\nmkdir -p .m2\n\n\ncp /opt/apache-maven/conf/settings.xml .m2/\n\n\nOpen the file \n.m2/settings.xml\n in a text editor.\n\n\nNavigate to the \nproxies\n section (line 85).\n\n\nThere is a commented-out example proxy server specification. Copy and paste the example specification below the commented-out section, but before the end of the closing \n/proxies\n tag.\n\n\nFill in your environment's proxy server information. For additional help and information, please see the Apache Maven guide to configuring a proxy server at \nhttps://maven.apache.org/guides/mini/guide-proxies.html\n.\n\n\n\n\nSSL Inspection\n\n\nIf your build environment is behind a proxy server that performs SSL inspection, some applications and tools will need to be configured to accommodate it. The following steps will add trusted certificates to the OpenMPF VM.\n\n\nAdditional information on Java keytool can be found at \nhttps://docs.oracle.com/javase/8/docs/technotes/tools/unix/keytool.html\n.\n\n\n\n\nDownload any certificates needed for using SSL in your build environment to \n/home/mpf/Downloads\n.\n\n\nVerify that \n$JAVA_HOME\n is set correctly.\n    \n Running this command: \necho $JAVA_HOME\n should produce this output: \n/usr/java/latest\n\n\nFor each certificate, run this command, filling in the values for certificate alias, certificate name, and keystore passphrase:\n    \n \nsudo $JAVA_HOME/bin/keytool -import -alias \ncertificate alias\n -file /home/mpf/Downloads/\ncertificate name\n.crt -keystore \"$JAVA_HOME/jre/lib/security/cacerts\" -storepass \nkeystore passphrase\n -noprompt\n\n\nFor each certificate, run this command, filling in the value for certificate name:\n    \n \nsudo cp /home/mpf/Downloads/\ncertificate name\n.crt /tmp\n\n\nFor each certificate, run this command, filling in the values for certificate name:\n    \n \nsudo -u root -H sh -c \"openssl x509 -in /tmp/\ncertificate name\n.crt    -text \n /etc/pki/ca-trust/source/anchors/\ncertificate name\n.pem\"\n\n\nRun these commands once:\n\n\nsudo -u root -H sh -c \"update-ca-trust enable\"\n\n\nsudo -u root -H sh -c \"update-ca-trust extract\"\n\n\n\n\n\n\nRun these commands once, filling in the value for the root certificate name:\n\n\nsudo cp /etc/pki/tls/certs/ca-bundle.crt /etc/pki/tls/certs/ca-bundle.crt.original\n\n\nsudo -u root -H sh -c \"cat /etc/pki/ca-trust/source/anchors/\nroot certificate name\n.pem \n /etc/pki/tls/certs/ca-bundle.crt\"\n\n\n\n\n\n\n\n\nAlternatively, if adding certificates is not an option or difficulties are encountered, you may optionally skip SSL certificate verification for these tools. This is not recommended:\n\n\nwget\n\n\n\n\ncd /home/mpf\n\n\ntouch /home/mpf/.wgetrc\n\n\nIn a text editor, open the file \n/home/mpf/.wgetrc\n\n\n\n\nAdd this line:\n\n\ncheck_certificate=off\n\n\n\n\n\n\nSave and close the file.\n\n\n\n\n. /home/mpf/.wgetrc\n\n\n\n\ngit\n\n\n\n\ncd /home/mpf\n\n\ngit config http.sslVerify false\n\n\ngit config --global http.sslVerify false\n\n\n\n\nmaven\n\n\n\n\nIn a text editor, open the file \n/etc/profile.d/mpf.sh\n\n\nAt the bottom of the file, add this line:\n\nexport MAVEN_OPTS=\"-Dmaven.wagon.http.ssl.insecure=true -Dmaven.wagon.http.ssl.allowall=true -Dmaven.wagon.http.ssl.ignore.validity.dates=true\"\n\n\nSave and close the file.\n\n\n. /etc/profile.d/mpf.sh\n\n\n\n\nPackage Lists\n\n\n\n\n\n\n/mpfdata/ansible/install/repo/rpms/management\n\n\n\n\nadwaita-cursor-theme-3.14.1-1.el7.noarch.rpm\n\n\nadwaita-icon-theme-3.14.1-1.el7.noarch.rpm\n\n\nansible-2.1.1.0-0.git201608081816.e71cce7.HEAD.el7.centos.noarch.rpm\n\n\nat-spi2-atk-2.14.1-1.el7.x86_64.rpm\n\n\nat-spi2-core-2.14.1-2.el7.x86_64.rpm\n\n\ncairo-gobject-1.14.2-1.el7.x86_64.rpm\n\n\ncolord-libs-1.2.7-2.el7.x86_64.rpm\n\n\ncreaterepo-0.9.9-26.el7.noarch.rpm\n\n\ndeltarpm-3.6-3.el7.x86_64.rpm\n\n\nebtables-2.0.10-15.el7.x86_64.rpm\n\n\ngcc-4.8.5-11.el7.x86_64.rpm\n\n\nglibc-2.17-157.el7_3.1.x86_64.rpm\n\n\nglibc-common-2.17-157.el7_3.1.x86_64.rpm\n\n\nglibc-devel-2.17-157.el7_3.1.x86_64.rpm\n\n\nglibc-headers-2.17-157.el7_3.1.x86_64.rpm\n\n\ngtk3-3.14.13-20.el7.x86_64.rpm\n\n\nhttpd-2.4.6-45.el7.centos.4.x86_64.rpm\n\n\nhttpd-tools-2.4.6-45.el7.centos.4.x86_64.rpm\n\n\njson-glib-1.0.2-1.el7.x86_64.rpm\n\n\nkernel-headers-3.10.0-514.16.1.el7.x86_64.rpm\n\n\nlcms2-2.6-3.el7.x86_64.rpm\n\n\nlibffi-devel-3.0.13-18.el7.x86_64.rpm\n\n\nlibgusb-0.1.6-3.el7.x86_64.rpm\n\n\nlibmng-1.0.10-14.el7.x86_64.rpm\n\n\nlibselinux-python-2.5-6.el7.x86_64.rpm\n\n\nlibtomcrypt-1.17-23.el7.x86_64.rpm\n\n\nlibtommath-0.42.0-4.el7.x86_64.rpm\n\n\nlibXevie-1.0.3-7.1.el7.x86_64.rpm\n\n\nlibxml2-2.9.1-6.el7_2.3.x86_64.rpm\n\n\nlibxml2-python-2.9.1-6.el7_2.3.x86_64.rpm\n\n\nlibXtst-1.2.2-2.1.el7.x86_64.rpm\n\n\nlibyaml-0.1.4-11.el7_0.x86_64.rpm\n\n\nmailcap-2.1.41-2.el7.noarch.rpm\n\n\nmpfr-3.1.1-4.el7.x86_64.rpm\n\n\nopenssh-6.6.1p1-35.el7_3.x86_64.rpm\n\n\nopenssh-askpass-6.6.1p1-35.el7_3.x86_64.rpm\n\n\nopenssh-clients-6.6.1p1-35.el7_3.x86_64.rpm\n\n\nopenssh-server-6.6.1p1-35.el7_3.x86_64.rpm\n\n\npciutils-3.5.1-1.el7.x86_64.rpm\n\n\npy-bcrypt-0.4-4.el7.x86_64.rpm\n\n\npython-2.7.5-48.el7.x86_64.rpm\n\n\npython2-crypto-2.6.1-13.el7.x86_64.rpm\n\n\npython2-pip-8.1.2-5.el7.noarch.rpm\n\n\npython2-ptyprocess-0.5.1-6.el7.noarch.rpm\n\n\npython2-pyasn1-0.1.9-7.el7.noarch.rpm\n\n\npython2-simplejson-3.10.0-1.el7.x86_64.rpm\n\n\npython-babel-0.9.6-8.el7.noarch.rpm\n\n\npython-backports-1.0-8.el7.x86_64.rpm\n\n\npython-backports-ssl_match_hostname-3.4.0.2-4.el7.noarch.rpm\n\n\npython-cffi-1.6.0-5.el7.x86_64.rpm\n\n\npython-chardet-2.2.1-1.el7_1.noarch.rpm\n\n\npython-crypto-2.6.1-1.el7.centos.x86_64.rpm\n\n\npython-deltarpm-3.6-3.el7.x86_64.rpm\n\n\npython-devel-2.7.5-48.el7.x86_64.rpm\n\n\npython-ecdsa-0.11-3.el7.centos.noarch.rpm\n\n\npython-httplib2-0.7.7-3.el7.noarch.rpm\n\n\npython-jinja2-2.7.2-2.el7.noarch.rpm\n\n\npython-keyczar-0.71c-2.el7.noarch.rpm\n\n\npython-kitchen-1.1.1-5.el7.noarch.rpm\n\n\npython-libs-2.7.5-48.el7.x86_64.rpm\n\n\npython-markupsafe-0.11-10.el7.x86_64.rpm\n\n\npython-paramiko-1.12.4-1.el7.centos.noarch.rpm\n\n\npython-passlib-1.6.2-2.el7.noarch.rpm\n\n\npython-ply-3.4-10.el7.noarch.rpm\n\n\npython-pycparser-2.14-1.el7.noarch.rpm\n\n\npython-setuptools-0.9.8-4.el7.noarch.rpm\n\n\npython-six-1.9.0-2.el7.noarch.rpm\n\n\npython-slip-0.4.0-2.el7.noarch.rpm\n\n\npython-slip-dbus-0.4.0-2.el7.noarch.rpm\n\n\nPyYAML-3.10-11.el7.x86_64.rpm\n\n\nqt-4.8.5-13.el7.x86_64.rpm\n\n\nqt-settings-19-23.5.el7.centos.noarch.rpm\n\n\nqt-x11-4.8.5-13.el7.x86_64.rpm\n\n\nrest-0.7.92-5.el7.x86_64.rpm\n\n\nsshpass-1.06-1.el7.x86_64.rpm\n\n\nyum-utils-1.1.31-40.el7.noarch.rpm\n\n\n\n\n\n\n\n\n/mpfdata/ansible/install/repo/rpms/mpf-deps\n\n\n\n\napr-1.4.8-3.el7.x86_64.rpm\n\n\napr-util-1.5.2-6.el7.x86_64.rpm\n\n\napr-util-ldap-1.5.2-6.el7.x86_64.rpm\n\n\natk-2.14.0-1.el7.x86_64.rpm\n\n\navahi-libs-0.6.31-17.el7.x86_64.rpm\n\n\ncairo-1.14.2-1.el7.x86_64.rpm\n\n\ncdparanoia-libs-10.2-17.el7.x86_64.rpm\n\n\ncpp-4.8.5-11.el7.x86_64.rpm\n\n\ncups-libs-1.6.3-26.el7.x86_64.rpm\n\n\nfontconfig-2.10.95-10.el7.x86_64.rpm\n\n\nfontpackages-filesystem-1.44-8.el7.noarch.rpm\n\n\ngdk-pixbuf2-2.31.6-3.el7.x86_64.rpm\n\n\ngraphite2-1.3.6-1.el7_2.x86_64.rpm\n\n\ngsm-1.0.13-11.el7.x86_64.rpm\n\n\ngstreamer-0.10.36-7.el7.x86_64.rpm\n\n\ngstreamer1-1.4.5-1.el7.x86_64.rpm\n\n\ngstreamer1-plugins-base-1.4.5-2.el7.x86_64.rpm\n\n\ngstreamer-plugins-base-0.10.36-10.el7.x86_64.rpm\n\n\ngstreamer-tools-0.10.36-7.el7.x86_64.rpm\n\n\ngtk2-2.24.28-8.el7.x86_64.rpm\n\n\ngtk3-3.14.13-20.el7.x86_64.rpm\n\n\nharfbuzz-0.9.36-1.el7.x86_64.rpm\n\n\nhicolor-icon-theme-0.12-7.el7.noarch.rpm\n\n\niso-codes-3.46-2.el7.noarch.rpm\n\n\njasper-libs-1.900.1-29.el7.x86_64.rpm\n\n\njbigkit-libs-2.0-11.el7.x86_64.rpm\n\n\njdk-8u60-linux-x64.rpm\n\n\njemalloc-3.6.0-1.el7.x86_64.rpm\n\n\njre-8u60-linux-x64.rpm\n\n\nlibdc1394-2.2.2-3.el7.x86_64.rpm\n\n\nlibICE-1.0.9-2.el7.x86_64.rpm\n\n\nlibjpeg-turbo-1.2.90-5.el7.x86_64.rpm\n\n\nlibmng-1.0.10-14.el7.x86_64.rpm\n\n\nlibmpc-1.0.1-3.el7.x86_64.rpm\n\n\nlibogg-1.3.0-7.el7.x86_64.rpm\n\n\nlibpng-1.5.13-7.el7_2.x86_64.rpm\n\n\nlibraw1394-2.1.0-2.el7.x86_64.rpm\n\n\nlibSM-1.2.2-2.el7.x86_64.rpm\n\n\nlibthai-0.1.14-9.el7.x86_64.rpm\n\n\nlibtheora-1.1.1-8.el7.x86_64.rpm\n\n\nlibtiff-4.0.3-27.el7_3.x86_64.rpm\n\n\nlibusbx-1.0.20-1.el7.x86_64.rpm\n\n\nlibv4l-0.9.5-4.el7.x86_64.rpm\n\n\nlibvisual-0.4.0-16.el7.x86_64.rpm\n\n\nlibvorbis-1.3.3-8.el7.x86_64.rpm\n\n\nlibvpx-1.3.0-5.el7_0.x86_64.rpm\n\n\nlibX11-1.6.3-3.el7.x86_64.rpm\n\n\nlibX11-common-1.6.3-3.el7.noarch.rpm\n\n\nlibXau-1.0.8-2.1.el7.x86_64.rpm\n\n\nlibxcb-1.11-4.el7.x86_64.rpm\n\n\nlibXcomposite-0.4.4-4.1.el7.x86_64.rpm\n\n\nlibXcursor-1.1.14-2.1.el7.x86_64.rpm\n\n\nlibXdamage-1.1.4-4.1.el7.x86_64.rpm\n\n\nlibXext-1.3.3-3.el7.x86_64.rpm\n\n\nlibXfixes-5.0.1-2.1.el7.x86_64.rpm\n\n\nlibXft-2.3.2-2.el7.x86_64.rpm\n\n\nlibXi-1.7.4-2.el7.x86_64.rpm\n\n\nlibXinerama-1.1.3-2.1.el7.x86_64.rpm\n\n\nlibxml2-2.9.1-6.el7_2.3.x86_64.rpm\n\n\nlibXrandr-1.4.2-2.el7.x86_64.rpm\n\n\nlibXrender-0.9.8-2.1.el7.x86_64.rpm\n\n\nlibxshmfence-1.2-1.el7.x86_64.rpm\n\n\nlibXv-1.0.10-2.el7.x86_64.rpm\n\n\nlibXxf86vm-1.1.3-2.1.el7.x86_64.rpm\n\n\nlog4cxx-0.10.0-16.el7.x86_64.rpm\n\n\nmesa-libEGL-11.2.2-2.20160614.el7.x86_64.rpm\n\n\nmesa-libgbm-11.2.2-2.20160614.el7.x86_64.rpm\n\n\nmesa-libGL-11.2.2-2.20160614.el7.x86_64.rpm\n\n\nmesa-libglapi-11.2.2-2.20160614.el7.x86_64.rpm\n\n\nmesa-libGLU-9.0.0-4.el7.x86_64.rpm\n\n\nmysql-community-client-5.6.36-2.el7.x86_64.rpm\n\n\nmysql-community-common-5.6.36-2.el7.x86_64.rpm\n\n\nmysql-community-libs-5.6.36-2.el7.x86_64.rpm\n\n\nmysql-community-server-5.6.36-2.el7.x86_64.rpm\n\n\nmysql-connector-python-2.0.4-1.el7.noarch.rpm\n\n\nmysql-connector-python-2.1.6-1.el7.x86_64.rpm\n\n\nMySQL-python-1.2.5-1.el7.x86_64.rpm\n\n\nnet-tools-2.0-0.17.20131004git.el7.x86_64.rpm\n\n\nopenjpeg-libs-1.5.1-16.el7_3.x86_64.rpm\n\n\nopenssh-6.6.1p1-35.el7_3.x86_64.rpm\n\n\nopenssh-clients-6.6.1p1-35.el7_3.x86_64.rpm\n\n\nopenssh-server-6.6.1p1-35.el7_3.x86_64.rpm\n\n\nopus-1.0.2-6.el7.x86_64.rpm\n\n\norc-0.4.22-5.el7.x86_64.rpm\n\n\npango-1.36.8-2.el7.x86_64.rpm\n\n\nperl-5.16.3-291.el7.x86_64.rpm\n\n\nperl-Carp-1.26-244.el7.noarch.rpm\n\n\nperl-Compress-Raw-Bzip2-2.061-3.el7.x86_64.rpm\n\n\nperl-Compress-Raw-Zlib-2.061-4.el7.x86_64.rpm\n\n\nperl-constant-1.27-2.el7.noarch.rpm\n\n\nperl-Data-Dumper-2.145-3.el7.x86_64.rpm\n\n\nperl-DBD-MySQL-4.023-5.el7.x86_64.rpm\n\n\nperl-DBI-1.627-4.el7.x86_64.rpm\n\n\nperl-Encode-2.51-7.el7.x86_64.rpm\n\n\nperl-Exporter-5.68-3.el7.noarch.rpm\n\n\nperl-File-Path-2.09-2.el7.noarch.rpm\n\n\nperl-File-Temp-0.23.01-3.el7.noarch.rpm\n\n\nperl-Filter-1.49-3.el7.x86_64.rpm\n\n\nperl-Getopt-Long-2.40-2.el7.noarch.rpm\n\n\nperl-HTTP-Tiny-0.033-3.el7.noarch.rpm\n\n\nperl-IO-Compress-2.061-2.el7.noarch.rpm\n\n\nperl-libs-5.16.3-291.el7.x86_64.rpm\n\n\nperl-macros-5.16.3-291.el7.x86_64.rpm\n\n\nperl-Net-Daemon-0.48-5.el7.noarch.rpm\n\n\nperl-parent-0.225-244.el7.noarch.rpm\n\n\nperl-PathTools-3.40-5.el7.x86_64.rpm\n\n\nperl-PlRPC-0.2020-14.el7.noarch.rpm\n\n\nperl-Pod-Escapes-1.04-291.el7.noarch.rpm\n\n\nperl-podlators-2.5.1-3.el7.noarch.rpm\n\n\nperl-Pod-Perldoc-3.20-4.el7.noarch.rpm\n\n\nperl-Pod-Simple-3.28-4.el7.noarch.rpm\n\n\nperl-Pod-Usage-1.63-3.el7.noarch.rpm\n\n\nperl-Scalar-List-Utils-1.27-248.el7.x86_64.rpm\n\n\nperl-Socket-2.010-4.el7.x86_64.rpm\n\n\nperl-Storable-2.45-3.el7.x86_64.rpm\n\n\nperl-Text-ParseWords-3.29-4.el7.noarch.rpm\n\n\nperl-threads-1.87-4.el7.x86_64.rpm\n\n\nperl-threads-shared-1.43-6.el7.x86_64.rpm\n\n\nperl-Time-HiRes-1.9725-3.el7.x86_64.rpm\n\n\nperl-Time-Local-1.2300-2.el7.noarch.rpm\n\n\npixman-0.34.0-1.el7.x86_64.rpm\n\n\nredis-3.2.8-1.el7.remi.x86_64.rpm\n\n\nSDL-1.2.15-14.el7.x86_64.rpm\n\n\nspeex-1.2-0.19.rc1.el7.x86_64.rpm\n\n\nunzip-6.0-16.el7.x86_64.rpm\n\n\nxml-common-0.6.3-39.el7.noarch.rpm\n\n\n\n\n\n\n\n\n/mpfdata/ansible/install/repo/tars\n\n\n\n\napache-activemq-5.13.0-bin.tar.gz\n\n\napache-tomcat-7.0.72.tar.gz\n\n\n\n\n\n\n\n\n/mpfdata/ansible/install/repo/pip\n\n\n\n\nargcomplete-1.8.2-py2.py3-none-any.whl\n\n\nargh-0.26.2-py2.py3-none-any.whl\n\n\nbcrypt-3.1.3-cp27-cp27mu-manylinux1_x86_64.whl\n\n\ncffi-1.10.0-cp27-cp27mu-manylinux1_x86_64.whl\n\n\npycparser-2.17.tar.gz\n\n\nPyMySQL-0.7.11-py2.py3-none-any.whl\n\n\nsix-1.10.0-py2.py3-none-any.whl\n\n\n\n\n\n\n\n\nBuild and Test Environment\n\n\nWhen developing for the OpenMPF, you may find the following collaboration and continuous integration tools helpful.\n\n\nJenkins\n\n\nhttps://jenkins.io\n\n\nPhabricator\n\n\nhttps://www.phacility.com/phabricator", 
            "title": "Build Guide"
        }, 
        {
            "location": "/Build-Environment-Setup-Guide/#general-information", 
            "text": "The Open Media Processing Framework (OpenMPF) software is distributed to interested parties as a raw source code package. This is to avoid any potential licensing issues that may arise from distributing a pre-compiled executable that is linked to dependencies that are licensed under a copyleft license or have patent restrictions. Generally, it is acceptable build and execute software with these dependencies for non-commercial in-house use.  By distributing the OpenMPF software as raw source code the development team is able to keep most of the software clean from copyleft and patent issues so that it can be published under a more open Apache license and freely distributed to interested parties.   IMPORTANT:  It is the responsibility of the end users who follow this guide, and otherwise build the OpenMPF software to create an executable, to abide by all of the non-commercial and re-distribution restrictions imposed by the dependencies that the OpenMPF software uses. Building the OpenMPF and linking in these dependencies at build time or run time results in creating a derivative work under the terms of the GNU General Public License. Refer to the About page within the OpenMPF for more information about these dependencies.   In general, it is only acceptable to use and distribute the executable form of the OpenMPF \"in house\", which is loosely defined as internally with an organization. The OpenMPF should only be distributed to third parties in raw source code form and those parties will be responsible for creating their own executable.  This guide provides comprehensive instructions for setting up a build environment and generating an OpenMPF deployment package that contains the executable form of the software. This package is self-contained so that it can be installed on a minimal CentOS 7 system without Internet connectivity. This package can be freely distributed and installed in-house, but not distributed to third parties.", 
            "title": "General Information"
        }, 
        {
            "location": "/Build-Environment-Setup-Guide/#set-up-the-minimal-centos-7-vm", 
            "text": "The following instructions are for setting up a VM for building an OpenMPF deployment package. This VM is not necessarily a machine on which the OpenMPF will be deployed and run. Those machines may have other requirements. For more information refer to the  OpenMPF Installation Guide .   This guide assumes a starting point of CentOS 7 with a minimal installation.  At the time of writing this, the available minimal .iso file is CentOS-7-x86_64-Minimal-1611.iso. It should be downloaded from  https://www.centos.org/download/  prior to starting these steps.   Oracle Virtual Box 5.0.20-106931 is used as the virtualization platform. Another platform such as VMware or a physical system can be used but are not supported.    Create a new VM with these settings:   Name : \u2019OpenMPF Build\u2019. (This guide assumes the name \u2018OpenMPF Build\u2019, but any name can be used.)  Type : Linux  Version : Red Hat (64-bit)     The recommended minimum virtual system specifications are:   Memory : 8192MB  CPU : 4  Disk : 40GB on a SSD.     Network settings may vary based on your local environment. Connectivity to the public Internet is assumed. The network settings used in this guide are:   Attached to : NAT  Advanced -  Adapter Type : Intel PRO/1000 MT Desktop (82540EM)  Cable Connected : Checked", 
            "title": "Set Up the Minimal CentOS 7 VM"
        }, 
        {
            "location": "/Build-Environment-Setup-Guide/#installing-centos-7", 
            "text": "NOTE:  If your build environment is behind a proxy server, please read the appendix section  Proxy Configuration  for instructions to configure the yum package manager before continuing.    Open the \u2018Settings\u2019 for the OpenMPF Build VM.  Select the \u2018Storage\u2019 menu item.  In the \u2018Storage Tree\u2019 section under the \u2018Controller: IDE\u2019 item, select the optical disc icon.  Under the \u2018Attributes\u2019 section, select the optical disc icon with a small black arrow. This will bring up a menu.  Select \u2018Choose Virtual Optical Disc file\u2026\u2019  Choose the \u2018CentOS-7-x86_64-Minimal-1611.iso\u2019 file.  Press the \u2018OK\u2019 button to exit the OpenMPF Build VM settings.  Right click on the OpenMPF Build VM and select \u2018Start\u2019 and \u2018Normal Start\u2019. A new window will open with the running VM.  On the \u2018CentOS 7\u2019 screen, select \u2018Install CentOS 7\u2019 with the keyboard and press the Enter key.  Select the appropriate language and press the \u2018Continue\u2019 button.  On the \u2018Installation Summary\u2019 screen, select the \u2018Installation Destination\u2019 icon.  Press the \u2018Done\u2019 button to accept the defaults.  On the \u2018Installation Summary\u2019 screen, select the \u2018Network   Host Name\u2019 icon. There should be one interface listed.  Set the slider switch to \u2018On\u2019.  Press the \u2018Configure\u2019 button, select the \u2018General\u2019 tab, and check the box for \u2018Automatically connect to this network when available\u2019.  Press the 'Save' button.  Each interface should show its status as \u2018Connected\u2019 with an IPv4 address.  Leave the hostname as \u2018localhost.localdomain\u2019.  Press the \u2018Done\u2019 button.  Use the default values for everything else and press 'Begin Installation'.  Set a password for the root account.  Under \u2018User Creation\u2019, create a new user:  Full Name : mpf  User Name : mpf  Check the box for \u2018Make this user administrator\u2019    Password : mpf    When installation is finished, press the \u2018Finish Configuration\u2019 button.  When configuration is finished, press the \u2018Reboot\u2019 button.  At the login prompt, login as user \u2018mpf\u2019 and password \u2018mpf\u2019.  Install the epel repository and Delta RPM:\n       sudo yum install -y epel-release deltarpm  Perform an initial system update:\n       sudo yum update -y  Install Gnome Desktop Environment and some packages needed for the Virtual Box Guest Additions:\n       sudo yum groups install -y \"GNOME Desktop\"  Install packages needed for the Virtual Box Guest Additions:\n       sudo yum install gcc kernel-devel bzip2  NOTE:  You may have to specify a kernel version when installing \u2018kernel-devel\u2018 as a Virtual Box guest addition. For example:  sudo yum install kernel-devel-3.10.0-327.el7.x86_64 .    Reboot the system:\n       sudo reboot now  Follow the on screen instructions to accept the license agreement.  At the login prompt, login as user \u2018mpf\u2019 and password \u2018mpf\u2019.  Switch user to root with this command:\n       sudo su -  On your host system in the Virtual Box Application, select the OpenMPF Build VM menu item \u2018Devices\u2019 and then \u2018Insert Guest Additions CD image\u2026\u2019  Install the Virtual Box Guest Additions:  mount /dev/cdrom /mnt  cd /mnt  ./VBoxLinuxAdditions.run    systemctl set-default graphical.target  reboot now  At the graphical login screen, select the 'mpf' user.  Enter 'mpf' as the password.  A welcome screen will come up on the first launch of the Gnome desktop environment. Press the 'Next' button on the 'Language' page.  Press the 'Next' button on the 'Typing' page.  Press the 'Skip' button on the 'Online Accounts' page.  Press the 'Start using CentOS Linux' button.  Close the 'Getting Started' window that appears.  On the desktop, right click the 'VBOXADDITIONS_5.0.22_108108' icon and select 'Eject'.  On your host system in the Virtual Box Application, select the OpenMPF Build VM menu item \u2018Devices\u2019, then \u2018Shared Clipboard\u2019, then \"Bidirectional\". This will enable the ability to copy and paste commands from this document into the VM.  On your host system in the Virtual Box Application, select the OpenMPF Build VM menu item \u2018Devices\u2019, then \u2018Drag and Drop\u2019, then \"Bidirectional\". This will enable the ability to drag files from the host system to the guest VM.", 
            "title": "Installing CentOS 7"
        }, 
        {
            "location": "/Build-Environment-Setup-Guide/#set-up-the-openmpf-build-environment", 
            "text": "NOTE:  If your build environment is behind a proxy server, please read the appendix section  Proxy Configuration  for instructions to configure the yum package manager before continuing.   At the time of writing, all URLs provided in this section were verified as working.", 
            "title": "Set Up the OpenMPF Build Environment"
        }, 
        {
            "location": "/Build-Environment-Setup-Guide/#configure-additional-repositories", 
            "text": "Install the Oracle MySQL Community Release Repository:  wget -P /home/mpf/Downloads \"http://dev.mysql.com/get/mysql-community-release-el7-5.noarch.rpm\"  sudo rpm -ivh /home/mpf/Downloads/mysql-community-release-el7-5.noarch.rpm    Install the Remi Repo for Redis:  wget -P /home/mpf/Downloads \"http://rpms.remirepo.net/RPM-GPG-KEY-remi\"  wget -P /home/mpf/Downloads \"http://rpms.famillecollet.com/enterprise/remi-release-7.rpm\"  sudo rpm --import /home/mpf/Downloads/RPM-GPG-KEY-remi  sudo rpm -Uvh /home/mpf/Downloads/remi-release-7.rpm  sudo yum-config-manager --enable remi    Create an \u2018/apps\u2019 directory and package subdirectories:  sudo mkdir -p /apps/install/lib  sudo mkdir -p /apps/bin/apache  sudo mkdir /apps/ansible  sudo mkdir -p /apps/source/cmake_sources  sudo mkdir /apps/source/apache_sources  sudo mkdir /apps/source/google_sources  sudo mkdir /apps/source/opencv_sources  sudo mkdir /apps/source/ffmpeg_sources  sudo mkdir /apps/source/dlib-sources  sudo mkdir /apps/source/openalpr_sources  sudo mkdir /apps/source/ansible_sources  sudo chown -R mpf:mpf /apps  sudo chmod -R 755 /apps    Add /apps/install/bin to the system PATH variable:  sudo sh -c 'echo \"PATH=\\$PATH:/apps/install/bin\"   /etc/profile.d/mpf.sh'  . /etc/profile.d/mpf.sh    Create the OpenMPF ldconfig file:\n     sudo touch /etc/ld.so.conf.d/mpf-x86_64.conf  Add /apps/install/lib to the OpenMPF ldconfig file:\n     sudo sh -c 'echo \"/apps/install/lib\"   /etc/ld.so.conf.d/mpf-x86_64.conf'  Update the shared library cache:\n     sudo ldconfig", 
            "title": "Configure Additional Repositories"
        }, 
        {
            "location": "/Build-Environment-Setup-Guide/#rpm-dependencies", 
            "text": "The following RPM packages will need to be downloaded and installed. Use of the yum package manager is recommended:  sudo yum install -y asciidoc autoconf automake boost boost-devel cmake3 curl freetype-devel gcc-c++ git graphviz gstreamer-plugins-base-devel gtk2-devel gtkglext-devel gtkglext-libs jasper jasper-devel libavc1394-devel libcurl-devel libdc1394-devel libffi-devel libICE-devel libjpeg-turbo-devel libpng-devel libSM-devel libtiff-devel libtool libv4l-devel libXinerama-devel libXmu-devel libXt-devel log4cplus log4cplus-devel log4cxx log4cxx-devel make mercurial mesa-libGL-devel mesa-libGLU-devel mysql-community-client mysql-community-server nasm ncurses-devel numpy pangox-compat pangox-compat-devel perl-CPAN-Meta-YAML perl-DBD-MySQL perl-DBI perl-Digest-MD5 perl-File-Find-Rule perl-File-Find-Rule-Perl perl-JSON perl-JSON-PP perl-List-Compare perl-Number-Compare perl-Params-Util perl-Parse-CPAN-Meta php pkgconfig python-devel python-httplib2 python-jinja2 python-keyczar python2-paramiko python2-pip python-setuptools python-six PyYAML qt qt-devel qt-x11 redis rpm-build sshpass tbb tbb-devel tree unzip uuid-devel wget yasm yum-utils zlib-devel", 
            "title": "RPM Dependencies"
        }, 
        {
            "location": "/Build-Environment-Setup-Guide/#get-the-openmpf-source-code", 
            "text": "Open a terminal window and perform the following steps:    Clone the OpenMPF repository   cd /home/mpf  git clone https://github.com/openmpf/openmpf-projects.git --recursive  (Optional) The HTTPS repository URL requires configuring your Github account with a certificate pair. The HTTP URL may be used without any certificates:\n     git clone http://github.com/openmpf/openmpf-projects.git --recursive     Copy the mpf user profile script from the extracted source code:\n       sudo cp /home/mpf/openmpf-projects/openmpf/trunk/mpf-install/src/main/scripts/mpf-profile.sh /etc/profile.d/mpf.sh", 
            "title": "Get the OpenMPF Source Code"
        }, 
        {
            "location": "/Build-Environment-Setup-Guide/#binary-packages", 
            "text": "NOTE:  If your environment is behind a proxy server that performs SSL inspection, please read the appendix section  SSL Inspection  before continuing.   The following binary packages will need to be downloaded and installed:    Oracle JDK:\n     For reference only:  http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html   cd /home/mpf  wget --no-cookies --header \"Cookie: oraclelicense=accept-securebackup-cookie\" \"http://download.oracle.com/otn-pub/java/jdk/8u60-b27/jdk-8u60-linux-x64.rpm\" -O /apps/bin/jdk-8u60-linux-x64.rpm  sudo yum -y localinstall --nogpgcheck /apps/bin/jdk-8u60-linux-x64.rpm  sudo alternatives --install /usr/bin/java java /usr/java/jdk1.8.0_60/jre/bin/java 20000  sudo alternatives --install /usr/bin/jar jar /usr/java/jdk1.8.0_60/bin/jar 20000  sudo alternatives --install /usr/bin/javac javac /usr/java/jdk1.8.0_60/bin/javac 20000  sudo alternatives --install /usr/bin/javaws javaws /usr/java/jdk1.8.0_60/jre/bin/javaws 20000  sudo alternatives --set java /usr/java/jdk1.8.0_60/jre/bin/java  sudo alternatives --set javaws /usr/java/jdk1.8.0_60/jre/bin/javaws  sudo alternatives --set javac /usr/java/jdk1.8.0_60/bin/javac  sudo alternatives --set jar /usr/java/jdk1.8.0_60/bin/jar  NOTE:  If this command to set the  jar  alternative fails with the following error:  failed to read link /usr/bin/jar: No such file or directory  You should run the following commands again:\n-  sudo alternatives --install /usr/bin/jar jar /usr/java/jdk1.8.0_60/bin/jar 20000 \n-  sudo alternatives --set jar /usr/java/jdk1.8.0_60/bin/jar    . /etc/profile.d/mpf.sh     Apache ActiveMQ 5.13.0:\n     For reference only:  http://activemq.apache.org   cd /apps/bin/apache  wget -O /apps/bin/apache/apache-activemq-5.13.0-bin.tar.gz \"https://archive.apache.org/dist/activemq/5.13.0/apache-activemq-5.13.0-bin.tar.gz\"  sudo tar xvzf apache-activemq-5.13.0-bin.tar.gz -C /opt/  sudo chown -R mpf:mpf /opt/apache-activemq-5.13.0  sudo chmod -R 755 /opt/apache-activemq-5.13.0  sudo ln -s /opt/apache-activemq-5.13.0 /opt/activemq    Apache Tomcat 7.0.72:\n     For reference only:  http://tomcat.apache.org  cd /apps/bin/apache  wget -O /apps/bin/apache/apache-tomcat-7.0.72.tar.gz \"http://archive.apache.org/dist/tomcat/tomcat-7/v7.0.72/bin/apache-tomcat-7.0.72.tar.gz\"  tar xzvf apache-tomcat-7.0.72.tar.gz  sudo mkdir -p /usr/share/apache-tomcat  sudo cp -Rf /apps/bin/apache/apache-tomcat-7.0.72/* /usr/share/apache-tomcat/  sudo chown -R mpf:mpf /usr/share/apache-tomcat  sudo chmod -R 755 /usr/share/apache-tomcat  sudo ln -s /usr/share/apache-tomcat /opt/apache-tomcat  sudo perl -i -p0e 's/ !--\\n     Manager pathname=\"\" \\/ \\n      -- .*?/ !-- -- \\n     Manager pathname=\"\" \\/ /s' /opt/apache-tomcat/conf/context.xml  sudo rm -rf /opt/apache-tomcat/webapps/*    Apache Ant 1.9.6:\n     For reference only:  http://ant.apache.org  cd /apps/bin/apache  wget -O /apps/bin/apache/apache-ant-1.9.6-bin.tar.gz \"https://archive.apache.org/dist/ant/binaries/apache-ant-1.9.6-bin.tar.gz\"  tar xzvf apache-ant-1.9.6-bin.tar.gz  sudo cp -R /apps/bin/apache/apache-ant-1.9.6 /apps/install/  sudo chown -R mpf:mpf /apps/install/apache-ant-1.9.6  sudo sed -i '/^PATH/s/$/:\\/apps\\/install\\/apache-ant-1.9.6\\/bin/' /etc/profile.d/mpf.sh  . /etc/profile.d/mpf.sh    Apache Maven 3.3.3:\n     For reference only:  https://maven.apache.org  cd /apps/bin/apache  wget -O /apps/bin/apache/apache-maven-3.3.3-bin.tar.gz \"https://archive.apache.org/dist/maven/maven-3/3.3.3/binaries/apache-maven-3.3.3-bin.tar.gz\"  tar xzvf apache-maven-3.3.3-bin.tar.gz  sudo mkdir /opt/apache-maven  sudo cp -Rf /apps/bin/apache/apache-maven-3.3.3/* /opt/apache-maven/  sudo chown -R mpf:mpf /opt/apache-maven  sudo sed -i '/^PATH/s/$/:\\/opt\\/apache-maven\\/bin/' /etc/profile.d/mpf.sh  sudo sh -c 'echo \"M2_HOME=/opt/apache-maven\"   /etc/profile.d/mpf.sh'  . /etc/profile.d/mpf.sh", 
            "title": "Binary Packages"
        }, 
        {
            "location": "/Build-Environment-Setup-Guide/#python-packages", 
            "text": "C Foreign Function Interface (CFFI):  cd /home/mpf  sudo -E easy_install -U cffi    OpenMPF Administrative Tools:\n       sudo -E pip install /home/mpf/openmpf-projects/openmpf/trunk/bin/mpf-scripts", 
            "title": "Python Packages"
        }, 
        {
            "location": "/Build-Environment-Setup-Guide/#building-dependencies", 
            "text": "NOTE:  If your build environment is behind a proxy server, please read the appendix section  Proxy Configuration  for instructions to configure git before continuing.   The following source packages will need to be downloaded, built, and installed:   Cmake 2.8.12.2:\n     For reference only:  https://cmake.org  cd /apps/source/cmake_sources  wget -O /apps/source/cmake_sources/cmake-2.8.12.2.tar.gz \"https://cmake.org/files/v2.8/cmake-2.8.12.2.tar.gz\"  tar xvzf cmake-2.8.12.2.tar.gz  cd cmake-2.8.12.2  chmod +x *  ./configure --prefix=/apps/install  make -j  sudo make install  sudo ldconfig  sudo ln -s /apps/install/bin/cmake /usr/local/bin/cmake      NOTE:  FFmpeg can be built with different encoders and modules that are individually licensed. It is recommended to check each developer\u2019s documentation for the most up-to-date licensing information.        FFmpeg 2.6.3:  xvidcore:\n     For reference only:  https://labs.xvid.com  cd /apps/source/ffmpeg_sources  wget -O /apps/source/ffmpeg_sources/xvidcore-1.3.2.tar.gz \"http://downloads.xvid.org/downloads/xvidcore-1.3.2.tar.gz\"  tar zxvf xvidcore-1.3.2.tar.gz  cd xvidcore/build/generic  ./configure --prefix=\"/apps/install\"  make  sudo make install  make distclean  sudo ldconfig    libx264:\n     For reference only:  http://www.videolan.org/developers/x264.html  cd /apps/source/ffmpeg_sources  wget -O /apps/source/ffmpeg_sources/x264-snapshot-20140223-2245-stable.tar.bz2 \"ftp://ftp.videolan.org/pub/videolan/x264/snapshots/x264-snapshot-20140223-2245-stable.tar.bz2\"  tar xvjf x264-snapshot-20140223-2245-stable.tar.bz2  cd x264-snapshot-20140223-2245-stable  PKG_CONFIG_PATH=\"/apps/install/lib/pkgconfig\" ./configure --prefix=\"/apps/install\" --bindir=\"/apps/install\" --enable-shared  sudo sed -i '/^PATH/s/$/:\\/apps\\/install\\/lib\\/pkgconfig/' /etc/profile.d/mpf.sh  sudo sh -c 'echo \"export PKG_CONFIG_PATH=/apps/install/lib/pkgconfig\"   /etc/profile.d/mpf.sh'  . /etc/profile.d/mpf.sh  make  sudo make install  make distclean  sudo ldconfig    opencore-amr:\n     For reference only:  https://sourceforge.net/projects/opencore-amr  cd /apps/source/ffmpeg_sources  wget -O /apps/source/ffmpeg_sources/opencore-amr-0.1.3.tar.gz \"http://downloads.sourceforge.net/project/opencore-amr/opencore-amr/opencore-amr-0.1.3.tar.gz?r=https%3A%2F%2Fsourceforge.net%2Fprojects%2Fopencore-amr%2Ffiles%2Fopencore-amr%2F ts=1467223123 use_mirror=tenet\"  tar xvzf opencore-amr-0.1.3.tar.gz  cd opencore-amr-0.1.3  autoreconf -fiv  ./configure --prefix=\"/apps/install\" --enable-shared  make  sudo make install  make distclean  sudo ldconfig    libmp3lame:\n     For reference only:  http://lame.sourceforge.net  cd /apps/source/ffmpeg_sources  wget -O /apps/source/ffmpeg_sources/lame-3.99.5.tar.gz \"http://downloads.sourceforge.net/project/lame/lame/3.99/lame-3.99.5.tar.gz\"  tar xzvf lame-3.99.5.tar.gz  cd lame-3.99.5  ./configure --prefix=\"/apps/install\" --bindir=\"/apps/install/bin\" --enable-shared --enable-nasm  make  sudo make install  make distclean  sudo ldconfig    libogg:\n     For reference only:  https://www.xiph.org/ogg  cd /apps/source/ffmpeg_sources  wget -O /apps/source/ffmpeg_sources/libogg-1.3.2.tar.gz \"http://downloads.xiph.org/releases/ogg/libogg-1.3.2.tar.gz\"  tar xvzf libogg-1.3.2.tar.gz  cd libogg-1.3.2  ./configure --prefix=\"/apps/install\" --enable-shared  make  sudo make install  make distclean  sudo ldconfig    libvorbis:\n     For reference only:  https://xiph.org/vorbis  cd /apps/source/ffmpeg_sources  wget -O /apps/source/ffmpeg_sources/libvorbis-1.3.4.tar.gz \"http://downloads.xiph.org/releases/vorbis/libvorbis-1.3.4.tar.gz\"  tar xzvf libvorbis-1.3.4.tar.gz  cd libvorbis-1.3.4  LDFLAGS=\"-L/apps/install/lib\" CPPFLAGS=\"-I/apps/install/include\" ./configure --prefix=\"/apps/install\" --with-ogg=\"/apps/install\" --enable-shared  make  sudo make install  make distclean  sudo ldconfig    libtheora:\n     For reference only:  https://www.theora.org  cd /apps/source/ffmpeg_sources  wget -O /apps/source/ffmpeg_sources/libtheora-1.1.1.tar.bz2 \"http://downloads.xiph.org/releases/theora/libtheora-1.1.1.tar.bz2\"  tar -xvjf libtheora-1.1.1.tar.bz2  cd libtheora-1.1.1  ./configure --prefix=\"/apps/install\" --enable-shared  make  sudo make install  make distclean  sudo ldconfig    FFmpeg:\n     For reference only:  https://ffmpeg.org  cd /apps/source/ffmpeg_sources  git clone https://git.ffmpeg.org/ffmpeg.git ffmpeg  cd ffmpeg  git checkout af5917698bd44f136fd0ff00a9e5f8b5f92f2d58  PKG_CONFIG_PATH=\"/apps/install/lib/pkgconfig\" ./configure --prefix=\"/apps/install\" --extra-cflags=\"-I/apps/install/include\" --extra-ldflags=\"-L/apps/install/lib\" --bindir=\"/apps/install/bin\" --enable-gpl --enable-nonfree --enable-libtheora --enable-libfreetype --enable-libmp3lame --enable-libvorbis --enable-libx264 --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-version3 --enable-shared --disable-libsoxr --enable-avresample  make  sudo make install  make distclean  sudo ln -s /apps/install/bin/ffmpeg /usr/bin/ffmpeg  sudo sh -c 'echo \"PATH=\\$PATH:/apps/install/bin\"   /etc/profile.d/mpf.sh'  sudo sh -c 'echo \"export CXXFLAGS=-isystem\\ /apps/install/include\"   /etc/profile.d/mpf.sh'  . /etc/profile.d/mpf.sh  sudo ldconfig      Google protocol buffers 2.5.0:\n     For reference only:  https://developers.google.com/protocol-buffers  cd /apps/source/google_sources  wget -O /apps/source/google_sources/protobuf-2.5.0.tar.gz \"https://github.com/google/protobuf/releases/download/v2.5.0/protobuf-2.5.0.tar.gz\"  tar xvzf protobuf-2.5.0.tar.gz  cd protobuf-2.5.0  ./configure --prefix=/apps/install  make -j8  sudo make install  make distclean  sudo ldconfig  sudo sh -c 'echo \"export CXXFLAGS=-isystem\\ /apps/install/include\"   /etc/profile.d/mpf.sh'  sudo ln -s /apps/install/bin/protoc /usr/local/bin/protoc  sudo ln -s /usr/lib64/libuuid.so.1.3.0 /usr/lib64/libuuid.so    Apr 1.5.2:\n     For reference only:  https://apr.apache.org  cd /apps/source/apache_sources  wget -O /apps/source/apache_sources/apr-1.5.2.tar.gz \"http://archive.apache.org/dist/apr/apr-1.5.2.tar.gz\"  tar -zxvf apr-1.5.2.tar.gz  cd /apps/source/apache_sources/apr-1.5.2  ./configure --prefix=/apps/install  make -j8  sudo make install  make distclean  sudo ldconfig    Apr-util 1.5.4:\n     For reference only:  https://apr.apache.org  cd /apps/source/apache_sources  wget -O /apps/source/apache_sources/apr-util-1.5.4.tar.gz \"http://archive.apache.org/dist/apr/apr-util-1.5.4.tar.gz\"  tar -xzvf apr-util-1.5.4.tar.gz  cd /apps/source/apache_sources/apr-util-1.5.4  ./configure --with-apr=/apps/install --prefix=/apps/install  make -j8  sudo make install  make distclean  sudo ldconfig    Activemqcpp 3.9.0:\n     For reference only:  http://activemq.apache.org/cms  cd /apps/source/apache_sources  wget -O /apps/source/apache_sources/activemq-cpp-library-3.9.0-src.tar.gz \"https://archive.apache.org/dist/activemq/activemq-cpp/3.9.0/activemq-cpp-library-3.9.0-src.tar.gz\"  tar zxvf activemq-cpp-library-3.9.0-src.tar.gz  cd /apps/source/apache_sources/activemq-cpp-library-3.9.0  ./autogen.sh  ./configure --disable-ssl --prefix=/apps/install  make -j8  sudo make install  make distclean  sudo ldconfig  sudo ln -s /apps/install/lib/libactivemq-cpp.so.19.0.0 /usr/lib/libactivemq-cpp.so    OpenCV 3.2.0:\n     For reference only:  http://opencv.org  cd /apps/source/opencv_sources  git clone https://github.com/opencv/opencv.git  cd opencv  git checkout 26e9b42a44a62e00e0c1237f778040169162116c  cd ..  git clone https://github.com/opencv/opencv_contrib.git  cd opencv_contrib  git checkout 009d2efb75fbb0eded127864cb1ca932d58d1738  cd ..  cd opencv  mkdir release  cd release  PKG_CONFIG_PATH=\"/apps/install/lib/pkgconfig\" cmake3 -D CMAKE_BUILD_TYPE=Release -D -DWITH_GSTREAMER:BOOL=\"0\" -DWITH_OPENMP:BOOL=\"1\" -DBUILD_opencv_apps:BOOL=\"0\" -DWITH_OPENCLAMDBLAS:BOOL=\"0\" -DWITH_CUDA:BOOL=\"0\" -DCLAMDFFT_ROOT_DIR:PATH=\"CLAMDFFT_ROOT_DIR-NOTFOUND\" -DBUILD_opencv_aruco:BOOL=\"0\" -DCMAKE_INSTALL_PREFIX:PATH=\"/apps/install/opencv3.2.0\" -DWITH_WEBP:BOOL=\"0\" -DBZIP2_LIBRARIES:FILEPATH=\"BZIP2_LIBRARIES-NOTFOUND\" -DWITH_GIGEAPI:BOOL=\"0\" -DOPENCV_EXTRA_MODULES_PATH:PATH=\"/apps/source/opencv_sources/opencv_contrib/modules\" -DWITH_JPEG:BOOL=\"1\" -DWITH_CUFFT:BOOL=\"0\" -DWITH_IPP:BOOL=\"0\" -DWITH_V4L:BOOL=\"1\" -DWITH_GDAL:BOOL=\"0\" -DWITH_OPENCLAMDFFT:BOOL=\"0\" -DWITH_GPHOTO2:BOOL=\"0\" -DWITH_VTK:BOOL=\"0\" -DWITH_GTK_2_X:BOOL=\"0\" -DBUILD_opencv_world:BOOL=\"0\" -DWITH_TIFF:BOOL=\"1\" -DWITH_1394:BOOL=\"0\" -DWITH_EIGEN:BOOL=\"0\" -DWITH_LIBV4L:BOOL=\"0\" -DBUILD_opencv_ts:BOOL=\"0\" -DWITH_MATLAB:BOOL=\"0\" -DWITH_OPENCL:BOOL=\"0\" -DWITH_PVAPI:BOOL=\"0\" ..  make -j4  sudo make install  sudo sh -c 'echo \"/apps/install/opencv3.2.0/lib\"   /etc/ld.so.conf.d/mpf-x86_64.conf'  sudo ln -sf /apps/install/opencv3.2.0 /opt/opencv-3.2.0  sudo ln -sf /apps/install/opencv3.2.0/include/opencv2 /usr/local/include/opencv2  sudo ln -sf /apps/install/opencv3.2.0/include/opencv /usr/local/include/opencv  sudo ldconfig  export OpenCV_DIR=/opt/opencv-3.2.0/share/OpenCV    Leptonica 1.72:\n     For reference only:  https://github.com/DanBloomberg/leptonica  cd /apps/source/openalpr_sources  wget -O /apps/source/openalpr_sources/leptonica-1.72.tar.gz \"https://github.com/DanBloomberg/leptonica/archive/v1.72.tar.gz\"  tar xvzf leptonica-1.72.tar.gz  sudo mkdir /usr/local/src/openalpr       sudo cp -R /apps/source/openalpr_sources/leptonica-1.72 /usr/local/src/openalpr/  sudo chown -R mpf:mpf /usr/local/src/openalpr  sudo chmod -R 755 /usr/local/src/openalpr  cd /usr/local/src/openalpr/leptonica-1.72  ./configure --prefix=/usr/local  make --directory /usr/local/src/openalpr/leptonica-1.72 -j  sudo make --directory /usr/local/src/openalpr/leptonica-1.72 install  make --directory /usr/local/src/openalpr/leptonica-1.72 distclean  sudo ldconfig    Tesseract 3.04.00:\n     For reference only:  https://github.com/tesseract-ocr  cd /apps/source/openalpr_sources  wget -O /apps/source/openalpr_sources/tesseract-3.04.00.tar.gz \"https://github.com/tesseract-ocr/tesseract/archive/3.04.00.tar.gz\"  tar xvzf tesseract-3.04.00.tar.gz  wget -O /apps/source/openalpr_sources/tessdata-3.04.00.tar.gz https://github.com/tesseract-ocr/tessdata/archive/3.04.00.tar.gz  tar xvzf tessdata-3.04.00.tar.gz  sudo mkdir -p /usr/local/src/openalpr/tesseract-ocr  sudo cp -a /apps/source/openalpr_sources/tessdata-3.04.00/. /usr/local/src/openalpr/tesseract-ocr/tessdata/  sudo cp -a /apps/source/openalpr_sources/tesseract-3.04.00/. /usr/local/src/openalpr/tesseract-ocr/  sudo chown -R mpf:mpf /usr/local/src/openalpr  sudo chmod -R 755 /usr/local/src/openalpr  cd /usr/local/src/openalpr/tesseract-ocr  sh autogen.sh  ./configure  make --directory /usr/local/src/openalpr/tesseract-ocr -j  sudo make --directory /usr/local/src/openalpr/tesseract-ocr install  sudo ldconfig    OpenALPR 2.3.0:\n     For reference only:  https://github.com/openalpr/openalpr  cd /apps/source/openalpr_sources  git clone https://github.com/openalpr/openalpr.git  cd openalpr  git checkout 469c4fd6d782ac63a55246d1073b0f88edd0d230  cp -a /apps/source/openalpr_sources/openalpr /usr/local/src/openalpr/  mkdir -p /usr/local/src/openalpr/openalpr/src/build  cd /usr/local/src/openalpr/openalpr/src/build  cmake3 -j --DCmake3 -j_INSTALL_PREFIX:PATH=/usr -D WITH_DAEMON=OFF ../  make --directory /usr/local/src/openalpr/openalpr/src/build -j  sudo make --directory /usr/local/src/openalpr/openalpr/src/build install  sudo ln -sf /usr/local/src/openalpr/openalpr /usr/share/openalpr  sudo cp -a /usr/local/lib/libopenalpr.so /usr/lib/libopenalpr.so  sudo cp /usr/local/lib/libopenalpr.so.2 /usr/lib/libopenalpr.so.2  sudo sh -c 'echo \"export TESSDATA_PREFIX=/usr/local/src/openalpr/openalpr/runtime_data/ocr\"   /etc/profile.d/mpf.sh'  sudo ldconfig  . /etc/profile.d/mpf.sh    dlib:\n     For reference only:  http://dlib.net  cd /apps/source  wget -O /apps/source/config4cpp.tar.gz \"http://www.config4star.org/download/config4cpp.tar.gz\"  tar xvzf config4cpp.tar.gz  cd config4cpp  make  cd /apps/source/dlib-sources  wget -O /apps/source/dlib-sources/dlib-18.18.tar.bz2 \"http://dlib.net/files/dlib-18.18.tar.bz2\"  tar xvjf dlib-18.18.tar.bz2  cd dlib-18.18/dlib  mkdir build  cd build  cmake3 ../  cmake3 --build . --config Release  Make sure libdlib.so and libdlib.so.18.18.0 are present in /apps/source/dlib-sources/dlib-18.18/dlib/build  sudo make install    Ansible:\n     For reference only:  https://github.com/ansible/ansible  cd /apps/source/ansible_sources  git clone https://github.com/ansible/ansible.git --recursive  cd ansible  git checkout e71cce777685f96223856d5e6cf506a9ea2ef3ff  git pull --rebase  git submodule update --init --recursive  cd /apps/source/ansible_sources/ansible/lib/ansible/modules/core  git checkout 36f512abc1a75b01ae7207c74cdfbcb54a84be54  cd /apps/source/ansible_sources/ansible/lib/ansible/modules/extras  git checkout 32338612b38d1ddfd0d42b1245c597010da02970  cd /apps/source/ansible_sources/ansible  make rpm  sudo rpm -Uvh ./rpm-build/ansible-*.noarch.rpm", 
            "title": "Building Dependencies"
        }, 
        {
            "location": "/Build-Environment-Setup-Guide/#configuring-mysql", 
            "text": "sudo systemctl start mysqld  mysql -u root --execute \"UPDATE mysql.user SET Password=PASSWORD('password') WHERE User='root';flush privileges;\"  mysql -u root -ppassword --execute \"create database mpf\"  mysql -u root -ppassword --execute \"create user 'mpf'@'%' IDENTIFIED by 'mpf';flush privileges;\"  mysql -u root -ppassword --execute \"create user 'mpf'@'$(hostname)' IDENTIFIED by 'mpf';flush privileges;\"  mysql -u root -ppassword --execute \"create user 'mpf'@'localhost' IDENTIFIED by 'mpf';flush privileges;\"  mysql -u root -ppassword --execute \"grant all privileges on mpf.* to 'mpf';flush privileges;\"  sudo systemctl enable mysqld.service  sudo chkconfig --level 2345 mysqld on", 
            "title": "Configuring MySQL"
        }, 
        {
            "location": "/Build-Environment-Setup-Guide/#configuring-activemq", 
            "text": "Some additional manual configuration of ActiveMQ is required. For each step, open the specified file in a text editor, make the change, and save the file. If ActiveMQ is running, please stop it before making these changes.  Use Additional Memory  In  /opt/activemq/bin/env  (line 27), comment out the line:  ACTIVEMQ_OPTS_MEMORY= -Xms64M -Xmx1G   so that it reads:  #ACTIVEMQ_OPTS_MEMORY= -Xms64M -Xmx1G   Disable Persistence  In  /opt/activemq/conf/activemq.xml  (line 40), change the line:  broker xmlns= http://activemq.apache.org/schema/core  brokerName= localhost  dataDirectory= ${activemq.data}   so that it reads:  broker xmlns= http://activemq.apache.org/schema/core  brokerName= localhost  dataDirectory= ${activemq.data}  persistent= false   Respect Priorities  In  /opt/activemq/conf/activemq.xml  (line 44) under the line:  policyEntries   add the line:  policyEntry queue=  prioritizedMessages= true  useCache= false  expireMessagesPeriod= 0  queuePrefetch= 1  /   Enable JMX  In  /opt/activemq/conf/activemq.xml  (line 71), change the line:  managementContext createConnector= false /   so that it reads:  managementContext createConnector= true /   Change Log Conversion Pattern  In  /opt/activemq/conf/log4j.properties  (line 52), change the line:  log4j.appender.logfile.layout.ConversionPattern=%d | %-5p | %m | %c | %t%n  so that it reads:  log4j.appender.logfile.layout.ConversionPattern=%d %p [%t] %c - %m%n", 
            "title": "Configuring ActiveMQ"
        }, 
        {
            "location": "/Build-Environment-Setup-Guide/#configuring-redis", 
            "text": "Redis should be set to run in the background (i.e. as a daemon process).  In  /etc/redis.conf  (line 128), change the line:  daemonize no  so that it reads:  daemonize yes", 
            "title": "Configuring Redis"
        }, 
        {
            "location": "/Build-Environment-Setup-Guide/#https-configuration", 
            "text": "Generate a self-signed certificate and keystore   NOTE:   A valid keystore is required to run the OpenMPF with HTTPS support. These instructions will generate a keystore that should be used for local builds only. When deploying OpenMPF, a keystore containing a valid certificate trust chain should be used.    Open a new terminal window.  sudo systemctl stop tomcat7  cd /home/mpf  $JAVA_HOME/bin/keytool -genkey -alias tomcat -keyalg RSA  At the prompt, enter a keystore password of:  mpf123  Re-enter the keystore password of:  mpf123  At the  What is your first and last name?  prompt, press the Enter key for a blank value.  At the  What is the name of your organizational unit?  , press the Enter key for a blank value.  At the  What is the name of your organization?  prompt, press the Enter key for a blank value.  At the  What is the name of your City or Locality?  prompt, press the Enter key for a blank value.  At the  What is the name of your State or Province?  prompt, press the Enter key for a blank value.  At the  What is the two-letter country code for this unit?  prompt, press the Enter key for a blank value.  At the  Is CN=Unknown, OU=Unknown, O=Unknown, L=Unknown, ST=Unknown, C=Unknown correct?  prompt, type  yes  and press the Enter key to accept the values.  At the  Enter key password for  tomcat  prompt, press the Enter key for a blank value.  Verify the file  /home/mpf/.keystore  was created at the current time.   Tomcat Configuration   Open the file  /opt/apache-tomcat/conf/server.xml  in a text editor.  Below the commented out section on lines 87 through 90, add the following lines: Connector SSLEnabled=\"true\" acceptCount=\"100\" clientAuth=\"false\"\n    disableUploadTimeout=\"true\" enableLookups=\"false\" maxThreads=\"25\"\n    port=\"8443\" keystoreFile=\"/home/mpf/.keystore\" keystorePass=\"mpf123\"\n    protocol=\"org.apache.coyote.http11.Http11NioProtocol\" scheme=\"https\"\n    secure=\"true\" sslProtocol=\"TLS\" /  Save and close the file.  Create the file  /opt/apache-tomcat/bin/setenv.sh  and open it in a text editor.  Add the following line: export CATALINA_OPTS=\"-server -Xms256m -XX:PermSize=512m -XX:MaxPermSize=512m -Djgroups.tcp.port=7800 -Djava.library.path=$LD_LIBRARY_PATH -Djgroups.tcpping.initial_hosts='$ALL_MPF_NODES' -Dtransport.guarantee='CONFIDENTIAL' -Dweb.rest.protocol='https'\"  Save and close the file.   Using an IDE  If running Tomcat from an IDE, such as IntelliJ, then  -Dtransport.guarantee=\"CONFIDENTIAL\" -Dweb.rest.protocol=\"https\"  should be added at the end of the Tomcat VM arguments for your Tomcat run configuration. It is not necessary to add these arguments when running tomcat from the command line or a systemd command because of configured  CATALINA_OPTS  variable.", 
            "title": "HTTPS Configuration"
        }, 
        {
            "location": "/Build-Environment-Setup-Guide/#optional-http-configuration", 
            "text": "The OpenMPF can also be run using HTTP instead of HTTPS.   Open the file  /opt/apache-tomcat/conf/server.xml  in a text editor.  Below the commented out section on lines 87 through 90, remove the following lines if they exist: Connector SSLEnabled=\"true\" acceptCount=\"100\" clientAuth=\"false\"\n    disableUploadTimeout=\"true\" enableLookups=\"false\" maxThreads=\"25\"\n    port=\"8443\" keystoreFile=\"/home/mpf/.keystore\" keystorePass=\"mpf123\"\n    protocol=\"org.apache.coyote.http11.Http11NioProtocol\" scheme=\"https\"\n    secure=\"true\" sslProtocol=\"TLS\" /  Save and close the file.  Create the file  /opt/apache-tomcat/bin/setenv.sh  and open it in a text editor.  Add the following line: export CATALINA_OPTS=\"-server -Xms256m -XX:PermSize=512m -XX:MaxPermSize=512m -Djgroups.tcp.port=7800 -Djava.library.path=$LD_LIBRARY_PATH -Djgroups.tcpping.initial_hosts='$ALL_MPF_NODES' -Dtransport.guarantee='NONE' -Dweb.rest.protocol='http'\"  Save and close the file.", 
            "title": "(Optional) HTTP Configuration"
        }, 
        {
            "location": "/Build-Environment-Setup-Guide/#adding-additional-maven-dependencies", 
            "text": "Some Maven dependencies needed for the OpenMPF were not publicly available at the time this guide was written. These have been provided with the the OpenMPF source code located here  https://github.com/openmpf/openmpf-build-tools/blob/master/mpf-maven-deps.tar.gz . These steps assume the archive  mpf-maven-deps.tar.gz  is at  /home/mpf/openmpf-projects/openmpf-build-tools/mpf-maven-deps.tar.gz .   Set up the local Maven repository:  cd /home/mpf  mkdir -p .m2/repository    Extract the archive to the local Maven repository: tar xvzf /home/mpf/openmpf-projects/openmpf-build-tools/mpf-maven-deps.tar.gz -C /home/mpf/.m2/repository/", 
            "title": "Adding Additional Maven Dependencies"
        }, 
        {
            "location": "/Build-Environment-Setup-Guide/#building-and-packaging-the-openmpf", 
            "text": "The OpenMPF uses Apache Maven to automate software builds. The  mvn  commands in this guide are assumed to be run at the command line.", 
            "title": "Building and Packaging the OpenMPF"
        }, 
        {
            "location": "/Build-Environment-Setup-Guide/#build-environment", 
            "text": "The OpenMPF packaging script makes use of a directory /mpfdata with the following structure:    mpfdata - the top level directory containing the structure and non-source code artifacts to be packaged for distribution.\n  \u251c\u2500\u2500 ansible\n  \u2502   \u2514\u2500\u2500 install\n  \u2502       \u2514\u2500\u2500 repo\n  \u2502           \u251c\u2500\u2500 files - Any other uncategorized files needed by the OpenMPF.\n  \u2502           \u251c\u2500\u2500 pip - Dependency packages needed for the OpenMPF administration scripts. Installed with Python pip during deployment.\n  \u2502           \u251c\u2500\u2500 rpms - Contains all of the RPM packages needed for installing and running the OpenMPF. Installed with the yum package manager during deployment.\n  \u2502           \u2502   \u251c\u2500\u2500 management - RPM  packages needed for the OpenMPF deployment process.\n  \u2502           \u2502   \u251c\u2500\u2500 mpf - The OpenMPF RPM packages.\n  \u2502           \u2502   \u2514\u2500\u2500 mpf-deps - RPM packages needed by the OpenMPF.\n  \u2502           \u2514\u2500\u2500 tars - Binary packages in tar archives needed by the OpenMPF.\n  \u2514\u2500\u2500 releases - Contains the release package(s) that will be built.  Create the build environment structure:   sudo mkdir -p /mpfdata/ansible/install/repo/rpms/management  sudo mkdir /mpfdata/ansible/install/repo/rpms/mpf  sudo mkdir /mpfdata/ansible/install/repo/rpms/mpf-deps  sudo mkdir /mpfdata/ansible/install/repo/files  sudo mkdir /mpfdata/ansible/install/repo/pip  sudo mkdir /mpfdata/ansible/install/repo/tars  sudo mkdir /mpfdata/releases  sudo chown -R mpf:mpf /mpfdata", 
            "title": "Build Environment"
        }, 
        {
            "location": "/Build-Environment-Setup-Guide/#third-party-rpms-tars-and-python-pip-packages-included-with-an-openmpf-package", 
            "text": "As with the OpenMPF Build VM, the OpenMPF deployment package is targeted for a minimal install of CentOS 7. The  Package Lists  section lists required third-party dependencies that are packaged with the OpenMPF installation files by the  CreateCustomPackage.pl  script. Depending on which dependencies are already installed on your target system(s), some or all of these dependencies may not be needed. The script will only add the dependencies present in the  /mpfdata/ansible/install/repo/  directory to the package.  The following commands can be used to populate the dependency packages into the  /mpfdata/ansible/install/repo  directory:   yumdownloader --exclude=*.i?86 --archlist=x86_64 adwaita-cursor-theme adwaita-icon-theme at-spi2-atk at-spi2-core cairo-gobject colord-libs createrepo deltarpm ebtables gcc glibc glibc-common glibc-devel glibc-headers gtk3 httpd httpd-tools json-glib kernel-headers lcms2 libffi-devel libgusb libmng libselinux-python libtomcrypt libtommath libXevie libxml2 libxml2-python libXtst libyaml mailcap mpfr openssh openssh-askpass openssh-clients openssh-server pciutils py-bcrypt python python2-crypto python-babel python-backports python-backports-ssl_match_hostname python-cffi python-chardet python-crypto python-deltarpm python-devel python-ecdsa python-httplib2 python-jinja2 python-keyczar python-kitchen python-libs python-markupsafe python-paramiko python-passlib python-pip python-ply python-ptyprocess python-pyasn1 python-pycparser python-setuptools python-simplejson python-six python-slip python-slip-dbus PyYAML qt qt-settings qt-x11 rest sshpass yum-utils --destdir /mpfdata/ansible/install/repo/rpms/management -C  yumdownloader --exclude=*.i?86 --archlist=x86_64 apr apr-util apr-util-ldap atk avahi-libs cairo cdparanoia-libs cpp cups-libs fontconfig fontpackages-filesystem gdk-pixbuf2 graphite2 gsm gstreamer gstreamer1 gstreamer1-plugins-base gstreamer-plugins-base gstreamer-tools gtk2 gtk3 harfbuzz hicolor-icon-theme iso-codes jasper-libs jbigkit-libs jemalloc libdc1394 libICE libjpeg-turbo libmng libmpc libogg libpng libraw1394 libSM libthai libtheora libtiff libusbx libv4l libvisual libvorbis libvpx libX11 libX11-common libXau libxcb libXcomposite libXcursor libXdamage libXext libXfixes libXft libXi libXinerama libxml2 libXrandr libXrender libxshmfence libXv libXxf86vm log4cxx mesa-libEGL mesa-libgbm mesa-libGL mesa-libglapi mesa-libGLU mysql-community-client mysql-community-common mysql-community-libs mysql-community-server mysql-connector-python MySQL-python net-tools openjpeg-libs openssh openssh-clients openssh-server opus orc pango perl perl-Carp perl-Compress-Raw-Bzip2 perl-Compress-Raw-Zlib perl-constant perl-Data-Dumper perl-DBD-MySQL perl-DBI perl-Encode perl-Exporter perl-File-Path perl-File-Temp perl-Filter perl-Getopt-Long perl-HTTP-Tiny perl-IO-Compress perl-libs perl-macros perl-Net-Daemon perl-parent perl-PathTools perl-PlRPC perl-Pod-Escapes perl-podlators perl-Pod-Perldoc perl-Pod-Simple perl-Pod-Usage perl-Scalar-List-Utils perl-Socket perl-Storable perl-Text-ParseWords perl-threads perl-threads-shared perl-Time-HiRes perl-Time-Local pixman redis SDL speex unzip xml-common --destdir /mpfdata/ansible/install/repo/rpms/mpf-deps -C  cp /apps/source/ansible_sources/ansible/rpm-build/ansible-*.noarch.rpm /mpfdata/ansible/install/repo/rpms/management/  wget --no-cookies --header \"Cookie: oraclelicense=accept-securebackup-cookie\" \"http://download.oracle.com/otn-pub/java/jdk/8u60-b27/jdk-8u60-linux-x64.rpm\" -O /mpfdata/ansible/install/repo/rpms/mpf-deps/jdk-8u60-linux-x64.rpm  NOTE:  Oracle may require an account to download archived versions of the JRE.    Download jre-8u60-linux-x64.rpm and place it in  /mpfdata/ansible/install/repo/rpms/mpf-deps  :  http://www.oracle.com/technetwork/java/javase/downloads/java-archive-javase8-2177648.html#jre-8u60-oth-JPR  wget -O /mpfdata/ansible/install/repo/tars/apache-activemq-5.13.0-bin.tar.gz \"https://archive.apache.org/dist/activemq/5.13.0/apache-activemq-5.13.0-bin.tar.gz\"  wget -O /mpfdata/ansible/install/repo/tars/apache-tomcat-7.0.72.tar.gz \"http://archive.apache.org/dist/tomcat/tomcat-7/v7.0.72/bin/apache-tomcat-7.0.72.tar.gz\"  cd /mpfdata/ansible/install/repo/pip  pip install --download . argcomplete argh bcrypt cffi pycparser PyMySQL six", 
            "title": "Third-party RPMs, Tars, and Python Pip packages included with an OpenMPF Package"
        }, 
        {
            "location": "/Build-Environment-Setup-Guide/#build-the-open-source-openmpf-package", 
            "text": "Follow the instructions in the  Build the OpenMPF Package  section below. Use the following value for  configFile : /home/mpf/openmpf-projects/openmpf/trunk/jenkins/scripts/config_files/mpf-open-source-package.json", 
            "title": "Build the Open Source OpenMPF Package"
        }, 
        {
            "location": "/Build-Environment-Setup-Guide/#build-the-openmpf-package", 
            "text": "NOTE:  If your build environment is behind a proxy server, please read the appendix section  Proxy Configuration  for instructions to configure Maven before continuing.   In the instructions below, provide a positive integer value for  buildNum . If this is your first build, provide a \"1\". If this is your second build then provide a \"2\", so on and so forth. The build number will be displayed on the login screen.    Remove the development properties file:   cd /home/mpf/openmpf-projects/openmpf  rm -f trunk/workflow-manager/src/main/resources/properties/mpf-private.properties     (Optional) run maven clean if there has been a previous software build:\n       mvn clean   Run the Perl  PackageRPMS.pl  script. This will compile the code artifacts, place them in the local maven repository, and create the necessary component RPMs and tar files.  cd /home/mpf/openmpf-projects/openmpf/trunk/jenkins/scripts  perl PackageRPMS.pl /home/mpf/openmpf-projects/openmpf master 0  buildNum   configFile    After the build is complete, the final package is created by running the Perl script  CreateCustomPackage.pl :  cd /home/mpf/openmpf-projects/openmpf/trunk/jenkins/scripts  perl CreateCustomPackage.pl /home/mpf/openmpf-projects/openmpf master  buildNum   configFile    The package  openmpf-*+master-0.tar.gz  will be under  /mpfdata/releases/ .  (Optional) Copy the development properties file back if you wish to run the OpenMPF on the OpenMPF Build VM: cp /home/mpf/openmpf-projects/openmpf/trunk/workflow-manager/src/main/resources/properties/mpf-private-example.properties /home/mpf/openmpf-projects/openmpf/trunk/workflow-manager/src/main/resources/properties/mpf-private.properties", 
            "title": "Build the OpenMPF Package"
        }, 
        {
            "location": "/Build-Environment-Setup-Guide/#optional-testing-the-openmpf", 
            "text": "NOTE:  If your build environment is behind a proxy server, please read the appendix section  Proxy Configuration  for instructions to configure Firefox before continuing.   Run these commands to build the OpenMPF and run the integration tests:   cd /home/mpf/openmpf-projects/openmpf   Copy the development properties file into place:  cp trunk/workflow-manager/src/main/resources/properties/mpf-private-example.properties trunk/workflow-manager/src/main/resources/properties/mpf-private.properties    Open the file  /etc/ansible/hosts  in a text editor.  sudo  is required to edit this file.    If they do not already exist, add these two lines above  # Ex 1: Ungrouped hosts, specify before any group headers.  (line 11):  [mpf-child]\nlocalhost.localdomain    Save and close the file.   mvn clean install -DskipTests -Dmaven.test.skip=true -DskipITs -Dmaven.tomcat.skip=true -Dcomponents.build.package.json= configFile  -Dcomponents.build.dir=/home/mpf/openmpf-projects/openmpf/mpf-component-build -Dstartup.auto.registration.skip=false  sudo cp /home/mpf/openmpf-projects/openmpf/trunk/install/libexec/node-manager /etc/init.d/  sudo systemctl daemon-reload  mpf start --xtc  (This command will start ActiveMQ, MySQL, Redis, and node-manager; not Tomcat.)  mvn verify -Dtransport.guarantee=\"NONE\" -Dweb.rest.protocol=\"http\" -Dcomponents.build.package.json= configFile  -Dstartup.auto.registration.skip=false -Dcomponents.build.dir=/home/mpf/openmpf-projects/openmpf/mpf-component-build  mpf stop --xtc  (This command will stop node-manager, Redis, MySQL, and ActiveMQ; not Tomcat.)    NOTE:  Please see the appendix section  Known Issues  regarding any  java.lang.InterruptedException: null  warning log messages observed when running the tests.", 
            "title": "(Optional) Testing the OpenMPF"
        }, 
        {
            "location": "/Build-Environment-Setup-Guide/#optional-building-and-running-the-web-application", 
            "text": "NOTE:  If your build environment is behind a proxy server, please read the appendix section  Proxy Configuration  for instructions to configure Firefox before continuing.   Run these commands to build the OpenMPF and launch the web application:   cd /home/mpf/openmpf-projects/openmpf   Copy the development properties file into place:  cp trunk/workflow-manager/src/main/resources/properties/mpf-private-example.properties trunk/workflow-manager/src/main/resources/properties/mpf-private.properties    Open the file  /etc/ansible/hosts  in a text editor.  sudo  is required to edit this file.    If they do not already exist, add these two lines above  # Ex 1: Ungrouped hosts, specify before any group headers.  (line 11):  [mpf-child]\nlocalhost.localdomain    Save and close the file.   mvn clean install -DskipTests -Dmaven.test.skip=true -DskipITs -Dmaven.tomcat.skip=true  -Dcomponents.build.package.json= configFile  -Dstartup.auto.registration.skip=false -Dcomponents.build.dir=/home/mpf/openmpf-projects/openmpf/mpf-component-build  cd /home/mpf/openmpf-projects/openmpf/trunk/workflow-manager  rm -rf /opt/apache-tomcat/webapps/workflow-manager*  cp target/workflow-manager.war /opt/apache-tomcat/webapps/workflow-manager.war  cd ../..  sudo cp trunk/install/libexec/node-manager /etc/init.d/  sudo systemctl daemon-reload  mpf start   The web application should start running in the background as a daemon. Look for this log message in the Tomcat log ( /opt/apache-tomcat/logs/catalina.out ) with a time value indicating the workflow-manager has finished starting:  INFO: Server startup in 39030 ms  After startup, the workflow-manager will be available at  http://localhost:8080/workflow-manager . Connect to this URL with FireFox. Chrome is also supported, but is not pre-installed on the VM.  If you want to test regular user capabilities, log in as 'mpf'. Please see the  OpenMPF User Guide  for more information. Alternatively, if you want to test admin capabilities then log in as 'admin'. Please see the  OpenMPF Admin Manual  for more information. When finished testing using the browser (or other external clients), go back to the terminal window used to launch Tomcat and enter the stop command  mpf stop .   NOTE:  Through the use of port forwarding, the workflow-manager can also be accessed from your guest operating system. Please see the Virtual Box documentation  https://www.virtualbox.org/manual/ch06.html#natforward  for configuring port forwarding.   The preferred method to start and stop services for OpenMPF is with the  mpf start  and  mpf stop  commands. For additional information on these commands, please see the  Command Line Tools  section of the  OpenMPF Admin Manual . These will start and stop ActiveMQ, MySQL, Redis, node-manager, and Tomcat, respectively. Alternatively, to perform these actions manually, the following commands can be used in a terminal window:  Starting  /opt/activemq/bin/activemq start\nsudo systemctl start mysqld\nsudo redis-server /etc/redis.conf\nsudo systemctl start node-manager\n/opt/apache-tomcat/bin/catalina.sh run  Stopping  /opt/apache-tomcat/bin/catalina.sh run\n# Wait 60 seconds for tomcat to stop.\nsudo systemctl stop node-manager\nredis-cli flushall\nredis-cli shutdown\nsudo systemctl stop mysqld\n/opt/activemq/bin/activemq stop   NOTE:  For debugging purposes, it may be helpful to manually start the Tomcat service in a separate terminal window. This will display the log output directly to the terminal. Wait at least one minute for Tomcat to exit and the node manager to perform some cleanup tasks. If the node manager is stopped too early after quitting Tomcat, some of the processes it was responsible for launching may continue to run.", 
            "title": "(Optional) Building and running the web application"
        }, 
        {
            "location": "/Build-Environment-Setup-Guide/#default-credentials", 
            "text": "Regular User  username:  mpf  password:  mpf123    Administrator  username:  admin  password:  mpfadm", 
            "title": "Default Credentials"
        }, 
        {
            "location": "/Build-Environment-Setup-Guide/#deploying-the-openmpf", 
            "text": "Please see the  OpenMPF Installation Guide .", 
            "title": "Deploying the OpenMPF"
        }, 
        {
            "location": "/Build-Environment-Setup-Guide/#appendices", 
            "text": "", 
            "title": "Appendices"
        }, 
        {
            "location": "/Build-Environment-Setup-Guide/#known-issues", 
            "text": "The following are known issues that are related to setting up and running the OpenMPF on a build VM. For a more complete list of known issues, please see the OpenMPF Release Notes.  Test Exceptions  When running the tests, you may observe warning log messages similar to this:  //2016-07-25 16:16:27,848 WARN [Time-limited test] org.mitre.mpf.mst.TestSystem - Exception occurred while waiting. Assuming that the job has completed (but failed)\njava.lang.InterruptedException: null\n    at java.lang.Object.wait(Native Method) ~[na:1.8.0_60]\n    at java.lang.Object.wait(Object.java:502) ~[na:1.8.0_60]\n    at org.mitre.mpf.mst.TestSystem.waitFor(TestSystem.java:209) [test-classes/:na]\n    at org.mitre.mpf.mst.TestSystem.runPipelineOnMedia(TestSystem.java:201) [test-classes/:na]\n    at org.mitre.mpf.mst.TestSystemOnDiff.runSpeechSphinxDetectAudio(TestSystemOnDiff.java:250) [test-classes/:na]\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_60]\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_60]\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_60]\n    at java.lang.reflect.Method.invoke(Method.java:497) ~[na:1.8.0_60]\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) [junit-4.12.jar:4.12]\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.12.jar:4.12]\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) [junit-4.12.jar:4.12]\n    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.12.jar:4.12]\n    at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:75) [spring-test-4.2.5.RELEASE.jar:4.2.5.RELEASE]\n    at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:86) [spring-test-4.2.5.RELEASE.jar:4.2.5.RELEASE]\n    at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:84) [spring-test-4.2.5.RELEASE.jar:4.2.5.RELEASE]\n    at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298) [junit-4.12.jar:4.12]\n    at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292) [junit-4.12.jar:4.12]\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_60]\n    at java.lang.Thread.run(Thread.java:745) [na:1.8.0_60]//  This does not necessarily indicate any type of software bug. The most likely cause for this message is that a test has timed out. Increasing the available system resources or increasing the test timeout values may help.  Time Differences Between OpenMPF Nodes  When installing OpenMPF on multiple nodes, an NTP service should be set up on each of the systems in the cluster so that their times are synchronized. Otherwise, the log viewer may behave incorrectly when it updates in real time.", 
            "title": "Known Issues"
        }, 
        {
            "location": "/Build-Environment-Setup-Guide/#proxy-configuration", 
            "text": "Yum Package Manager Proxy Configuration  Before using the yum package manager,  it may be necessary to configure it to work with your environment's proxy settings. If credentials are not required, it is not necessary to add them to the yum configuration.   sudo bash -c 'echo \"proxy= address : port \"   /etc/yum.conf'  sudo bash -c 'echo \"proxy_username= username \"   /etc/yum.conf'  sudo bash -c 'echo \"proxy_password= password \"   /etc/yum.conf'   Proxy Environment Variables  If your build environment is behind a proxy server, some applications and tools will need to be configured to use it. To configure an HTTP and HTTPS proxy, run the following commands. If credentials are not required, leave those fields blank.   sudo bash -c 'echo \"export http_proxy= username : password @ url : port \"   /etc/profile.d/mpf.sh  . /etc/profile.d/mpf.sh  sudo bash -c 'echo \"export https_proxy='${http_proxy}'\"   /etc/profile.d/mpf.sh'  sudo bash -c 'echo \"export HTTP_PROXY='${http_proxy}'\"   /etc/profile.d/mpf.sh'  sudo bash -c 'echo \"export HTTPS_PROXY='${http_proxy}'\"   /etc/profile.d/mpf.sh'  . /etc/profile.d/mpf.sh   Git Proxy Configuration  If your build environment is behind a proxy server, git will need to be configured to use it. The following command will set the git global proxy. If the environment variable  $http_proxy  is not set, use the full proxy server address, port, and credentials (if needed).\n      git config --global http.proxy $http_proxy  Firefox Proxy Configuration  Before running the integration tests and the web application, it may be necessary to configure Firefox with your environment's proxy settings.   In a new terminal window, type  firefox  and press enter. This will launch a new Firefox window.  In the new Firefox window, enter  about:preferences#advanced  in the URL text box and press enter.  In the left sidebar click 'Advanced', then click the  Network  tab, and in the  Connection  section press the 'Settings...' button.  Enter the proxy settings for your environment.  In the 'No Proxy for:' text box, verify that  localhost  is included.  Press the 'OK' button.  Close all open Firefox instances.   Maven Proxy Configuration  Before using Maven, it may be necessary to configure it to work with your environment's proxy settings. Open a new terminal window and run these commands. Afterwards, continue with adding the additional maven dependencies.   cd /home/mpf  mkdir -p .m2  cp /opt/apache-maven/conf/settings.xml .m2/  Open the file  .m2/settings.xml  in a text editor.  Navigate to the  proxies  section (line 85).  There is a commented-out example proxy server specification. Copy and paste the example specification below the commented-out section, but before the end of the closing  /proxies  tag.  Fill in your environment's proxy server information. For additional help and information, please see the Apache Maven guide to configuring a proxy server at  https://maven.apache.org/guides/mini/guide-proxies.html .", 
            "title": "Proxy Configuration"
        }, 
        {
            "location": "/Build-Environment-Setup-Guide/#ssl-inspection", 
            "text": "If your build environment is behind a proxy server that performs SSL inspection, some applications and tools will need to be configured to accommodate it. The following steps will add trusted certificates to the OpenMPF VM.  Additional information on Java keytool can be found at  https://docs.oracle.com/javase/8/docs/technotes/tools/unix/keytool.html .   Download any certificates needed for using SSL in your build environment to  /home/mpf/Downloads .  Verify that  $JAVA_HOME  is set correctly.\n      Running this command:  echo $JAVA_HOME  should produce this output:  /usr/java/latest  For each certificate, run this command, filling in the values for certificate alias, certificate name, and keystore passphrase:\n       sudo $JAVA_HOME/bin/keytool -import -alias  certificate alias  -file /home/mpf/Downloads/ certificate name .crt -keystore \"$JAVA_HOME/jre/lib/security/cacerts\" -storepass  keystore passphrase  -noprompt  For each certificate, run this command, filling in the value for certificate name:\n       sudo cp /home/mpf/Downloads/ certificate name .crt /tmp  For each certificate, run this command, filling in the values for certificate name:\n       sudo -u root -H sh -c \"openssl x509 -in /tmp/ certificate name .crt    -text   /etc/pki/ca-trust/source/anchors/ certificate name .pem\"  Run these commands once:  sudo -u root -H sh -c \"update-ca-trust enable\"  sudo -u root -H sh -c \"update-ca-trust extract\"    Run these commands once, filling in the value for the root certificate name:  sudo cp /etc/pki/tls/certs/ca-bundle.crt /etc/pki/tls/certs/ca-bundle.crt.original  sudo -u root -H sh -c \"cat /etc/pki/ca-trust/source/anchors/ root certificate name .pem   /etc/pki/tls/certs/ca-bundle.crt\"     Alternatively, if adding certificates is not an option or difficulties are encountered, you may optionally skip SSL certificate verification for these tools. This is not recommended:  wget   cd /home/mpf  touch /home/mpf/.wgetrc  In a text editor, open the file  /home/mpf/.wgetrc   Add this line:  check_certificate=off    Save and close the file.   . /home/mpf/.wgetrc   git   cd /home/mpf  git config http.sslVerify false  git config --global http.sslVerify false   maven   In a text editor, open the file  /etc/profile.d/mpf.sh  At the bottom of the file, add this line: export MAVEN_OPTS=\"-Dmaven.wagon.http.ssl.insecure=true -Dmaven.wagon.http.ssl.allowall=true -Dmaven.wagon.http.ssl.ignore.validity.dates=true\"  Save and close the file.  . /etc/profile.d/mpf.sh", 
            "title": "SSL Inspection"
        }, 
        {
            "location": "/Build-Environment-Setup-Guide/#package-lists", 
            "text": "/mpfdata/ansible/install/repo/rpms/management   adwaita-cursor-theme-3.14.1-1.el7.noarch.rpm  adwaita-icon-theme-3.14.1-1.el7.noarch.rpm  ansible-2.1.1.0-0.git201608081816.e71cce7.HEAD.el7.centos.noarch.rpm  at-spi2-atk-2.14.1-1.el7.x86_64.rpm  at-spi2-core-2.14.1-2.el7.x86_64.rpm  cairo-gobject-1.14.2-1.el7.x86_64.rpm  colord-libs-1.2.7-2.el7.x86_64.rpm  createrepo-0.9.9-26.el7.noarch.rpm  deltarpm-3.6-3.el7.x86_64.rpm  ebtables-2.0.10-15.el7.x86_64.rpm  gcc-4.8.5-11.el7.x86_64.rpm  glibc-2.17-157.el7_3.1.x86_64.rpm  glibc-common-2.17-157.el7_3.1.x86_64.rpm  glibc-devel-2.17-157.el7_3.1.x86_64.rpm  glibc-headers-2.17-157.el7_3.1.x86_64.rpm  gtk3-3.14.13-20.el7.x86_64.rpm  httpd-2.4.6-45.el7.centos.4.x86_64.rpm  httpd-tools-2.4.6-45.el7.centos.4.x86_64.rpm  json-glib-1.0.2-1.el7.x86_64.rpm  kernel-headers-3.10.0-514.16.1.el7.x86_64.rpm  lcms2-2.6-3.el7.x86_64.rpm  libffi-devel-3.0.13-18.el7.x86_64.rpm  libgusb-0.1.6-3.el7.x86_64.rpm  libmng-1.0.10-14.el7.x86_64.rpm  libselinux-python-2.5-6.el7.x86_64.rpm  libtomcrypt-1.17-23.el7.x86_64.rpm  libtommath-0.42.0-4.el7.x86_64.rpm  libXevie-1.0.3-7.1.el7.x86_64.rpm  libxml2-2.9.1-6.el7_2.3.x86_64.rpm  libxml2-python-2.9.1-6.el7_2.3.x86_64.rpm  libXtst-1.2.2-2.1.el7.x86_64.rpm  libyaml-0.1.4-11.el7_0.x86_64.rpm  mailcap-2.1.41-2.el7.noarch.rpm  mpfr-3.1.1-4.el7.x86_64.rpm  openssh-6.6.1p1-35.el7_3.x86_64.rpm  openssh-askpass-6.6.1p1-35.el7_3.x86_64.rpm  openssh-clients-6.6.1p1-35.el7_3.x86_64.rpm  openssh-server-6.6.1p1-35.el7_3.x86_64.rpm  pciutils-3.5.1-1.el7.x86_64.rpm  py-bcrypt-0.4-4.el7.x86_64.rpm  python-2.7.5-48.el7.x86_64.rpm  python2-crypto-2.6.1-13.el7.x86_64.rpm  python2-pip-8.1.2-5.el7.noarch.rpm  python2-ptyprocess-0.5.1-6.el7.noarch.rpm  python2-pyasn1-0.1.9-7.el7.noarch.rpm  python2-simplejson-3.10.0-1.el7.x86_64.rpm  python-babel-0.9.6-8.el7.noarch.rpm  python-backports-1.0-8.el7.x86_64.rpm  python-backports-ssl_match_hostname-3.4.0.2-4.el7.noarch.rpm  python-cffi-1.6.0-5.el7.x86_64.rpm  python-chardet-2.2.1-1.el7_1.noarch.rpm  python-crypto-2.6.1-1.el7.centos.x86_64.rpm  python-deltarpm-3.6-3.el7.x86_64.rpm  python-devel-2.7.5-48.el7.x86_64.rpm  python-ecdsa-0.11-3.el7.centos.noarch.rpm  python-httplib2-0.7.7-3.el7.noarch.rpm  python-jinja2-2.7.2-2.el7.noarch.rpm  python-keyczar-0.71c-2.el7.noarch.rpm  python-kitchen-1.1.1-5.el7.noarch.rpm  python-libs-2.7.5-48.el7.x86_64.rpm  python-markupsafe-0.11-10.el7.x86_64.rpm  python-paramiko-1.12.4-1.el7.centos.noarch.rpm  python-passlib-1.6.2-2.el7.noarch.rpm  python-ply-3.4-10.el7.noarch.rpm  python-pycparser-2.14-1.el7.noarch.rpm  python-setuptools-0.9.8-4.el7.noarch.rpm  python-six-1.9.0-2.el7.noarch.rpm  python-slip-0.4.0-2.el7.noarch.rpm  python-slip-dbus-0.4.0-2.el7.noarch.rpm  PyYAML-3.10-11.el7.x86_64.rpm  qt-4.8.5-13.el7.x86_64.rpm  qt-settings-19-23.5.el7.centos.noarch.rpm  qt-x11-4.8.5-13.el7.x86_64.rpm  rest-0.7.92-5.el7.x86_64.rpm  sshpass-1.06-1.el7.x86_64.rpm  yum-utils-1.1.31-40.el7.noarch.rpm     /mpfdata/ansible/install/repo/rpms/mpf-deps   apr-1.4.8-3.el7.x86_64.rpm  apr-util-1.5.2-6.el7.x86_64.rpm  apr-util-ldap-1.5.2-6.el7.x86_64.rpm  atk-2.14.0-1.el7.x86_64.rpm  avahi-libs-0.6.31-17.el7.x86_64.rpm  cairo-1.14.2-1.el7.x86_64.rpm  cdparanoia-libs-10.2-17.el7.x86_64.rpm  cpp-4.8.5-11.el7.x86_64.rpm  cups-libs-1.6.3-26.el7.x86_64.rpm  fontconfig-2.10.95-10.el7.x86_64.rpm  fontpackages-filesystem-1.44-8.el7.noarch.rpm  gdk-pixbuf2-2.31.6-3.el7.x86_64.rpm  graphite2-1.3.6-1.el7_2.x86_64.rpm  gsm-1.0.13-11.el7.x86_64.rpm  gstreamer-0.10.36-7.el7.x86_64.rpm  gstreamer1-1.4.5-1.el7.x86_64.rpm  gstreamer1-plugins-base-1.4.5-2.el7.x86_64.rpm  gstreamer-plugins-base-0.10.36-10.el7.x86_64.rpm  gstreamer-tools-0.10.36-7.el7.x86_64.rpm  gtk2-2.24.28-8.el7.x86_64.rpm  gtk3-3.14.13-20.el7.x86_64.rpm  harfbuzz-0.9.36-1.el7.x86_64.rpm  hicolor-icon-theme-0.12-7.el7.noarch.rpm  iso-codes-3.46-2.el7.noarch.rpm  jasper-libs-1.900.1-29.el7.x86_64.rpm  jbigkit-libs-2.0-11.el7.x86_64.rpm  jdk-8u60-linux-x64.rpm  jemalloc-3.6.0-1.el7.x86_64.rpm  jre-8u60-linux-x64.rpm  libdc1394-2.2.2-3.el7.x86_64.rpm  libICE-1.0.9-2.el7.x86_64.rpm  libjpeg-turbo-1.2.90-5.el7.x86_64.rpm  libmng-1.0.10-14.el7.x86_64.rpm  libmpc-1.0.1-3.el7.x86_64.rpm  libogg-1.3.0-7.el7.x86_64.rpm  libpng-1.5.13-7.el7_2.x86_64.rpm  libraw1394-2.1.0-2.el7.x86_64.rpm  libSM-1.2.2-2.el7.x86_64.rpm  libthai-0.1.14-9.el7.x86_64.rpm  libtheora-1.1.1-8.el7.x86_64.rpm  libtiff-4.0.3-27.el7_3.x86_64.rpm  libusbx-1.0.20-1.el7.x86_64.rpm  libv4l-0.9.5-4.el7.x86_64.rpm  libvisual-0.4.0-16.el7.x86_64.rpm  libvorbis-1.3.3-8.el7.x86_64.rpm  libvpx-1.3.0-5.el7_0.x86_64.rpm  libX11-1.6.3-3.el7.x86_64.rpm  libX11-common-1.6.3-3.el7.noarch.rpm  libXau-1.0.8-2.1.el7.x86_64.rpm  libxcb-1.11-4.el7.x86_64.rpm  libXcomposite-0.4.4-4.1.el7.x86_64.rpm  libXcursor-1.1.14-2.1.el7.x86_64.rpm  libXdamage-1.1.4-4.1.el7.x86_64.rpm  libXext-1.3.3-3.el7.x86_64.rpm  libXfixes-5.0.1-2.1.el7.x86_64.rpm  libXft-2.3.2-2.el7.x86_64.rpm  libXi-1.7.4-2.el7.x86_64.rpm  libXinerama-1.1.3-2.1.el7.x86_64.rpm  libxml2-2.9.1-6.el7_2.3.x86_64.rpm  libXrandr-1.4.2-2.el7.x86_64.rpm  libXrender-0.9.8-2.1.el7.x86_64.rpm  libxshmfence-1.2-1.el7.x86_64.rpm  libXv-1.0.10-2.el7.x86_64.rpm  libXxf86vm-1.1.3-2.1.el7.x86_64.rpm  log4cxx-0.10.0-16.el7.x86_64.rpm  mesa-libEGL-11.2.2-2.20160614.el7.x86_64.rpm  mesa-libgbm-11.2.2-2.20160614.el7.x86_64.rpm  mesa-libGL-11.2.2-2.20160614.el7.x86_64.rpm  mesa-libglapi-11.2.2-2.20160614.el7.x86_64.rpm  mesa-libGLU-9.0.0-4.el7.x86_64.rpm  mysql-community-client-5.6.36-2.el7.x86_64.rpm  mysql-community-common-5.6.36-2.el7.x86_64.rpm  mysql-community-libs-5.6.36-2.el7.x86_64.rpm  mysql-community-server-5.6.36-2.el7.x86_64.rpm  mysql-connector-python-2.0.4-1.el7.noarch.rpm  mysql-connector-python-2.1.6-1.el7.x86_64.rpm  MySQL-python-1.2.5-1.el7.x86_64.rpm  net-tools-2.0-0.17.20131004git.el7.x86_64.rpm  openjpeg-libs-1.5.1-16.el7_3.x86_64.rpm  openssh-6.6.1p1-35.el7_3.x86_64.rpm  openssh-clients-6.6.1p1-35.el7_3.x86_64.rpm  openssh-server-6.6.1p1-35.el7_3.x86_64.rpm  opus-1.0.2-6.el7.x86_64.rpm  orc-0.4.22-5.el7.x86_64.rpm  pango-1.36.8-2.el7.x86_64.rpm  perl-5.16.3-291.el7.x86_64.rpm  perl-Carp-1.26-244.el7.noarch.rpm  perl-Compress-Raw-Bzip2-2.061-3.el7.x86_64.rpm  perl-Compress-Raw-Zlib-2.061-4.el7.x86_64.rpm  perl-constant-1.27-2.el7.noarch.rpm  perl-Data-Dumper-2.145-3.el7.x86_64.rpm  perl-DBD-MySQL-4.023-5.el7.x86_64.rpm  perl-DBI-1.627-4.el7.x86_64.rpm  perl-Encode-2.51-7.el7.x86_64.rpm  perl-Exporter-5.68-3.el7.noarch.rpm  perl-File-Path-2.09-2.el7.noarch.rpm  perl-File-Temp-0.23.01-3.el7.noarch.rpm  perl-Filter-1.49-3.el7.x86_64.rpm  perl-Getopt-Long-2.40-2.el7.noarch.rpm  perl-HTTP-Tiny-0.033-3.el7.noarch.rpm  perl-IO-Compress-2.061-2.el7.noarch.rpm  perl-libs-5.16.3-291.el7.x86_64.rpm  perl-macros-5.16.3-291.el7.x86_64.rpm  perl-Net-Daemon-0.48-5.el7.noarch.rpm  perl-parent-0.225-244.el7.noarch.rpm  perl-PathTools-3.40-5.el7.x86_64.rpm  perl-PlRPC-0.2020-14.el7.noarch.rpm  perl-Pod-Escapes-1.04-291.el7.noarch.rpm  perl-podlators-2.5.1-3.el7.noarch.rpm  perl-Pod-Perldoc-3.20-4.el7.noarch.rpm  perl-Pod-Simple-3.28-4.el7.noarch.rpm  perl-Pod-Usage-1.63-3.el7.noarch.rpm  perl-Scalar-List-Utils-1.27-248.el7.x86_64.rpm  perl-Socket-2.010-4.el7.x86_64.rpm  perl-Storable-2.45-3.el7.x86_64.rpm  perl-Text-ParseWords-3.29-4.el7.noarch.rpm  perl-threads-1.87-4.el7.x86_64.rpm  perl-threads-shared-1.43-6.el7.x86_64.rpm  perl-Time-HiRes-1.9725-3.el7.x86_64.rpm  perl-Time-Local-1.2300-2.el7.noarch.rpm  pixman-0.34.0-1.el7.x86_64.rpm  redis-3.2.8-1.el7.remi.x86_64.rpm  SDL-1.2.15-14.el7.x86_64.rpm  speex-1.2-0.19.rc1.el7.x86_64.rpm  unzip-6.0-16.el7.x86_64.rpm  xml-common-0.6.3-39.el7.noarch.rpm     /mpfdata/ansible/install/repo/tars   apache-activemq-5.13.0-bin.tar.gz  apache-tomcat-7.0.72.tar.gz     /mpfdata/ansible/install/repo/pip   argcomplete-1.8.2-py2.py3-none-any.whl  argh-0.26.2-py2.py3-none-any.whl  bcrypt-3.1.3-cp27-cp27mu-manylinux1_x86_64.whl  cffi-1.10.0-cp27-cp27mu-manylinux1_x86_64.whl  pycparser-2.17.tar.gz  PyMySQL-0.7.11-py2.py3-none-any.whl  six-1.10.0-py2.py3-none-any.whl", 
            "title": "Package Lists"
        }, 
        {
            "location": "/Build-Environment-Setup-Guide/#build-and-test-environment", 
            "text": "When developing for the OpenMPF, you may find the following collaboration and continuous integration tools helpful.  Jenkins  https://jenkins.io  Phabricator  https://www.phacility.com/phabricator", 
            "title": "Build and Test Environment"
        }, 
        {
            "location": "/Installation/", 
            "text": "NOTICE:\n This software (or technical data) was produced for the U.S. Government under contract, and is subject to the Rights in Data-General Clause 52.227-14, Alt. IV (DEC 2007).\nCopyright 2017 The MITRE Corporation. All Rights Reserved.\n\n\n\n\nMinimum Resource Requirements\n\n\nHardware\n\n\nOpenMPF performs best when processing is distributed across a cluster of computers; a minimum of one dedicated server is required that provides the following:\n\n\n\n\n4 Central Processing Units (CPUs)\n\n\n4GB Random Access Memory (RAM), \nalthough in any operational use case environment at least 16GB of RAM is recommended\n\n\n40GB hard disk space, \nwith additional space to store media and processed objects\n\n\n\n\nIn a cluster configuration, participating servers are referred to as \nnodes\n, with one controlling node designated as the \nmaster\n node and the others designated as \nchild\n nodes.  In this case, a shared file system accessible to all participating nodes is also required.\n\n\nThe \nmaster\n contains the Workflow manager, ActiveMQ, MySQL, an instance of the OpenMPF process manager, named the \nNode Manager\n. A \nchild\n contains only a node manager and processing components/algorithms.\n\n\nBelow is an example layout of an OpenMPF cluster consisting of 3 nodes:\n\n\n\n\nOperating System and Software\n\n\nOpenMPF runs on the CentOS 7 operating system, with Linux firewall (iptables) disabled and Linux SELINUX in permissive state (disabled is the preferred state to limit logging activity).\n\n\nA browser is required in order to utilize the OpenMPF Web User Interface (UI). The officially supported browsers are FireFox and Chrome. Although other browsers might work, they have not been thoroughly tested and might not display or function properly.\n\n\nOpenMPF Pre-Installation\n\n\n\n\nImportant:\n Please verify that all steps in the Pre-installation Checklist are completed \nprior\n to cluster configuration.\n\n\n\n\nPre-Installation Checklist\n\n\nOpenMPF Installation\n\n\n\n\nYou only need to complete the following steps on the OpenMPF master node.\n\n\n\n\n 1. Install and Configure OpenMPF Management Software \n\n\nCopy the OpenMPF release package .tar.gz, (e.g. openmpf-open-source-0.9.0+master.tar.gz) to the OpenMPF master node.\n\n\nFrom the OpenMPF master node, unpack the OpenMPF package.\n\n\ntar zxvf \nlatest .tar.gz\n\ncd mpf-release\nsudo sh install-mpf.sh\n\n\n\n\n 2. Configure the OpenMPF Cluster \n\n\n\n\nNote: A master node will \nnot\n run any services unless it is also designated and configured as a child. Think of a child as a worker in the OpenMPF cluster. Thus, in a single server environment it is mandatory to designate the host as both a master and child in order to do any meaningful processing (e.g. detection). By default, the master only runs the workflow manager web app, AMQ, Redis and MySQL.\n\n\nNote: When prompted for username and password, use the same username and password you used to log in to the master node.\n\n\nNote: When prompted for hostnames, only put in the hostnames (e.g., node-1), DO NOT put in the fully qualified domain name (e.g., node-1.example.org) or OpenMPF will behave in strange ways.\n\n\n\n\nsudo sh /opt/mpf/manage/configure-cluster.sh\n\n\n\n\n 3. Push OpenMPF Configuration to OpenMPF Nodes\n\n\n\n\nNote: Early in the script you will be prompted for the OpenMPF password. Use \"mpf\".\n\n\n\n\n# As the \nmpf\n user (you may need to log out and log back in):\n. /opt/mpf/manage/push-configuration.sh\n\n\n\n\n 4. Complete Node Configuration \n\n\nOpenMPF is now running (no reboot required).\n\n\nTo complete node configuration:\n\n\n\n\nFrom the master node, browse to: http://localhost:8080/workflow-manager\n\n\nLogin as the administrator (username: \"admin\" / password: \"mpfadm\")\n\n\nGo to the Nodes page and add detection services as desired\n\n\n\n\nUpdating Site Configuration\n\n\nYou can add or remove nodes and change other configuration options once OpenMPF has already been installed.\n\n\n# As the \nmpf\n user:\nmpf stop\nsudo sh /opt/mpf/manage/configure-cluster.sh\n/opt/mpf/manage/push-configuration.sh\n\n\n\n\nCreating a Keystore\n\n\n\n\nIMPORTANT: This is not recommended for a production environment.\n\n\n\n\nThese instructions will create a keystore with a self-signed certificate at /home/mpf/.keystore.\n\n\n\n\nOpen a new terminal window.\n\n\nsudo systemctl stop tomcat7\n\n\ncd /home/mpf\n\n\nkeytool -genkey -alias tomcat -keyalg RSA\n\n\nAt the prompt, enter a keystore password of: \nmpf123\n\n\nRe-enter the keystore password of: \nmpf123\n\n\nAt the \nWhat is your first and last name?\n prompt, press the Enter key for a blank value.\n\n\nAt the \nWhat is the name of your organizational unit?\n , press the Enter key for a blank value.\n\n\nAt the \nWhat is the name of your organization?\n prompt, press the Enter key for a blank value.\n\n\nAt the \nWhat is the name of your City or Locality?\n prompt, press the Enter key for a blank value.\n\n\nAt the \nWhat is the name of your State or Province?\n prompt, press the Enter key for a blank value.\n\n\nAt the \nWhat is the two-letter country code for this unit?\n prompt, press the Enter key for a blank value.\n\n\nAt the \nIs CN=Unknown, OU=Unknown, O=Unknown, L=Unknown, ST=Unknown, C=Unknown correct?\n prompt, press the Enter key to accept the values.\n\n\nAt the \nEnter key password for \ntomcat\n prompt, press the Enter key for a blank value.\n\n\nVerify the file \n/home/mpf/.keystore\n was created at the current time.", 
            "title": "Install Guide"
        }, 
        {
            "location": "/Installation/#minimum-resource-requirements", 
            "text": "", 
            "title": "Minimum Resource Requirements"
        }, 
        {
            "location": "/Installation/#hardware", 
            "text": "OpenMPF performs best when processing is distributed across a cluster of computers; a minimum of one dedicated server is required that provides the following:   4 Central Processing Units (CPUs)  4GB Random Access Memory (RAM),  although in any operational use case environment at least 16GB of RAM is recommended  40GB hard disk space,  with additional space to store media and processed objects   In a cluster configuration, participating servers are referred to as  nodes , with one controlling node designated as the  master  node and the others designated as  child  nodes.  In this case, a shared file system accessible to all participating nodes is also required.  The  master  contains the Workflow manager, ActiveMQ, MySQL, an instance of the OpenMPF process manager, named the  Node Manager . A  child  contains only a node manager and processing components/algorithms.  Below is an example layout of an OpenMPF cluster consisting of 3 nodes:", 
            "title": "Hardware"
        }, 
        {
            "location": "/Installation/#operating-system-and-software", 
            "text": "OpenMPF runs on the CentOS 7 operating system, with Linux firewall (iptables) disabled and Linux SELINUX in permissive state (disabled is the preferred state to limit logging activity).  A browser is required in order to utilize the OpenMPF Web User Interface (UI). The officially supported browsers are FireFox and Chrome. Although other browsers might work, they have not been thoroughly tested and might not display or function properly.", 
            "title": "Operating System and Software"
        }, 
        {
            "location": "/Installation/#openmpf-pre-installation", 
            "text": "Important:  Please verify that all steps in the Pre-installation Checklist are completed  prior  to cluster configuration.", 
            "title": "OpenMPF Pre-Installation"
        }, 
        {
            "location": "/Installation/#pre-installation-checklist", 
            "text": "", 
            "title": "Pre-Installation Checklist"
        }, 
        {
            "location": "/Installation/#openmpf-installation", 
            "text": "You only need to complete the following steps on the OpenMPF master node.    1. Install and Configure OpenMPF Management Software   Copy the OpenMPF release package .tar.gz, (e.g. openmpf-open-source-0.9.0+master.tar.gz) to the OpenMPF master node.  From the OpenMPF master node, unpack the OpenMPF package.  tar zxvf  latest .tar.gz \ncd mpf-release\nsudo sh install-mpf.sh   2. Configure the OpenMPF Cluster    Note: A master node will  not  run any services unless it is also designated and configured as a child. Think of a child as a worker in the OpenMPF cluster. Thus, in a single server environment it is mandatory to designate the host as both a master and child in order to do any meaningful processing (e.g. detection). By default, the master only runs the workflow manager web app, AMQ, Redis and MySQL.  Note: When prompted for username and password, use the same username and password you used to log in to the master node.  Note: When prompted for hostnames, only put in the hostnames (e.g., node-1), DO NOT put in the fully qualified domain name (e.g., node-1.example.org) or OpenMPF will behave in strange ways.   sudo sh /opt/mpf/manage/configure-cluster.sh   3. Push OpenMPF Configuration to OpenMPF Nodes   Note: Early in the script you will be prompted for the OpenMPF password. Use \"mpf\".   # As the  mpf  user (you may need to log out and log back in):\n. /opt/mpf/manage/push-configuration.sh   4. Complete Node Configuration   OpenMPF is now running (no reboot required).  To complete node configuration:   From the master node, browse to: http://localhost:8080/workflow-manager  Login as the administrator (username: \"admin\" / password: \"mpfadm\")  Go to the Nodes page and add detection services as desired", 
            "title": "OpenMPF Installation"
        }, 
        {
            "location": "/Installation/#updating-site-configuration", 
            "text": "You can add or remove nodes and change other configuration options once OpenMPF has already been installed.  # As the  mpf  user:\nmpf stop\nsudo sh /opt/mpf/manage/configure-cluster.sh\n/opt/mpf/manage/push-configuration.sh", 
            "title": "Updating Site Configuration"
        }, 
        {
            "location": "/Installation/#creating-a-keystore", 
            "text": "IMPORTANT: This is not recommended for a production environment.   These instructions will create a keystore with a self-signed certificate at /home/mpf/.keystore.   Open a new terminal window.  sudo systemctl stop tomcat7  cd /home/mpf  keytool -genkey -alias tomcat -keyalg RSA  At the prompt, enter a keystore password of:  mpf123  Re-enter the keystore password of:  mpf123  At the  What is your first and last name?  prompt, press the Enter key for a blank value.  At the  What is the name of your organizational unit?  , press the Enter key for a blank value.  At the  What is the name of your organization?  prompt, press the Enter key for a blank value.  At the  What is the name of your City or Locality?  prompt, press the Enter key for a blank value.  At the  What is the name of your State or Province?  prompt, press the Enter key for a blank value.  At the  What is the two-letter country code for this unit?  prompt, press the Enter key for a blank value.  At the  Is CN=Unknown, OU=Unknown, O=Unknown, L=Unknown, ST=Unknown, C=Unknown correct?  prompt, press the Enter key to accept the values.  At the  Enter key password for  tomcat  prompt, press the Enter key for a blank value.  Verify the file  /home/mpf/.keystore  was created at the current time.", 
            "title": "Creating a Keystore"
        }, 
        {
            "location": "/User-Guide/", 
            "text": "NOTICE:\n This software (or technical data) was produced for the U.S. Government under contract, and is subject to the Rights in Data-General Clause 52.227-14, Alt. IV (DEC 2007).\nCopyright 2017 The MITRE Corporation. All Rights Reserved.\n\n\n\n\nGeneral\n\n\nAccessing the Web UI\n\n\nOn the server hosting the Open Media Processing Framework (OpenMPF), the Web UI is accessible at http://localhost:8080/workflow-manager. To access it from other machines, substitute the hostname or IP address of the master node server in place of \"localhost\".\n\n\nThe OpenMPF user interface (UI) was designed and tested for use with Chrome and FireFox. It has not been tested with other browsers. Attempting to use an unsupported browser will result in a warning.\n\n\nLogging In\n\n\nThe OpenMPF Web UI requires user authentication and provides two default accounts: \"mpf\" and \"admin\". The password for the \"mpf\" user is \"mpf123\". These accounts are used to assign user or admin roles for OpenMPF cluster management. Note that an administrator can remove these accounts and/or add new ones using a command line tool. Refer to the \nAdmin Guide\n for features available to an admin user.\n\n\n\n\nThe landing page for a user is the Job Status page:\n\n\n\n\nLogging in starts a user session. By default, after 30 minutes of inactivity the user will automatically be logged out of the system. Within one minute of logging out the user will be prompted to extend or end their session. Note that the timeout period can be configured by any admin user with the admin role.\n\n\nA given user can only be logged into the OpenMPF from one machine using one browser at a time. If the same user attempts to log in from another machine, or another browser on the same machine, then the first user session will be terminated immediately and redirected back to the login page. This feature ensures that the user will be able to immediately log in again if the user accidentally closes the browser window or shuts down their machine without properly logging out first.\n\n\nA user may have multiple browser tabs or windows open for the same session, for example, to view the Jobs Status page and Logs page at the same time. It is not recommended that two users login using the same browser at the same time in different tabs or windows. Technically, the second user to login will take precedence, but the first user session will not appear to be terminated. Instead the first user will appear to share recently uploaded media, recent jobs, and other information with the second user. Also, when one of the users logs out in this scenario, they will both be logged out.\n\n\nOnce logged in, only the \"admin\" user has access to the full capabilities within the application, including node configuration, resetting system properties, and stopping and starting processes across the cluster. A non-admin user can view the status of processes in the Admin Console but cannot alter the node configuration or stop and start processes.\n\n\nLogging out\n\n\nTo log out a user can click the down arrow associated with the user icon at the top right hand corner of the page and then select \"Logout\":\n\n\n\n\nUser (Non-Admin) Features\n\n\nThe remainder of this document will describe the features available to a non-admin user.\n\n\nCreating Workflow Manager Jobs\n\n\nA \"job\" consists of a set of image, video, or audio files and a set of exploitation algorithms that will operate on those files.  A job is created by assigning input media file(s) to a pipeline.  A pipeline specifies the order in which processing steps are performed. Each step consists of a single task and each task consists of one or more actions which may be performed in parallel. The following sections describe the UI views associated with the different aspects of job creation and job execution.\n\n\nCreate Job\n\n\nThis is the primary page for creating jobs. Creating a job consists of uploading and selecting files as well as a pipeline and job priority.\n\n\n\n\nUploading Files\n\n\nSelecting a directory in the File Manager will display all files in that directory.  The user can use previously uploaded files, or to choose from the icon bar at the bottom of the panel:\n\n\n Create New Folder\n\n Add Local Files\n\n Upload from URL\n\n Refresh\n\n\nNote that the first three options are only available if the \"remote-media\" directory or one of its subdirectories is selected. That directory resides in the OpenMPF share directory. The full path is shown in the footer of the File Manager section.\n\n\nClicking the \"Add Local Files\" icon will display a file browser dialog so that the user can select and upload one or more files from their local machine. The files will be uploaded to the selected directory. The upload progress dialog will display a preview of each file (if possible) and whether or not each file is uploaded successfully.\n\n\nClicking the \"Create New Folder\" icon will allow the user to create a new directory within the one currently selected. If the user has selected \"remote-media\", then adding a directory called \"Test Data\" will place it within \"remote-media\". \"Test Data\" will appear as a subdirectory in the directory tree shown in the web UI. If the user then clicks on \"Test Data\" and then the \"Add Local Files\" button the user can upload files to that specific directory. In the screenshot below, \"lena.png\" has been uploaded to the parent \"remote-media\" directory.\n\n\n\n\nClicking the \"Upload from URL\" icon enables the user to specify URLs pointing to remote media. Each URL must appear on a new line. Note that if a URL to a video is submitted then it must be a direct link to the video file. Specifying a URL to a YouTube HTML page, for example, will not work.\n\n\n\n\nClicking the \"Refresh\" icon updates the displayed file tree from the file system. Use this if an external process has added or removed files to or from the underlying file system.\n\n\nCreating Jobs\n\n\nCreating a job consists of selecting files as well as a pipeline and job priority.\n\n\n\n\nFiles are selected by first clicking the name of a directory to populate the files table in the center of the UI and then clicking the checkbox next to the file. Multiple files can be selected, including files from different directories. Also, the contents of an entire directory, and its subdirectories, can be selected by clicking the checkbox next to the parent directory name. To review which files have been selected, click the \"View\" button shown to the right of the \"# Files\" indicator.  If there are many files in a directory, you may need to page through the directory using the page number buttons at the bottom of the center pane.\n\n\nYou can remove a file from the selected files by clicking on the red \"X\" for the individual file.  You can also remove multiple files by first selecting the files using the checkboxes and then clicking on the \"Remove Checked\" button.\n\n\n\n\nThe media properties can be adjusted for individual files by clicking on the \"Set Properties\" button for that file. You can modify the properties of a group of files by clicking on the \"Set properties for Checked\" after selecting multiple files.\n\n\n\n\nAfter files have been selected it's time to assign a pipeline and job priority. The \"Select a pipeline and job priority\" section is located on the right side of the screen.  Clicking on the down-arrow on the far right of the \"Select a pipeline\" area displays a drop-down menu containing the available pipelines.  Click on the desired pipeline to select it. Existing pipelines provided with the system are listed in the Default Pipelines section of this document.\n\n\n\"Select job priority\" is immediately below \"Select a pipeline\" and has a similar drop-down menu.  Clicking on the down-arrow on the right hand side of the \"Select job priority\" area displays the drop-down menu of available priorities.  Clicking on the desired priority selects it.  Priority 4 is the default value used if no priority is selected by the user. Priority 0 is the lowest priority, and priority 9 is the highest priority. When a job is executed it's divided into tasks that are each executed by a component service running on one of the nodes in the OpenMPF cluster. Each service executes tasks with the highest priority first. Note that a service will first complete the task it's currently processing before moving on to the next task. Thus, a long-running low-priority task may delay the execution of a high-priority task.\n\n\nAfter files have been selected and a pipeline and priority are assigned, clicking on the \"Create Job\" icon will start the job.  When the job starts, the user will be shown the \"Job Status\" view.\n\n\nJob Status\n\n\nThe Job Status page displays a summary of the status for all jobs run by any user in the past. The current status and progress of any running job can be monitored from this view, which is updated automatically.\n\n\n\n\nWhen a job is COMPLETE a user can view the generated JSON output object data by clicking the \"Output Objects\" button for that job. A new tab/window will open with the detection output. The detection object output displays a formatted JSON representation of the detection results.\n\n\n\n\nA user can click the \"Cancel\" button to attempt to cancel the execution of a job before it completes. Note that if a service is currently processing part of a job, for example, a video segment that's part of a larger video file, then it will continue to process that part of the job until it completes or there is an error. The act of cancelling a job will prevent other parts of that job from being processed. Thus, if the \"Cancel\" button is clicked late into the job execution, or if each part of the job is already being processed by services executing in parallel, it may have no effect. Also, if the video segment size is set to a very large number, and the detection being performed is slow, then cancelling a job could take awhile.\n\n\nA user can click the \"Resubmit\" button to execute a job again. The new job execution will retain the same job id and all generated artifacts, marked up media, and detection objects will be replaced with the new results. The results of the previous job execution will no longer be available. Note that the user has the option to change the job priority when resubmitting a job.\n\n\nYou can view the results of any Media Markup by clicking on the \"Media\" button for that job. This view will display the path of the source medium and the marked up output path of any media processed using a pipeline that contains a markup action. Clicking an image will display a popup with the marked up image. You cannot view a preview for marked up videos. In any case, the marked up data can be downloaded to the machine running the web browser by clicking the \"Download\" button.\n\n\n\n\nCreate Custom Pipelines\n\n\nA pipeline consists of a series of tasks executed sequentially. A task consists of a single action or a set of two or more actions performed in parallel. An action is the execution of an algorithm. The ability to arrange tasks and actions in various ways provides a great deal of flexibility when creating pipelines. Users may combine pre-existing tasks in different ways, or create new tasks based on the pre-existing actions.\n\n\nSelecting \"Create Custom Pipelines\" from the Workflow Manager menu brings up the Pipeline Creation View, which enables users to create new pipelines. To create a new action, the user can scroll to the \"Create A New Action\" section of the page and select the desired algorithm from the \"Select an Algorithm\" dropdown menu:\n\n\n\n\nSelecting an algorithm will bring up a scrollable table of properties associated with the algorithm, including each property's name, description, data type, and an editable field allowing the user to set a custom value. The user may enter values for only those properties that they wish to change; any property value fields left blank will result in default values being used for those properties. For example, a custom action may be created based on the OpenCV face detection component to scan for faces equal to or exceeding a size of 100x100 pixels.\n\n\nWhen done editing the property values, the user can click the \"Create Action\" button, enter a name and description for the action (both are required), and then click the \"Create\" button. The action will then be listed in the \"Available Actions\" table and also in the \"Select an Action\" dropdown menu used for task creation.\n\n\n\n\nTo create a new task, the user can scroll to the \"Create A New Task\" section of the page:\n\n\n\n\nThe user can use the \"Select an Action\" dropdown menu to select the desired action and then click \"Add Action to Task\". The user can follow this procedure to add additional actions to the task, if desired. Clicking on the \"Remove\" button next to an added action will remove it from the task. When the user is finished adding actions the user can click \"Create Task\", enter a name and description for the task (both are required), and then click the \"Create\" button. The task will be listed in the \"Available Tasks\" table as well as in the \"Select a Task\" dropdown menu used for pipeline creation.\n\n\n\n\nTo build a new pipeline, the user can scroll down to the \"Create A New Pipeline\" section of the page:\n\n\n\n\nThe user can use the \"Select a Task\" dropdown menu to select the first task and then click \"Add Task to Pipeline\". The user can follow this procedure to add additional tasks to the pipeline, if desired. Clicking on the \"Remove\" button next to an added task will remove it from the pipeline. When the user is finished adding tasks the user can click \"Create Pipeline\", enter a name and description for the pipeline (both are required), and then click the \"Create\" button. The pipeline will be listed in the \"Available Pipelines\" table.\n\n\n\n\nAll pipelines successfully created in this view will also appear in the pipeline drop down selection menus on any job creation page:\n\n\n\n\n\n\nNOTE: Pipeline, task, and action names are case-insensitive. All letters will be converted to uppercase.\n\n\n\n\nLogs\n\n\nThis page allows a user to view the various log files that are generated by system processes running on the various nodes in the OpenMPF cluster. A log file can be selected by first selecting a host from the \"Available Hosts\" drop-down and then selecting a log file from the \"Available Logs\" drop-down. The information in the log can be filtered for display based on the following log levels:  ALL, TRACE, DEBUG, INFO, WARN, ERROR, or FATAL.  Choosing a successive log level displays all information at that level and levels below (e.g., choosing WARN will cause all WARN, INFO, DEBUG, and TRACE information to be displayed, but will filter out ERROR and FATAL information).\n\n\n\n\nIn general, all services of the same component type running on the same node write log messages to the same file. For example, all OCV face detection services on somehost-7-mpfd2 write log messages to the same \"ocv-face-detection\" log file. All OCV face detection services on somehost-7-mpfd3 write log messages to a different \"ocv-face-detection\" log file.\n\n\nNote that only the master node will have the \"workflow-manager\" log. This is because the workflow manager only runs on the master node. The same is true for the \"activemq\" and \"tomcat\" logs.\n\n\nThe \"node-manager-startup\" and \"node-manager\" logs will appear for every node in the OpenMPF cluster. The \"node-manager-startup\" log captures information about the nodemanager startup process, such as if any errors occurred. The \"node-manager\" log captures information about node manager execution, such as starting and stopping services.\n\n\nThe \"detection\" log captures information about initializing C++ detection components and how they handle job request and response messages.\n\n\nNode Configuration and Status\n\n\nThis page allows a user to view the various service processes running on each node in the OpenMPF cluster. Each node shows information about the current status of each service, if it is unlaunchable due to an underlying error, and how many services are running for each node. If a service is unlaunchable, it will be indicated using a red status icon (not shown). Note that services are grouped by component type. Click the chevron \"\n\" to expand a service group to view the individual services.\n\n\n\n\nEach service is given a unique number to distinguish between multiple instances of the same service running on the same node. For example, if there are two instances of the OpenCV face detection service running on somehost-7-mpfd2 then the first one will have a name of Service 1 and the second one will be Service 2 (not shown).\n\n\nProperties Settings\n\n\nThis page allows a user to view the various OpenMPF properties configured automatically or by an admin user:\n\n\n\n\nStatistics\n\n\nThe \"Jobs\" tab on this page allows a user to view a bar graph representing the time it took to execute the longest running job for a given pipeline. Pipelines that do not have bars have not been used to run any jobs yet. Job statistics are preserved when the workflow manager is restarted.\n\n\n\n\nFor example, the DLIB FACE DETECTION PIPELINE was run twice. Note that the Y-axis in the bar graph has a logarithmic scale. Hovering the mouse over any bar in the graph will show more information. Information about each pipeline is listed below the graph.\n\n\nThe \"Processes\" tab on this page allows a user to view a table with information about the runtime of various internal workflow manager operations. The \"Count\" field represents the number of times each operation was run. The min, max, and mean are calculated over the set of times each operation was performed. Runtime information is reset when the workflow manager is restarted.\n\n\n\n\nREST API\n\n\nThis page allows a user to try out the various REST API endpoints provided by the workflow manager. It is intended to serve as a learning tool for technical users who wish to design and build systems that interact with the OpenMPF.\n\n\nAfter selecting a functional category, such as \"meta\", \"jobs\", \"statistics\", \"nodes\", \"pipelines\", or \"system-message\", each REST endpoint for that category is shown in a list. Selecting one of them will cause it to expand and reveal more information about the request and response structures. If the request takes any parameters then a section will appear that allows the user to manually specify them.\n\n\n\n\nIn the example above, the \"/rest/jobs/{id}\" endpoint was selected. It takes a required \"id\" parameter that corresponds to a previously run job and returns a JSON representation of that job's information. The screenshot below shows the result of specifying an \"id\" of \"1\", providing the \"mpf\" user credentials when prompted, and then clicking the \"Try it out!\" button:\n\n\n\n\nThe HTTP response information is shown below the \"Try it out!\" button. Note that the structure of the \"Response Body\" is the same as the response model shown in the \"Response Class\" directly underneath the \"/rest/jobs/{id}\" label.\n\n\nDetection Chaining\n\n\nThe OpenMPF has the ability to chain detection tasks together in a detection pipeline. As each detection stage in the pipeline completes, the volume of data to be processed in the next stage may be reduced. Generally, any detection tasks executed prior to the final detection task in the pipeline are referred to as preprocessors or filters. For example, consider the following pipeline which demonstrates the use of a motion preprocessor:\n\n\n\n\nIn the pipeline above, the motion preprocessor reduces the volume of data which is passed to the face detector. This is particularly useful when the input media collection contains videos captured by a fixed-location camera.  For example, a camera targeting a chokepoint such as a hallway door. The motion preprocessor will filter the input media so that only regions of video containing motion are passed on to the face detector.\n\n\nDetection pipelines may be created with, or without, preprocessors and filters using the Create Custom Pipelines view.\n\n\n\n\nWARNING: Preprocessors and filters may ultimately eliminate the entirety of a media file. When an entire media file is eliminated, none of the subsequent stages in the pipeline will operate on that file. Therefore, it is important to consider the consequences of using preprocessors/filters. For example, when the motion detection receives an image or audio file, its default behavior is to return a response indicating that the file did not contain any motion tracks. If the pipeline continued to face detection then none of the image files would be eligible for that kind of detection.\n\n\n\n\n\"USE_PREPROCESSOR\" Property\n\n\nIn order to mitigate the risk of eliminating useful media files simply because they are not supported by a detector using its default settings, some algorithms expose a \"USE_PREPROCESSOR\" property. When a user creates an action based on a detector with this property, the user may assign this property a nonzero value in order to indicate that the detector should behave as a preprocessor as opposed to a filter. When acting as a preprocessor, a detector will not emit an empty detection set when provided with an unsupported media type, rather it will return a single track spanning the duration of the media file. Thus, when configured with the \"USE_PREPROCESSOR\" setting, the motion detector will not prevent images from passing on to the next stage in the pipeline, for example.\n\n\nSegmenting Media\n\n\nThe OpenMPF allows users to configure video segmenting properties for actions in a pipeline. Audio files (which do not have the concept of \"frames\") and image files (which are treated like single-frame videos) are not affected by these properties.\n\n\nSegmenting is performed before a detection action in order to split work across the available detection services running on the various nodes in the OpenMPF cluster. In general, each instance of a detection service can process one video segment at a time. Multiple services can process separate segments at the same time, thus enabling parallel processing. There are two fundamental segmenting scenarios:\n\n\n\n\nSegmenting must be performed on a video which has not passed through a preprocessor or filter.\n\n\nSegmenting must be performed on a video which has passed through a preprocessor or filter.\n\n\n\n\nIn the first scenario the segmenting logic is less complex. The segmenter will create a supersegment corresponding to the entire length of the video (in frames), and it will then divide the supersegment into segments which respect to the provided \"TARGET_SEGMENT_LENGTH\" and \"MIN_SEGMENT_LENGTH\" properties.\n\n\nIn the second scenario the segmenting logic is more complex. The segmenter first examines the start and stop times associated with all of the overlapping tracks produced by the previous detection action in the pipeline and proceeds to merge those intervals and segment the result. The goal is to generate a minimum number of segments that don't include unnecessary frames (frames that don't belong to any tracks). For example:\n\n\n\n\n\"TARGET_SEGMENT_LENGTH\" Property\n\n\nThis property indicates the preferred number of frames which will be provided to the detection component. For example, a value of \"100\" indicates that the input video should be split into 100-frame segments. Note that the properties \"MIN_SEGMENT_LENGTH\" and \"MIN_GAP_BETWEEN_SEGMENTS\" may ultimately cause segments to vary from the preferred segment size.\n\n\n\"MIN_SEGMENT_LENGTH\" Property\n\n\nThis property indicates the minimum length of a segment which may be produced. If a segment is less than this value, the segment will be merged into the segment adjacent to it. If no segments are adjacent to the short segment, the segment will be ignored and will not produce a work unit. In other words, the frames associated with that short segment will not be processed by the rest of the pipeline.\n\n\nExample 1: Adjacent Segment Present\n\n\n\n\n\n\nIn this example, a preprocessor has completed and produced a single track.\n\n\nThe next detection action specifies the following parameters:\n\n\n\"TARGET_SEGMENT_LENGTH\" = 100\n\n\n\"MIN_SEGMENT_LENGTH\" = 75\n\n\nThree segments are initially produced from the input track with lengths corresponding to 100 frames, 100 frames, and 50 frames.\n\n\nSince the last frame does not exceed the minimum specified segment length, it must either be discarded or merged with an adjacent segment.\n\n\nSegments 2 and 3 are determined to be adjacent, so they are merged.\n\n\nUltimately, two segments are produced.\n\n\n\n\nExample 2: No Adjacent Segment\n\n\n\n\n\n\nIn this example, a preprocessor has completed and produced two non-overlapping tracks.\n\n\nThe next detection action specifies the following parameters:\n\n\n\"TARGET_SEGMENT_LENGTH\" = 100\n\n\n\"MIN_SEGMENT_LENGTH\" = 75\n\n\n\"MIN_GAP_BETWEEN_SEGMENTS\" = 50\n\n\nThe segmenter begins by merging any segments which are less than \"MIN_GAP_BETWEEN_SEGMENTS\" apart. There are none.\n\n\nThe segmenter then splits the existing segments using the \"MIN_SEGMENT_LENGTH\" and \"TARGET_SEGMENT_LENGTH\" values.\n\n\nThe segmenter iterates through each segment produced. If the segment satisfies the minimum length constraint, it moves to the next segment.\n\n\nWhen it reaches the third segment and finds the length of 50 frames does not exceed the minimum length, it merges that segment with the previous adjacent segment.\n\n\nWhen it reaches the final segment and finds that the length of 25 frames does not exceed the minimum length, and that there are no adjacent segments, the segment is destroyed.\n\n\nUltimately, only two segments are produced.\n\n\n\n\n\"MIN_GAP_BETWEEN_SEGMENTS\" Property\n\n\nThis property is important to pipelines which contain preprocessors or filters and controls the minimum gap which must appear between consecutive segments. The purpose of this property is to prevent scenarios where a preprocessor or filter produces a large number of short segments separated by only a few frames. By merging the segments together prior to performing further segmentation, the number of work units produced by the segmenting plan can be reduced, thereby reducing pipeline execution time.\n\n\nConsider the following diagram, which further illustrates the purpose of this property:\n\n\n\n\n\n\nThe user submits a video to a pipeline containing a motion preprocessor followed by another extractor (e.g., face).\n\n\nThe video is initially split into segments using the properties provided by the motion preprocessor. Specifically, the preprocessor action specifies the following parameters and four segments are produced:\n\n\n\"TARGET_SEGMENT_LENGTH\" = \"250\"\n\n\n\"MIN_SEGMENT_LENGTH\" = \"150\"\n\n\n\"MERGE_TRACKS\" = \"true\"\n\n\nThe segments are submitted to the motion preprocessor, and five distinct and non-overlapping tracks are returned based on the frames of the segments in which motion is detected.\n\n\nBecause the \"MERGE_TRACKS\" property is set to \"true\", tracks are merged across segment boundaries if applicable. This rule is applied to each pair of tracks that are only one frame apart (adjacent). Consequently, only three tracks are ultimately derived from the video. (The number of tracks is reduced from five to three between the \"Preprocessor\" and \"Track Merger\" phases of the diagram.)\n\n\nThe non-overlapping tracks are then used to form the video segments for the next detection action. This action specifies the following parameters:\n\n\n\"TARGET_SEGMENT_LENGTH\" = \"75\"\n\n\n\"MIN_SEGMENT_LENGTH\" = \"25\"\n\n\n\"MIN_GAP_BETWEEN_SEGMENTS\" = \"99\"\n\n\nThe segmenting logic merges tracks which are less than \"MIN_SEGMENT_LENGTH\" frames apart into one long segment. Once all tracks have been merged, each segment is itself segmented while respecting the provided \"TARGET_SEGMENT_LENGTH\" and \"MIN_SEGMENT_LENGTH\" properties. Ultimately, ten segments are produced. (Track #1 and Track #2 in the \"Track Merger\" phase of the diagram are combined, which is why Segment #3 in the \"Segmenter\" phase of the diagram includes the 25 frames that span the gap between those two tracks.)", 
            "title": "User Guide"
        }, 
        {
            "location": "/User-Guide/#general", 
            "text": "", 
            "title": "General"
        }, 
        {
            "location": "/User-Guide/#accessing-the-web-ui", 
            "text": "On the server hosting the Open Media Processing Framework (OpenMPF), the Web UI is accessible at http://localhost:8080/workflow-manager. To access it from other machines, substitute the hostname or IP address of the master node server in place of \"localhost\".  The OpenMPF user interface (UI) was designed and tested for use with Chrome and FireFox. It has not been tested with other browsers. Attempting to use an unsupported browser will result in a warning.", 
            "title": "Accessing the Web UI"
        }, 
        {
            "location": "/User-Guide/#logging-in", 
            "text": "The OpenMPF Web UI requires user authentication and provides two default accounts: \"mpf\" and \"admin\". The password for the \"mpf\" user is \"mpf123\". These accounts are used to assign user or admin roles for OpenMPF cluster management. Note that an administrator can remove these accounts and/or add new ones using a command line tool. Refer to the  Admin Guide  for features available to an admin user.   The landing page for a user is the Job Status page:   Logging in starts a user session. By default, after 30 minutes of inactivity the user will automatically be logged out of the system. Within one minute of logging out the user will be prompted to extend or end their session. Note that the timeout period can be configured by any admin user with the admin role.  A given user can only be logged into the OpenMPF from one machine using one browser at a time. If the same user attempts to log in from another machine, or another browser on the same machine, then the first user session will be terminated immediately and redirected back to the login page. This feature ensures that the user will be able to immediately log in again if the user accidentally closes the browser window or shuts down their machine without properly logging out first.  A user may have multiple browser tabs or windows open for the same session, for example, to view the Jobs Status page and Logs page at the same time. It is not recommended that two users login using the same browser at the same time in different tabs or windows. Technically, the second user to login will take precedence, but the first user session will not appear to be terminated. Instead the first user will appear to share recently uploaded media, recent jobs, and other information with the second user. Also, when one of the users logs out in this scenario, they will both be logged out.  Once logged in, only the \"admin\" user has access to the full capabilities within the application, including node configuration, resetting system properties, and stopping and starting processes across the cluster. A non-admin user can view the status of processes in the Admin Console but cannot alter the node configuration or stop and start processes.", 
            "title": "Logging In"
        }, 
        {
            "location": "/User-Guide/#logging-out", 
            "text": "To log out a user can click the down arrow associated with the user icon at the top right hand corner of the page and then select \"Logout\":", 
            "title": "Logging out"
        }, 
        {
            "location": "/User-Guide/#user-non-admin-features", 
            "text": "The remainder of this document will describe the features available to a non-admin user.", 
            "title": "User (Non-Admin) Features"
        }, 
        {
            "location": "/User-Guide/#creating-workflow-manager-jobs", 
            "text": "A \"job\" consists of a set of image, video, or audio files and a set of exploitation algorithms that will operate on those files.  A job is created by assigning input media file(s) to a pipeline.  A pipeline specifies the order in which processing steps are performed. Each step consists of a single task and each task consists of one or more actions which may be performed in parallel. The following sections describe the UI views associated with the different aspects of job creation and job execution.", 
            "title": "Creating Workflow Manager Jobs"
        }, 
        {
            "location": "/User-Guide/#create-job", 
            "text": "This is the primary page for creating jobs. Creating a job consists of uploading and selecting files as well as a pipeline and job priority.", 
            "title": "Create Job"
        }, 
        {
            "location": "/User-Guide/#uploading-files", 
            "text": "Selecting a directory in the File Manager will display all files in that directory.  The user can use previously uploaded files, or to choose from the icon bar at the bottom of the panel:   Create New Folder  Add Local Files  Upload from URL  Refresh  Note that the first three options are only available if the \"remote-media\" directory or one of its subdirectories is selected. That directory resides in the OpenMPF share directory. The full path is shown in the footer of the File Manager section.  Clicking the \"Add Local Files\" icon will display a file browser dialog so that the user can select and upload one or more files from their local machine. The files will be uploaded to the selected directory. The upload progress dialog will display a preview of each file (if possible) and whether or not each file is uploaded successfully.  Clicking the \"Create New Folder\" icon will allow the user to create a new directory within the one currently selected. If the user has selected \"remote-media\", then adding a directory called \"Test Data\" will place it within \"remote-media\". \"Test Data\" will appear as a subdirectory in the directory tree shown in the web UI. If the user then clicks on \"Test Data\" and then the \"Add Local Files\" button the user can upload files to that specific directory. In the screenshot below, \"lena.png\" has been uploaded to the parent \"remote-media\" directory.   Clicking the \"Upload from URL\" icon enables the user to specify URLs pointing to remote media. Each URL must appear on a new line. Note that if a URL to a video is submitted then it must be a direct link to the video file. Specifying a URL to a YouTube HTML page, for example, will not work.   Clicking the \"Refresh\" icon updates the displayed file tree from the file system. Use this if an external process has added or removed files to or from the underlying file system.", 
            "title": "Uploading Files"
        }, 
        {
            "location": "/User-Guide/#creating-jobs", 
            "text": "Creating a job consists of selecting files as well as a pipeline and job priority.   Files are selected by first clicking the name of a directory to populate the files table in the center of the UI and then clicking the checkbox next to the file. Multiple files can be selected, including files from different directories. Also, the contents of an entire directory, and its subdirectories, can be selected by clicking the checkbox next to the parent directory name. To review which files have been selected, click the \"View\" button shown to the right of the \"# Files\" indicator.  If there are many files in a directory, you may need to page through the directory using the page number buttons at the bottom of the center pane.  You can remove a file from the selected files by clicking on the red \"X\" for the individual file.  You can also remove multiple files by first selecting the files using the checkboxes and then clicking on the \"Remove Checked\" button.   The media properties can be adjusted for individual files by clicking on the \"Set Properties\" button for that file. You can modify the properties of a group of files by clicking on the \"Set properties for Checked\" after selecting multiple files.   After files have been selected it's time to assign a pipeline and job priority. The \"Select a pipeline and job priority\" section is located on the right side of the screen.  Clicking on the down-arrow on the far right of the \"Select a pipeline\" area displays a drop-down menu containing the available pipelines.  Click on the desired pipeline to select it. Existing pipelines provided with the system are listed in the Default Pipelines section of this document.  \"Select job priority\" is immediately below \"Select a pipeline\" and has a similar drop-down menu.  Clicking on the down-arrow on the right hand side of the \"Select job priority\" area displays the drop-down menu of available priorities.  Clicking on the desired priority selects it.  Priority 4 is the default value used if no priority is selected by the user. Priority 0 is the lowest priority, and priority 9 is the highest priority. When a job is executed it's divided into tasks that are each executed by a component service running on one of the nodes in the OpenMPF cluster. Each service executes tasks with the highest priority first. Note that a service will first complete the task it's currently processing before moving on to the next task. Thus, a long-running low-priority task may delay the execution of a high-priority task.  After files have been selected and a pipeline and priority are assigned, clicking on the \"Create Job\" icon will start the job.  When the job starts, the user will be shown the \"Job Status\" view.", 
            "title": "Creating Jobs"
        }, 
        {
            "location": "/User-Guide/#job-status", 
            "text": "The Job Status page displays a summary of the status for all jobs run by any user in the past. The current status and progress of any running job can be monitored from this view, which is updated automatically.   When a job is COMPLETE a user can view the generated JSON output object data by clicking the \"Output Objects\" button for that job. A new tab/window will open with the detection output. The detection object output displays a formatted JSON representation of the detection results.   A user can click the \"Cancel\" button to attempt to cancel the execution of a job before it completes. Note that if a service is currently processing part of a job, for example, a video segment that's part of a larger video file, then it will continue to process that part of the job until it completes or there is an error. The act of cancelling a job will prevent other parts of that job from being processed. Thus, if the \"Cancel\" button is clicked late into the job execution, or if each part of the job is already being processed by services executing in parallel, it may have no effect. Also, if the video segment size is set to a very large number, and the detection being performed is slow, then cancelling a job could take awhile.  A user can click the \"Resubmit\" button to execute a job again. The new job execution will retain the same job id and all generated artifacts, marked up media, and detection objects will be replaced with the new results. The results of the previous job execution will no longer be available. Note that the user has the option to change the job priority when resubmitting a job.  You can view the results of any Media Markup by clicking on the \"Media\" button for that job. This view will display the path of the source medium and the marked up output path of any media processed using a pipeline that contains a markup action. Clicking an image will display a popup with the marked up image. You cannot view a preview for marked up videos. In any case, the marked up data can be downloaded to the machine running the web browser by clicking the \"Download\" button.", 
            "title": "Job Status"
        }, 
        {
            "location": "/User-Guide/#create-custom-pipelines", 
            "text": "A pipeline consists of a series of tasks executed sequentially. A task consists of a single action or a set of two or more actions performed in parallel. An action is the execution of an algorithm. The ability to arrange tasks and actions in various ways provides a great deal of flexibility when creating pipelines. Users may combine pre-existing tasks in different ways, or create new tasks based on the pre-existing actions.  Selecting \"Create Custom Pipelines\" from the Workflow Manager menu brings up the Pipeline Creation View, which enables users to create new pipelines. To create a new action, the user can scroll to the \"Create A New Action\" section of the page and select the desired algorithm from the \"Select an Algorithm\" dropdown menu:   Selecting an algorithm will bring up a scrollable table of properties associated with the algorithm, including each property's name, description, data type, and an editable field allowing the user to set a custom value. The user may enter values for only those properties that they wish to change; any property value fields left blank will result in default values being used for those properties. For example, a custom action may be created based on the OpenCV face detection component to scan for faces equal to or exceeding a size of 100x100 pixels.  When done editing the property values, the user can click the \"Create Action\" button, enter a name and description for the action (both are required), and then click the \"Create\" button. The action will then be listed in the \"Available Actions\" table and also in the \"Select an Action\" dropdown menu used for task creation.   To create a new task, the user can scroll to the \"Create A New Task\" section of the page:   The user can use the \"Select an Action\" dropdown menu to select the desired action and then click \"Add Action to Task\". The user can follow this procedure to add additional actions to the task, if desired. Clicking on the \"Remove\" button next to an added action will remove it from the task. When the user is finished adding actions the user can click \"Create Task\", enter a name and description for the task (both are required), and then click the \"Create\" button. The task will be listed in the \"Available Tasks\" table as well as in the \"Select a Task\" dropdown menu used for pipeline creation.   To build a new pipeline, the user can scroll down to the \"Create A New Pipeline\" section of the page:   The user can use the \"Select a Task\" dropdown menu to select the first task and then click \"Add Task to Pipeline\". The user can follow this procedure to add additional tasks to the pipeline, if desired. Clicking on the \"Remove\" button next to an added task will remove it from the pipeline. When the user is finished adding tasks the user can click \"Create Pipeline\", enter a name and description for the pipeline (both are required), and then click the \"Create\" button. The pipeline will be listed in the \"Available Pipelines\" table.   All pipelines successfully created in this view will also appear in the pipeline drop down selection menus on any job creation page:    NOTE: Pipeline, task, and action names are case-insensitive. All letters will be converted to uppercase.", 
            "title": "Create Custom Pipelines"
        }, 
        {
            "location": "/User-Guide/#logs", 
            "text": "This page allows a user to view the various log files that are generated by system processes running on the various nodes in the OpenMPF cluster. A log file can be selected by first selecting a host from the \"Available Hosts\" drop-down and then selecting a log file from the \"Available Logs\" drop-down. The information in the log can be filtered for display based on the following log levels:  ALL, TRACE, DEBUG, INFO, WARN, ERROR, or FATAL.  Choosing a successive log level displays all information at that level and levels below (e.g., choosing WARN will cause all WARN, INFO, DEBUG, and TRACE information to be displayed, but will filter out ERROR and FATAL information).   In general, all services of the same component type running on the same node write log messages to the same file. For example, all OCV face detection services on somehost-7-mpfd2 write log messages to the same \"ocv-face-detection\" log file. All OCV face detection services on somehost-7-mpfd3 write log messages to a different \"ocv-face-detection\" log file.  Note that only the master node will have the \"workflow-manager\" log. This is because the workflow manager only runs on the master node. The same is true for the \"activemq\" and \"tomcat\" logs.  The \"node-manager-startup\" and \"node-manager\" logs will appear for every node in the OpenMPF cluster. The \"node-manager-startup\" log captures information about the nodemanager startup process, such as if any errors occurred. The \"node-manager\" log captures information about node manager execution, such as starting and stopping services.  The \"detection\" log captures information about initializing C++ detection components and how they handle job request and response messages.", 
            "title": "Logs"
        }, 
        {
            "location": "/User-Guide/#node-configuration-and-status", 
            "text": "This page allows a user to view the various service processes running on each node in the OpenMPF cluster. Each node shows information about the current status of each service, if it is unlaunchable due to an underlying error, and how many services are running for each node. If a service is unlaunchable, it will be indicated using a red status icon (not shown). Note that services are grouped by component type. Click the chevron \" \" to expand a service group to view the individual services.   Each service is given a unique number to distinguish between multiple instances of the same service running on the same node. For example, if there are two instances of the OpenCV face detection service running on somehost-7-mpfd2 then the first one will have a name of Service 1 and the second one will be Service 2 (not shown).", 
            "title": "Node Configuration and Status"
        }, 
        {
            "location": "/User-Guide/#properties-settings", 
            "text": "This page allows a user to view the various OpenMPF properties configured automatically or by an admin user:", 
            "title": "Properties Settings"
        }, 
        {
            "location": "/User-Guide/#statistics", 
            "text": "The \"Jobs\" tab on this page allows a user to view a bar graph representing the time it took to execute the longest running job for a given pipeline. Pipelines that do not have bars have not been used to run any jobs yet. Job statistics are preserved when the workflow manager is restarted.   For example, the DLIB FACE DETECTION PIPELINE was run twice. Note that the Y-axis in the bar graph has a logarithmic scale. Hovering the mouse over any bar in the graph will show more information. Information about each pipeline is listed below the graph.  The \"Processes\" tab on this page allows a user to view a table with information about the runtime of various internal workflow manager operations. The \"Count\" field represents the number of times each operation was run. The min, max, and mean are calculated over the set of times each operation was performed. Runtime information is reset when the workflow manager is restarted.", 
            "title": "Statistics"
        }, 
        {
            "location": "/User-Guide/#rest-api", 
            "text": "This page allows a user to try out the various REST API endpoints provided by the workflow manager. It is intended to serve as a learning tool for technical users who wish to design and build systems that interact with the OpenMPF.  After selecting a functional category, such as \"meta\", \"jobs\", \"statistics\", \"nodes\", \"pipelines\", or \"system-message\", each REST endpoint for that category is shown in a list. Selecting one of them will cause it to expand and reveal more information about the request and response structures. If the request takes any parameters then a section will appear that allows the user to manually specify them.   In the example above, the \"/rest/jobs/{id}\" endpoint was selected. It takes a required \"id\" parameter that corresponds to a previously run job and returns a JSON representation of that job's information. The screenshot below shows the result of specifying an \"id\" of \"1\", providing the \"mpf\" user credentials when prompted, and then clicking the \"Try it out!\" button:   The HTTP response information is shown below the \"Try it out!\" button. Note that the structure of the \"Response Body\" is the same as the response model shown in the \"Response Class\" directly underneath the \"/rest/jobs/{id}\" label.", 
            "title": "REST API"
        }, 
        {
            "location": "/User-Guide/#detection-chaining", 
            "text": "The OpenMPF has the ability to chain detection tasks together in a detection pipeline. As each detection stage in the pipeline completes, the volume of data to be processed in the next stage may be reduced. Generally, any detection tasks executed prior to the final detection task in the pipeline are referred to as preprocessors or filters. For example, consider the following pipeline which demonstrates the use of a motion preprocessor:   In the pipeline above, the motion preprocessor reduces the volume of data which is passed to the face detector. This is particularly useful when the input media collection contains videos captured by a fixed-location camera.  For example, a camera targeting a chokepoint such as a hallway door. The motion preprocessor will filter the input media so that only regions of video containing motion are passed on to the face detector.  Detection pipelines may be created with, or without, preprocessors and filters using the Create Custom Pipelines view.   WARNING: Preprocessors and filters may ultimately eliminate the entirety of a media file. When an entire media file is eliminated, none of the subsequent stages in the pipeline will operate on that file. Therefore, it is important to consider the consequences of using preprocessors/filters. For example, when the motion detection receives an image or audio file, its default behavior is to return a response indicating that the file did not contain any motion tracks. If the pipeline continued to face detection then none of the image files would be eligible for that kind of detection.", 
            "title": "Detection Chaining"
        }, 
        {
            "location": "/User-Guide/#use_preprocessor-property", 
            "text": "In order to mitigate the risk of eliminating useful media files simply because they are not supported by a detector using its default settings, some algorithms expose a \"USE_PREPROCESSOR\" property. When a user creates an action based on a detector with this property, the user may assign this property a nonzero value in order to indicate that the detector should behave as a preprocessor as opposed to a filter. When acting as a preprocessor, a detector will not emit an empty detection set when provided with an unsupported media type, rather it will return a single track spanning the duration of the media file. Thus, when configured with the \"USE_PREPROCESSOR\" setting, the motion detector will not prevent images from passing on to the next stage in the pipeline, for example.", 
            "title": "\"USE_PREPROCESSOR\" Property"
        }, 
        {
            "location": "/User-Guide/#segmenting-media", 
            "text": "The OpenMPF allows users to configure video segmenting properties for actions in a pipeline. Audio files (which do not have the concept of \"frames\") and image files (which are treated like single-frame videos) are not affected by these properties.  Segmenting is performed before a detection action in order to split work across the available detection services running on the various nodes in the OpenMPF cluster. In general, each instance of a detection service can process one video segment at a time. Multiple services can process separate segments at the same time, thus enabling parallel processing. There are two fundamental segmenting scenarios:   Segmenting must be performed on a video which has not passed through a preprocessor or filter.  Segmenting must be performed on a video which has passed through a preprocessor or filter.   In the first scenario the segmenting logic is less complex. The segmenter will create a supersegment corresponding to the entire length of the video (in frames), and it will then divide the supersegment into segments which respect to the provided \"TARGET_SEGMENT_LENGTH\" and \"MIN_SEGMENT_LENGTH\" properties.  In the second scenario the segmenting logic is more complex. The segmenter first examines the start and stop times associated with all of the overlapping tracks produced by the previous detection action in the pipeline and proceeds to merge those intervals and segment the result. The goal is to generate a minimum number of segments that don't include unnecessary frames (frames that don't belong to any tracks). For example:", 
            "title": "Segmenting Media"
        }, 
        {
            "location": "/User-Guide/#target_segment_length-property", 
            "text": "This property indicates the preferred number of frames which will be provided to the detection component. For example, a value of \"100\" indicates that the input video should be split into 100-frame segments. Note that the properties \"MIN_SEGMENT_LENGTH\" and \"MIN_GAP_BETWEEN_SEGMENTS\" may ultimately cause segments to vary from the preferred segment size.", 
            "title": "\"TARGET_SEGMENT_LENGTH\" Property"
        }, 
        {
            "location": "/User-Guide/#min_segment_length-property", 
            "text": "This property indicates the minimum length of a segment which may be produced. If a segment is less than this value, the segment will be merged into the segment adjacent to it. If no segments are adjacent to the short segment, the segment will be ignored and will not produce a work unit. In other words, the frames associated with that short segment will not be processed by the rest of the pipeline.", 
            "title": "\"MIN_SEGMENT_LENGTH\" Property"
        }, 
        {
            "location": "/User-Guide/#example-1-adjacent-segment-present", 
            "text": "In this example, a preprocessor has completed and produced a single track.  The next detection action specifies the following parameters:  \"TARGET_SEGMENT_LENGTH\" = 100  \"MIN_SEGMENT_LENGTH\" = 75  Three segments are initially produced from the input track with lengths corresponding to 100 frames, 100 frames, and 50 frames.  Since the last frame does not exceed the minimum specified segment length, it must either be discarded or merged with an adjacent segment.  Segments 2 and 3 are determined to be adjacent, so they are merged.  Ultimately, two segments are produced.", 
            "title": "Example 1: Adjacent Segment Present"
        }, 
        {
            "location": "/User-Guide/#example-2-no-adjacent-segment", 
            "text": "In this example, a preprocessor has completed and produced two non-overlapping tracks.  The next detection action specifies the following parameters:  \"TARGET_SEGMENT_LENGTH\" = 100  \"MIN_SEGMENT_LENGTH\" = 75  \"MIN_GAP_BETWEEN_SEGMENTS\" = 50  The segmenter begins by merging any segments which are less than \"MIN_GAP_BETWEEN_SEGMENTS\" apart. There are none.  The segmenter then splits the existing segments using the \"MIN_SEGMENT_LENGTH\" and \"TARGET_SEGMENT_LENGTH\" values.  The segmenter iterates through each segment produced. If the segment satisfies the minimum length constraint, it moves to the next segment.  When it reaches the third segment and finds the length of 50 frames does not exceed the minimum length, it merges that segment with the previous adjacent segment.  When it reaches the final segment and finds that the length of 25 frames does not exceed the minimum length, and that there are no adjacent segments, the segment is destroyed.  Ultimately, only two segments are produced.", 
            "title": "Example 2: No Adjacent Segment"
        }, 
        {
            "location": "/User-Guide/#min_gap_between_segments-property", 
            "text": "This property is important to pipelines which contain preprocessors or filters and controls the minimum gap which must appear between consecutive segments. The purpose of this property is to prevent scenarios where a preprocessor or filter produces a large number of short segments separated by only a few frames. By merging the segments together prior to performing further segmentation, the number of work units produced by the segmenting plan can be reduced, thereby reducing pipeline execution time.  Consider the following diagram, which further illustrates the purpose of this property:    The user submits a video to a pipeline containing a motion preprocessor followed by another extractor (e.g., face).  The video is initially split into segments using the properties provided by the motion preprocessor. Specifically, the preprocessor action specifies the following parameters and four segments are produced:  \"TARGET_SEGMENT_LENGTH\" = \"250\"  \"MIN_SEGMENT_LENGTH\" = \"150\"  \"MERGE_TRACKS\" = \"true\"  The segments are submitted to the motion preprocessor, and five distinct and non-overlapping tracks are returned based on the frames of the segments in which motion is detected.  Because the \"MERGE_TRACKS\" property is set to \"true\", tracks are merged across segment boundaries if applicable. This rule is applied to each pair of tracks that are only one frame apart (adjacent). Consequently, only three tracks are ultimately derived from the video. (The number of tracks is reduced from five to three between the \"Preprocessor\" and \"Track Merger\" phases of the diagram.)  The non-overlapping tracks are then used to form the video segments for the next detection action. This action specifies the following parameters:  \"TARGET_SEGMENT_LENGTH\" = \"75\"  \"MIN_SEGMENT_LENGTH\" = \"25\"  \"MIN_GAP_BETWEEN_SEGMENTS\" = \"99\"  The segmenting logic merges tracks which are less than \"MIN_SEGMENT_LENGTH\" frames apart into one long segment. Once all tracks have been merged, each segment is itself segmented while respecting the provided \"TARGET_SEGMENT_LENGTH\" and \"MIN_SEGMENT_LENGTH\" properties. Ultimately, ten segments are produced. (Track #1 and Track #2 in the \"Track Merger\" phase of the diagram are combined, which is why Segment #3 in the \"Segmenter\" phase of the diagram includes the 25 frames that span the gap between those two tracks.)", 
            "title": "\"MIN_GAP_BETWEEN_SEGMENTS\" Property"
        }, 
        {
            "location": "/Admin-Manual/", 
            "text": "NOTICE:\n This software (or technical data) was produced for the U.S. Government under contract, and is subject to the Rights in Data-General Clause 52.227-14, Alt. IV (DEC 2007).\nCopyright 2017 The MITRE Corporation. All Rights Reserved.\n\n\n\n\nWeb UI\n\n\nThe login procedure, as well as all of the pages accessible through the Workflow Manager sidebar, are the same for admin and non-admin users. Refer to the \nUser Guide\n for more information. The default account for an admin user has the username \"admin\" and password \"mpfadm\".\n\n\nThis document will cover the additional functionality permitted to admin users through the Admin Console pages.\n\n\nDashboard\n\n\nThe landing page for an admin user is the Job Status page:\n\n\n\n\nThe Job Status page displays a summary of the status for all jobs run by any user in the past. The current status and progress of any running job can be monitored from this view, which is updated automatically.\n\n\nNode Configuration and Status\n\n\nThis page provides a list of all of the services that are configured to run on the OpenMPF cluster, and enables an admin user to start, stop, or restart them on an individual basis. Only an admin user can perform these actions. If a non-admin user views this page, the \"Action(s)\" column is not displayed. This page also enables an admin user to edit the configuration for all nodes in the OpenMPF cluster. A non-admin user can only view the existing configuration.\n\n\n\n\nAn admin user can add a node by using the \"Add Node\" button and selecting a node in the OpenMPF cluster from the drop-down list. You an also select to add all services at this time. A node and all if its configured services can be removed by clicking the trash can to the right of the node's hostname.\n\n\nAn admin user can add services individually by selecting the node edit button at the bottom of the node. The number of service instances can be increased or decreased by using the drop-down. Click the \"Submit\" button to save the changes.\n\n\nAny node or service changes take effect immediately, no saving is required, except for adding services.\n\n\nWhen making changes, please be aware of the following:\n\n\n\n\nIt may take a minute for the configuration to take effect on the server.\n\n\nIf you remove an existing service from a node, any job that service is processing will be stopped, and you will need to resubmit that job.\n\n\nIf you create a new node, its configuration will not take effect until the OpenMPF software is properly installed and started on the associated host.\n\n\nIf you delete a node, you will need to manually turn off the hardware running that node (deleting a node does not shut down the machine).\n\n\n\n\nProperties Settings\n\n\nThis page allows an admin user to view and edit various OpenMPF properties:\n\n\n\n\nAn admin user can click inside of the \"Value\" field for any of the properties and type a new value. Doing so will change the color of the property to orange and display an orange icon to the right of the property name.\n\n\nNote that if the admin user types in the original value of the property, or clicks the \"Reset\" button, then it will return back to the normal coloration.\n\n\nWARNING: Changing the value of these properties can prevent the workflow manager from running after the web server is restarted. Also, no validation checks are performed on the user-provided values. Proceed with caution!\n\n\nAt the bottom of the properties table is the \"Save Properties\" button. The number of modified properties is shown in parentheses. Clicking the button will make the necessary changes to the properties file on the file system, but the changes will not take effect until the workflow manager is restarted. The saved properties will be colored blue and a blue icon will be displayed to the right of the property name. Additionally, a notification will appear at the top of the page alerting all system users that a restart is required:\n\n\n\n\nComponent Registration\n\n\nThis page allows an admin user to add and remove non-default components to and from the system:\n\n\n\n\nA component package takes the form of a tar.gz file. An admin user can either drag and drop the file onto the \"Upload a new component\" dropzone area or click the dropzone area to open a file browser and select the file that way. In either case, the component will begin to be uploaded to the system. If the admin user dragged and dropped the file onto the dropzone area then the upload progress will be shown in that area. Once uploaded, the workflow manager will automatically attempt to register the component. Notification messages will appear in the upper right side of the screen to indicate success or failure if an error occurs. The \"Current Components\" table will display the component status.\n\n\n\n\nIf for some reason the component package upload succeeded but the component registration failed then the admin user will be able to click the \"Register\" button again to try to another registration attempt. For example, the admin user may do this after reviewing the workflow manager logs and resolving any issues that prevented the component from successfully registering the first time. One reason may be that a component with the same name already exists on the system. Note that an error will also occur if the top-level directory of the component package, once extracted, already exists in the /opt/mpf/plugins directory on the system.\n\n\nOnce registered, an admin user has the option to remove the component. This will unregister it and completely remove any configured services, as well as the uploaded file and its extracted contents, from the system. Also, the component algorithm as well as any actions, tasks, and pipelines specified in the component's descriptor file will be removed when the component is removed.\n\n\nWARNING: Any actions, tasks, or pipelines created through the Create Custom Pipelines page that make use of the algorithm, actions, or tasks specified in the descriptor file of the component being removed will also be removed. This is to prevent pipelines from not working properly once the component is removed.\n\n\nCommand Line Tools\n\n\nOpenMPF release 0.6.0 and later installs command line tools that can be accessed through a terminal on the master node of the OpenMPF cluster. All of the tools take the form of actions: \nmpf \naction\n [options ...]\n. Note that tab-completion is enabled for ease of use.\n\n\nWARNING: These commands can be executed by anyone who has command line access to the master node.\n\n\nExecute \nmpf --help\n for general documentation and \nmpf \naction\n --help\n for documentation about a specific action.\n\n\n\n\nStart / Stop Actions\n: Actions for starting and stopping the OpenMPF system dependencies, including mySQL, ActiveMQ, Redis, Tomcat, and the node managers on the various nodes in the OpenMPF cluster.\n\n\nmpf status\n: displays a message indicating whether each of the system dependencies is running or not\n\n\nmpf start\n: starts all of the system dependencies\n\n\nmpf stop\n: stops all of the system dependencies\n\n\nmpf restart\n : stops and then starts all of the system dependencies\n\n\n\n\n\n\nUser Actions\n: Actions for managing workflow manager user accounts. If changes are made to an existing user then that user will need to log off or the workflow manager will need to be restarted for the changes to take effect.\n\n\nmpf list-users\n : lists all of the existing user accounts and their role (non-admin or admin)\n\n\nmpf add-user \nusername\n \nrole\n: adds a new user account; will be prompted to enter the account password\n\n\nmpf remove-user \nusername\n : removes an existing user account\n\n\nmpf change-role \nusername\n \nrole\n : change the role (non-admin to admin or vice versa) for an existing user\n\n\nmpf change-password \nusername\n: change the password for an existing user; will be prompted to enter the new account password\n\n\n\n\n\n\nClean Actions\n: Actions to remove old data and revert the system to a new install state. User accounts, registered components, as well as custom actions, tasks, and pipelines, are preserved.\n\n\nmpf clean\n: cleans out old job information and results, pending job requests, marked up media files, and ActiveMQ data, but preserves log files and uploaded media\n\n\nmpf clean --delete-logs --delete-uploaded-media\n: the same as \nmpf clean\n but also deletes log files and uploaded media", 
            "title": "Admin Guide"
        }, 
        {
            "location": "/Admin-Manual/#web-ui", 
            "text": "The login procedure, as well as all of the pages accessible through the Workflow Manager sidebar, are the same for admin and non-admin users. Refer to the  User Guide  for more information. The default account for an admin user has the username \"admin\" and password \"mpfadm\".  This document will cover the additional functionality permitted to admin users through the Admin Console pages.", 
            "title": "Web UI"
        }, 
        {
            "location": "/Admin-Manual/#dashboard", 
            "text": "The landing page for an admin user is the Job Status page:   The Job Status page displays a summary of the status for all jobs run by any user in the past. The current status and progress of any running job can be monitored from this view, which is updated automatically.", 
            "title": "Dashboard"
        }, 
        {
            "location": "/Admin-Manual/#node-configuration-and-status", 
            "text": "This page provides a list of all of the services that are configured to run on the OpenMPF cluster, and enables an admin user to start, stop, or restart them on an individual basis. Only an admin user can perform these actions. If a non-admin user views this page, the \"Action(s)\" column is not displayed. This page also enables an admin user to edit the configuration for all nodes in the OpenMPF cluster. A non-admin user can only view the existing configuration.   An admin user can add a node by using the \"Add Node\" button and selecting a node in the OpenMPF cluster from the drop-down list. You an also select to add all services at this time. A node and all if its configured services can be removed by clicking the trash can to the right of the node's hostname.  An admin user can add services individually by selecting the node edit button at the bottom of the node. The number of service instances can be increased or decreased by using the drop-down. Click the \"Submit\" button to save the changes.  Any node or service changes take effect immediately, no saving is required, except for adding services.  When making changes, please be aware of the following:   It may take a minute for the configuration to take effect on the server.  If you remove an existing service from a node, any job that service is processing will be stopped, and you will need to resubmit that job.  If you create a new node, its configuration will not take effect until the OpenMPF software is properly installed and started on the associated host.  If you delete a node, you will need to manually turn off the hardware running that node (deleting a node does not shut down the machine).", 
            "title": "Node Configuration and Status"
        }, 
        {
            "location": "/Admin-Manual/#properties-settings", 
            "text": "This page allows an admin user to view and edit various OpenMPF properties:   An admin user can click inside of the \"Value\" field for any of the properties and type a new value. Doing so will change the color of the property to orange and display an orange icon to the right of the property name.  Note that if the admin user types in the original value of the property, or clicks the \"Reset\" button, then it will return back to the normal coloration.  WARNING: Changing the value of these properties can prevent the workflow manager from running after the web server is restarted. Also, no validation checks are performed on the user-provided values. Proceed with caution!  At the bottom of the properties table is the \"Save Properties\" button. The number of modified properties is shown in parentheses. Clicking the button will make the necessary changes to the properties file on the file system, but the changes will not take effect until the workflow manager is restarted. The saved properties will be colored blue and a blue icon will be displayed to the right of the property name. Additionally, a notification will appear at the top of the page alerting all system users that a restart is required:", 
            "title": "Properties Settings"
        }, 
        {
            "location": "/Admin-Manual/#component-registration", 
            "text": "This page allows an admin user to add and remove non-default components to and from the system:   A component package takes the form of a tar.gz file. An admin user can either drag and drop the file onto the \"Upload a new component\" dropzone area or click the dropzone area to open a file browser and select the file that way. In either case, the component will begin to be uploaded to the system. If the admin user dragged and dropped the file onto the dropzone area then the upload progress will be shown in that area. Once uploaded, the workflow manager will automatically attempt to register the component. Notification messages will appear in the upper right side of the screen to indicate success or failure if an error occurs. The \"Current Components\" table will display the component status.   If for some reason the component package upload succeeded but the component registration failed then the admin user will be able to click the \"Register\" button again to try to another registration attempt. For example, the admin user may do this after reviewing the workflow manager logs and resolving any issues that prevented the component from successfully registering the first time. One reason may be that a component with the same name already exists on the system. Note that an error will also occur if the top-level directory of the component package, once extracted, already exists in the /opt/mpf/plugins directory on the system.  Once registered, an admin user has the option to remove the component. This will unregister it and completely remove any configured services, as well as the uploaded file and its extracted contents, from the system. Also, the component algorithm as well as any actions, tasks, and pipelines specified in the component's descriptor file will be removed when the component is removed.  WARNING: Any actions, tasks, or pipelines created through the Create Custom Pipelines page that make use of the algorithm, actions, or tasks specified in the descriptor file of the component being removed will also be removed. This is to prevent pipelines from not working properly once the component is removed.", 
            "title": "Component Registration"
        }, 
        {
            "location": "/Admin-Manual/#command-line-tools", 
            "text": "OpenMPF release 0.6.0 and later installs command line tools that can be accessed through a terminal on the master node of the OpenMPF cluster. All of the tools take the form of actions:  mpf  action  [options ...] . Note that tab-completion is enabled for ease of use.  WARNING: These commands can be executed by anyone who has command line access to the master node.  Execute  mpf --help  for general documentation and  mpf  action  --help  for documentation about a specific action.   Start / Stop Actions : Actions for starting and stopping the OpenMPF system dependencies, including mySQL, ActiveMQ, Redis, Tomcat, and the node managers on the various nodes in the OpenMPF cluster.  mpf status : displays a message indicating whether each of the system dependencies is running or not  mpf start : starts all of the system dependencies  mpf stop : stops all of the system dependencies  mpf restart  : stops and then starts all of the system dependencies    User Actions : Actions for managing workflow manager user accounts. If changes are made to an existing user then that user will need to log off or the workflow manager will need to be restarted for the changes to take effect.  mpf list-users  : lists all of the existing user accounts and their role (non-admin or admin)  mpf add-user  username   role : adds a new user account; will be prompted to enter the account password  mpf remove-user  username  : removes an existing user account  mpf change-role  username   role  : change the role (non-admin to admin or vice versa) for an existing user  mpf change-password  username : change the password for an existing user; will be prompted to enter the new account password    Clean Actions : Actions to remove old data and revert the system to a new install state. User accounts, registered components, as well as custom actions, tasks, and pipelines, are preserved.  mpf clean : cleans out old job information and results, pending job requests, marked up media files, and ActiveMQ data, but preserves log files and uploaded media  mpf clean --delete-logs --delete-uploaded-media : the same as  mpf clean  but also deletes log files and uploaded media", 
            "title": "Command Line Tools"
        }, 
        {
            "location": "/API-Overview/", 
            "text": "NOTICE:\n This software (or technical data) was produced for the U.S. Government under contract, and is subject to the Rights in Data-General Clause 52.227-14, Alt. IV (DEC 2007). Copyright 2017 The MITRE Corporation. All Rights Reserved.\n\n\n\n\nOpenMPF API Overview\n\n\nThe OpenMPF Application Programming Interface (API) provides a mechanism for integrating components into OpenMPF. The goals of the document are to:\n\n   Provide an overview of OpenMPF and its API\n\n   Define a \ncomponent\n in the context of the MPF\n*   Explain the use of the API\n\n\nTerminology:\n\nIn order to talk about OpenMPF, readers should be familiar with the following key OpenMPF-specific terms:\n\n\n\n\nJob\n - An OpenMPF work unit. A job contains a list of media files and the pipeline that will be used to process that media.\n\n\nPipeline\n - A logical flow of processes that will be performed on a piece of media. For instance, a pipeline may perform motion tracking on a video and feed the results into a face detection algorithm.\n\n\nComponent\n - An OpenMPF plugin that receives jobs (containing media), processes that media, and returns results.\n\n\nDetection Component\n - A component that performs either detection (with or without tracking), or classification on a piece of media.\n\n\nNode\n - An OpenMPF host that launches components. There may be more than one node in an OpenMPF cluster, thus forming a distributed system. There is always a master node that runs the OpenMPF web application.\n\n\nService\n - An instance of an OpenMPF component process. Each OpenMPF node may run one or more services at a time. Multiple services may run in parallel to process a job. For example, each service may process a different piece of media, or a segment of the same video.\n\n\n\n\nBackground\n\n\nOpenMPF consists of the Workflow Manager, a Node Manager, components, and a message passing mechanism that enables communication between the Workflow Manager and the components.\n\n\nWorkflow Manager\n\n\nThe Workflow Manager (WFM) receives job requests from user interface and external systems through the REST API. The WFM handles each request by creating a job, which consists of a collection of input media and a pipeline. These jobs are then broken down into job requests that are handled by component services, which in turn process media and return results.\n\n\nThe WFM orchestrates the flow of work within a job through the various stages of a processing pipeline. For each stage, the WFM communicates with the appropriate component services by exchanging JMS messages via a message broker. For example, if a pipeline consists of a motion detection stage, then the WFM will communicate with motion detection component services.\n\n\nThe WFM provides work to a component service by placing a job request on the request queue, and it retrieves the component\u2019s response by monitoring the appropriate response queue. The WFM may generate one or more job requests for a large video file, depending on how it segments the file into chunks. The segmentation properties can be specified system-wide using configuration files, or specified on a per-job basis.\n\n\n\n\nNote:\n All component messaging is abstracted within the OpenMPF Component API and component developers are not required or able to directly interact with the message queues.\n\n\n\n\nNode Manager\n\n\nThe Node Manager is a process that runs on each OpenMPF node. The Node Manager handles spawning the desired number of instances of a component based on the end-user's desired configuration. Each instance is referred to as a service.\n\n\nAfter the Node Manager spawns a service, the service waits for job requests from the Workflow Manager and produces a response for each request.\n\n\nComponents\n\n\nComponents are identified by seven key characteristics:\n\n   The \ntype of action\n the component performs\n\n   The \ntypes of data\n it supports\n\n   The \ntype of objects\n it detects\n\n   The \nname\n of the algorithm or vendor\n\n   The user-configurable \nproperties\n that the component exposes\n\n   The \nrequired states\n associated with a job prior to the execution of the component\n\n   The \nprovided states* associated with a job following the execution of the component\n\n\nA component\u2019s action type corresponds to the operation which the algorithm performs. Generally, this is \nDETECTION\n.\n\n\nThe data that a component accepts as inputs, and correspondingly produces as outputs, constrains its placement in a pipeline. This is some combination of \nIMAGE\n, \nAUDIO\n, and \nVIDEO\n.\n\n\nAs depicted in the figure below, detection components accept an input media file (or segment of the file in the case of video files) and produce a collection of object detections discovered in the data.\n\n\nThe type of objects produced depends on the input type. For example, video files produce video tracks, audio files produce audio tracks, and images produce image locations.\n\n\n\n\nThe OpenMPF Component Interface API presented provides developers an interface for developing new components for OpenMPF without requiring the developers to understand the internals of the framework.\n\n\nThe figure below depicts a high-level block diagram of the OpenMPF architecture with components.\n\n\n\n\nThe Component Registry serves as a central location for information about the components registered with the OpenMPF instance. A future goal is to develop a web page that can be used to browse the registry and display the metadata associated with each available component.\n\n\nOpenMPF includes a Component Executable for the \nDETECTION\n action type, as denoted by the blue cubes. Note that the Component Executable is shown three times to represent three instances of that process, one for each component type. This executable is responsible for loading a component library based on information provided at launch time from the Node Manager. \n\n\nOne Component Executable instance is associated with each component service. For example, a motion detection service, face detection service, and text detection service will require three instances of the Component Executable process, one for each service. For another example, three motion detection services will also require three instances of the Component Executable process, one for each service. The Component Executable is abstract; it does not care what kind of detection is performed. It simply interacts with the component library through the Component API.\n\n\nThe Component Executable receives job requests from the message broker, translates those requests for the component, and converts the component\u2019s outputs into response messages for the OpenMPF.\n\n\nA separate Component Executable is maintained for C++ and Java components. The component library is compiled as a C++ shared object library, or Java JAR, and encapsulates the component's detection logic.", 
            "title": "Component Overview"
        }, 
        {
            "location": "/API-Overview/#openmpf-api-overview", 
            "text": "The OpenMPF Application Programming Interface (API) provides a mechanism for integrating components into OpenMPF. The goals of the document are to:    Provide an overview of OpenMPF and its API    Define a  component  in the context of the MPF\n*   Explain the use of the API  Terminology: \nIn order to talk about OpenMPF, readers should be familiar with the following key OpenMPF-specific terms:   Job  - An OpenMPF work unit. A job contains a list of media files and the pipeline that will be used to process that media.  Pipeline  - A logical flow of processes that will be performed on a piece of media. For instance, a pipeline may perform motion tracking on a video and feed the results into a face detection algorithm.  Component  - An OpenMPF plugin that receives jobs (containing media), processes that media, and returns results.  Detection Component  - A component that performs either detection (with or without tracking), or classification on a piece of media.  Node  - An OpenMPF host that launches components. There may be more than one node in an OpenMPF cluster, thus forming a distributed system. There is always a master node that runs the OpenMPF web application.  Service  - An instance of an OpenMPF component process. Each OpenMPF node may run one or more services at a time. Multiple services may run in parallel to process a job. For example, each service may process a different piece of media, or a segment of the same video.", 
            "title": "OpenMPF API Overview"
        }, 
        {
            "location": "/API-Overview/#background", 
            "text": "OpenMPF consists of the Workflow Manager, a Node Manager, components, and a message passing mechanism that enables communication between the Workflow Manager and the components.", 
            "title": "Background"
        }, 
        {
            "location": "/API-Overview/#workflow-manager", 
            "text": "The Workflow Manager (WFM) receives job requests from user interface and external systems through the REST API. The WFM handles each request by creating a job, which consists of a collection of input media and a pipeline. These jobs are then broken down into job requests that are handled by component services, which in turn process media and return results.  The WFM orchestrates the flow of work within a job through the various stages of a processing pipeline. For each stage, the WFM communicates with the appropriate component services by exchanging JMS messages via a message broker. For example, if a pipeline consists of a motion detection stage, then the WFM will communicate with motion detection component services.  The WFM provides work to a component service by placing a job request on the request queue, and it retrieves the component\u2019s response by monitoring the appropriate response queue. The WFM may generate one or more job requests for a large video file, depending on how it segments the file into chunks. The segmentation properties can be specified system-wide using configuration files, or specified on a per-job basis.   Note:  All component messaging is abstracted within the OpenMPF Component API and component developers are not required or able to directly interact with the message queues.", 
            "title": "Workflow Manager"
        }, 
        {
            "location": "/API-Overview/#node-manager", 
            "text": "The Node Manager is a process that runs on each OpenMPF node. The Node Manager handles spawning the desired number of instances of a component based on the end-user's desired configuration. Each instance is referred to as a service.  After the Node Manager spawns a service, the service waits for job requests from the Workflow Manager and produces a response for each request.", 
            "title": "Node Manager"
        }, 
        {
            "location": "/API-Overview/#components", 
            "text": "Components are identified by seven key characteristics:    The  type of action  the component performs    The  types of data  it supports    The  type of objects  it detects    The  name  of the algorithm or vendor    The user-configurable  properties  that the component exposes    The  required states  associated with a job prior to the execution of the component    The  provided states* associated with a job following the execution of the component  A component\u2019s action type corresponds to the operation which the algorithm performs. Generally, this is  DETECTION .  The data that a component accepts as inputs, and correspondingly produces as outputs, constrains its placement in a pipeline. This is some combination of  IMAGE ,  AUDIO , and  VIDEO .  As depicted in the figure below, detection components accept an input media file (or segment of the file in the case of video files) and produce a collection of object detections discovered in the data.  The type of objects produced depends on the input type. For example, video files produce video tracks, audio files produce audio tracks, and images produce image locations.   The OpenMPF Component Interface API presented provides developers an interface for developing new components for OpenMPF without requiring the developers to understand the internals of the framework.  The figure below depicts a high-level block diagram of the OpenMPF architecture with components.   The Component Registry serves as a central location for information about the components registered with the OpenMPF instance. A future goal is to develop a web page that can be used to browse the registry and display the metadata associated with each available component.  OpenMPF includes a Component Executable for the  DETECTION  action type, as denoted by the blue cubes. Note that the Component Executable is shown three times to represent three instances of that process, one for each component type. This executable is responsible for loading a component library based on information provided at launch time from the Node Manager.   One Component Executable instance is associated with each component service. For example, a motion detection service, face detection service, and text detection service will require three instances of the Component Executable process, one for each service. For another example, three motion detection services will also require three instances of the Component Executable process, one for each service. The Component Executable is abstract; it does not care what kind of detection is performed. It simply interacts with the component library through the Component API.  The Component Executable receives job requests from the message broker, translates those requests for the component, and converts the component\u2019s outputs into response messages for the OpenMPF.  A separate Component Executable is maintained for C++ and Java components. The component library is compiled as a C++ shared object library, or Java JAR, and encapsulates the component's detection logic.", 
            "title": "Components"
        }, 
        {
            "location": "/CPP-Component-API/", 
            "text": "NOTICE:\n This software (or technical data) was produced for the U.S. Government under contract, and is subject to the Rights in Data-General Clause 52.227-14, Alt. IV (DEC 2007). Copyright 2017 The MITRE Corporation. All Rights Reserved.\n\n\n\n\nC++ Component API Overview\n\n\nIn OpenMPF, a \ncomponent\n is a plugin that receives jobs (containing media), processes that  media, and returns results.\n\n\nThe OpenMPF Component API currently supports the development of \ndetection components\n, which are used detect objects in image, video, or audio files.\n\n\nUsing this API, detection components can be built to provide:\n\n\n\n\nDetection (Localizing an object)\n\n\nTracking (Localizing an object across multiple frames)\n\n\nClassification (Detecting the type of object and optionally localizing that object)\n\n\nTranscription (Detecting speech and transcribing it into text)\n\n\n\n\nHow Components Integrate into OpenMPF\n\n\nComponents are integrated into OpenMPF through the use of OpenMPF's \nComponent Executable\n. Developers create component libraries that encapsulate the component detection logic. Each instance of the Component Executable loads one these libraries and uses it to service job requests sent by the OpenMPF Workflow Manager (WFM).\n\n\nThe Component Executable:\n\n\n\n\nReceives and parses job requests from the WFM\n\n\nInvokes functions on the component library to obtain detection results\n\n\nPopulates and sends the respective responses to the WFM\n\n\n\n\nThe basic psuedocode for the Component Executable is as follows:\n\n\ncomponent-\nSetRunDirectory(...)\ncomponent-\nInit()\nwhile (true) {\n  job = ReceiveJob()\n  if (component-\nSupports(job.data_type))\n    component-\nGetDetections(...) // Component logic does the work here\n  SendJobResponse()\n}\ncomponent-\nClose()\n\n\n\n\nEach instance of a Component Executable runs as a separate process.\n\n\nThe Component Executable receives and parses requests from the WFM, invokes functions on the Component Logic to get detection objects, and subsequently populates responses with the component output and sends them to the WFM.\n\n\nA component developer implements a detection component by extending \nMPFDetectionComponent\n.\n\n\nAs an alternative to extending \nMPFDetectionComponent\n directly, a developer may extend one of several convenience adapter classes provided by OpenMPF. See \nConvenience Adapters\n for more information.\n\n\nGetting Started\n\n\nThe quickest way to get started with the OpenMPF Component API is to first read the \nOpenMPF Component API Overview\n and then \nreview the source\n for example OpenMPF C++ detection components.\n\n\nDetection components are implemented by:\n\n\n\n\nExtending \nMPFDetectionComponent\n.\n\n\nBuilding the component into a shared object library. (See \nHelloWorldComponent CMakeLists.txt\n).\n\n\nPackaging the component into an OpenMPF-compliant .tar.gz file. (See \nComponent Packaging\n).\n\n\nRegistering the component with OpenMPF (see \nPackaging and Registering a Component\n).\n\n\n\n\nOpenMPF API Specification\n\n\nThe figure below presents a high-level component diagram of the OpenMPF API:\n\n\n\n\nThe API consists of \nComponent Interfaces\n, which provide interfaces and abstract classes for developing components; \nJob Definitions\n, which define the work to be performed by a component; \nJob Results\n, which define the results generated by the component; \nComponent Adapters\n, which provide default implementations of several of the \nMPFDetectionComponent\n interface; and \nComponent Utilities\n, which perform actions such as image rotation, and cropping.\n\n\nComponent Interface\n\n\n\n\nMPFComponent\n - Abstract base class for components.\n\n\n\n\nDetection Component Interface\n\n\n\n\nMPFDetectionComponent\n extends \nMPFComponent\n - Abstract class that should be extended by all OpenMPF detection components.\n\n\n\n\nJob Definitions\n\n\nThe following data structures contain details about a specific job (work unit):\n\n\n\n\nMPFImageJob\n extends \nMPFJob\n\n\nMPFVideoJob\n extends \nMPFJob\n\n\nMPFAudioJob\n extends \nMPFJob\n\n\n\n\nJob Results\n\n\nThe following classes define the results of a component's processing:\n\n\n\n\nMPFImageLocation\n\n\nMPFVideoTrack\n\n\nMPFAudioTrack\n\n\n\n\nComponents must also include two \nComponent Factory Functions\n.\n\n\nOpenMPF Component API\n\n\nThe \nMPFComponent\n class is the abstract base class utilized by all OpenMPF components.\n\n\nSee the latest source here.\n\n\n\n\nIMPORTANT:\n This interface should not be directly implemented, because no mechanism exists for launching components based off of it. Currently, the only supported type of component is detection, and all components should instead extend \nMPFDetectionComponent\n.\n\n\n\n\nInit()\n\n\nThe component should perform all initialization operations in the \nInit\n member function.\n\nInit\n will be called once by the OpenMPF Component Executable before any other member functions.\n\n\n\n\nFunction Definition:\n\nbool Init()\n\n\nParameters: none\n\n\nReturns: (bool) Return true if initialization is successful, otherwise return false.\n\n\nExample:\n\n\n\n\nbool SampleComponent::Init() {\n  // Get component paths\n  string run_dir = GetRunDirectory();\n  string plugin_path = run_dir + \n/SampleComponent\n;\n  string config_path = plugin_path + \n/config\n;\n\n  // Setup logger, load data models, etc.\n\n  return true;\n}\n\n\n\n\nClose()\n\n\nThe component should perform all shutdown operations in the \nClose\n member function.\n\nClose\n will be called once by the OpenMPF Component Executable prior to component shutdown.\n\n\nThis method is called before the component instance is deleted (see \nComponent Factory Functions\n).\n\n\n\n\nFunction Definition:\n\nbool Close()\n\n\nParameters: none\n\n\nReturns: (bool) Return true if successful, otherwise return false.\n\n\nExample:\n\n\n\n\n    bool SampleComponent::Close() {\n        // Free memory, etc.\n        return true;\n    }\n\n\n\n\nGetComponentType()\n\n\nThe GetComponentType() member function allows the OpenMPF Component API to determine the component \"type.\" Currently \nMPF_DETECTION_COMPONENT\n is the only supported component type. APIs for other component types may be developed in the future.\n\n\n\n\nFunction Definition:\n\nMPFComponentType GetComponentType()\n\n\nParameters: none\n\n\nReturns: (MPFComponentType) Currently, \nMPF_DETECTION_COMPONENT\n is the only supported return value.\n\n\nExample:\n\n\n\n\n    MPFComponentType SampleComponent::GetComponentType() {\n        return MPF_DETECTION_COMPONENT;\n    };\n\n\n\n\nGetRunDirectory()\n\n\nReturns the value of the private \nrun_directory\n data member which contains the full path of the parent folder above where the component is installed. This parent folder is also known as the plugin folder.\n\n\n\n\nFunction Definition:\n\nstring GetRunDirectory()\n\n\nParameters: none\n\n\nReturns: (string) Full path of the parent folder above where the component is installed.\n\n\nSample Usage:\n\n\n\n\n    string run_dir = GetRunDirectory();\n    string plugin_path = run_dir + \n/SampleComponent\n;\n    string config_path = plugin_path + \n/config\n;\n    string logconfig_file = config_path + \n/Log4cxxConfig.xml\n;\n\n\n\n\nSetRunDirectory(string)\n\n\nSets the value of the private \nrun_directory\n data member which contains the full path of the parent folder above where the component is installed.\n\n\n\n\nFunction Definition:\n\nvoid SetRunDirectory(const string \nrun_dir)\n\n\n\n\nParameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nData Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nrun_dir\n\n\nconst string \n\n\nFull path of the parent folder above where the component is installed.\n\n\n\n\n\n\n\n\n\n\n\n\nReturns: void\n\n\n\n\n\n\n\n\nIMPORTANT:\n \nSetRunDirectory\n is called by the Component Executable to set the correct path. This function should not be called within your implementation.\n\n\n\n\nComponent Factory Functions\n\n\nEvery detection component must include the following macros in its implementation:\n\n\nMPF_COMPONENT_CREATOR(TYPENAME);\n\n\nMPF_COMPONENT_DELETER();\n\n\nThe creator macro takes the \nTYPENAME\n of the detection component (for example, \u201cHelloWorldComponent\u201d). This macro creates the factory function that the OpenMPF Component Executable will call in order to instantiate the detection component. The creation function is called once, to obtain an instance of the component, after the component library has been loaded into memory.\n\n\nThe deleter macro creates the factory function that the Component Executable will use to delete that instance of the detection component. These macros must be used outside of a class declaration, preferably at the bottom or top of a component header file.\n\n\nExample:\n\n\n// Note: Do not put the TypeName/Class Name in quotes\nMPF_COMPONENT_CREATOR(ComponentNameHere);\nMPF_COMPONENT_DELETER();\n\n\n\n\nOpenMPF Detection Component API\n\n\nThe \nMPFDetectionComponent\n class is the abstract class utilized by all OpenMPF detection components. This class provides functions for developers to integrate detection logic into OpenMPF.\n\n\nSee the latest source here.\n\n\n\n\nIMPORTANT:\n Each detection component must implement all of the \nGetDetections()\n functions or extend from a superclass which provides implementations for them (see \nconvenience adapters\n).\n\n\nIf your component does not support a particular data type, it should simply:\n\nreturn MPF_UNSUPPORTED_DATA_TYPE;\n\n\n\n\nConvenience Adapters\n\n\nAs an alternative to extending \nMPFDetectionComponent\n directly, developers may extend one of several convenience adapter classes provided by OpenMPF.\n\n\nThese adapters provide default implementations of several methods in \nMPFDetectionComponent\n and ensure that the component's logic properly extends from the Component API. This enables developers to concentrate on implementation of the detection algorithm.\n\n\nThe following adapters are provided:\n\n\n\n\nImage Detection (\nsource\n)\n\n\nVideo Detection (\nsource\n)\n\n\nImage and Video Detection (\nsource\n)\n\n\nAudio Detection (\nsource\n)\n\n\nAudio and Video Detection (\nsource\n)\n\n\n\n\n\n\nExample: Creating Adaptors to Perform Naive Tracking:\n\nA simple detector that operates on videos may simply go through the video frame-by-frame, extract each frame\u2019s data, and perform detections on that data as though it were processing a new unrelated image each time. As each frame is processed, one or more \nMPFImageLocations\n are generated.\n\n\nGenerally, it is preferred that a detection component that supports \nVIDEO\n data is able to perform tracking across video frames to appropriately correlate \nMPFImageLocation\n detections across frames.\n\n\nAn adapter could be developed to perform simple tracking. This would correlate \nMPFImageLocation\n detections across frames by na\u00efvely looking for bounding box regions in each contiguous frame that overlap by a given threshold such as 50%.\n\n\n\n\nDetection Component Interface\n\n\nSupports(MPFDetectionDataType)\n\n\nReturns true or false depending on the data type is supported or not.\n\n\n\n\nFunction Definition:\n\nbool Supports(MPFDetectionDataType data_type)\n\n\n\n\nParameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nData Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ndata_type\n\n\nMPFDetectionDataType\n\n\nComponent should only return true for IMAGE, VIDEO, and/or AUDIO.\n\n\n\n\n\n\n\n\n\n\n\n\nReturns: (bool) True if the component supports the data type, otherwise false.\n\n\n\n\nExample:\n\n\n\n\n    // Sample component that supports only image and video files\n    bool SampleComponent::Supports(MPFDetectionDataType data_type) {\n        return data_type == MPFDetectionDataType::IMAGE || data_type == MPFDetectionDataType::VIDEO;\n    }\n\n\n\n\nGetDetectionType()\n\n\nReturns the type of object detected by the component.\n\n\n\n\nFunction Definition:\n\nstring GetDetectionType()\n\n\n\n\nParameters: None\n\n\n\n\n\n\nReturns: (string) The type of object detected by the component. Should be in all CAPS. Examples include: \nFACE\n, \nMOTION\n, \nPERSON\n, \nSPEECH\n, \nCLASS\n (for object classification), or \nTEXT\n.\n\n\n\n\nExample:\n\n\n\n\n    string SampleComponent::GetDetectionType() {\n        return \nFACE\n;\n    }\n\n\n\n\nGetDetections(MPFImageJob \u2026)\n\n\nUsed to detect objects in an image file. The MPFImageJob structure contains the data_uri specifying the location of the image file.\n\n\nCurrently, the data_uri is always a local file path. For example, \"/opt/mpf/share/remote-media/test-file.jpg\". This is because all media is copied to the OpenMPF server before the job is executed.\n\n\n\n\nFunction Definition:\n\n\n\n\n    MPFDetectionError GetDetections(const MPFImageJob \njob, vector\nMPFImageLocation\n \nlocations)\n\n\n\n\n\n\n\n\nParameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nData Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\njob\n\n\nconst MPFImageJob \n\n\nStructure containing details about the work to be performed. See \nMPFImageJob\n\n\n\n\n\n\nlocations\n\n\nvector\nMPFImageLocation\n \n\n\nThe \nMPFImageLocation\n data for each detected object.\n\n\n\n\n\n\n\n\n\n\n\n\nReturns: \nMPFDetectionError\n\n\n\n\nExample:\n\n\n\n\n    MPFDetectionError SampleComponent::GetDetections(const MPFImageJob \njob, vector\nMPFImageLocation\n \nlocations) {\n        // Parse job\n        // Generate image locations\n        return MPF_DETECTION_SUCCESS;\n    }\n\n\n\n\nGetDetections(MPFVideoJob \u2026)\n\n\nUsed to detect objects in a video file. Prior to being sent to the component, videos are split into logical \"segments\" of video data and each segment (containing a range of frames) is assigned to a different job. Components are not guaranteed to receive requests in any order. For example, the first request processed by a component might receive a request for frames 300-399 of a Video A, while the next request may cover frames 900-999 of a Video B.\n\n\n\n\nFunction Definition:\n\n\n\n\n    MPFDetectionError getDetections(const MPFVideoJob \njob, vector\nMPFVideoTrack\n tracks);\n\n\n\n\n\n\n\n\nParameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nData Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\njob\n\n\nconst MPFVideoJob \n\n\nStructure containing details about the work to be performed. See \nMPFVideoJob\n\n\n\n\n\n\ntracks\n\n\nvector\nMPFVideoTrack\n \n\n\nThe \nMPFVideoTrack\n data for each detected object.\n\n\n\n\n\n\n\n\n\n\n\n\nReturns: \nMPFDetectionError\n\n\n\n\nExample:\n\n\n\n\n    MPFDetectionError SampleComponent::GetDetections(const MPFAudioJob \njob, vector\nMPFAudioTrack\n \ntracks) {\n        // Parse job\n        // Generate tracks\n        return MPF_DETECTION_SUCCESS;\n    }\n\n\n\n\nGetDetections(MPFAudioJob \u2026)\n\n\nUsed to detect objects in an audio file. Currently, audio files are not logically segmented, so a job will contain the entirety of the audio file.\n\n\n\n\nFunction Definition:\n\n\n\n\n    MPFDetectionError GetDetections(const MPFAudioJob \njob, vector\nMPFAudioTrack\n \ntracks)\n\n\n\n\n\n\n\n\nParameters:\n\n\n\n\n\n\n\n\nParameter\n\n\nData Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\njob\n\n\nconst MPFAudioJob \n\n\nStructure containing details about the work to be performed. See \nMPFAudioJob\n\n\n\n\n\n\ntracks\n\n\nvector\nMPFAudioTrack\n \n\n\nThe \nMPFAudioTrack\n data for each detected object\n\n\n\n\n\n\n\n\n\n\n\n\nReturns: \nMPFDetectionError\n\n\n\n\nExample:\n\n\n\n\n    MPFDetectionError GetDetections(const MPFAudioJob \njob, vector\nMPFAudioTrack\n \ntracks) {\n        // Parse job\n        // Generate tracks\n        return MPF_DETECTION_SUCCESS;\n    }\n\n\n\n\nDetection Job Data Structures\n\n\nThe \nMPFDetectionComponent\n data structures contain details about a specific job (work unit):\n\n\n\n\nMPFImageJob\n extends \nMPFJob\n\n\nMPFVideoJob\n extends \nMPFJob\n\n\nMPFAudioJob\n extends \nMPFJob\n\n\n\n\nThe following data structures contain details about detection results:\n\n\n\n\nMPFImageLocation\n\n\nMPFVideoTrack\n\n\nMPFAudioTrack\n\n\n\n\nMPFJob\n\n\nStructure containing information about about a job to be performed on a piece of media.\n\n\n\n\nConstructor(s):\n\n\n\n\n    MPFJob(\n      const string \njob_name,\n      const string \ndata_uri,\n      const Properties \njob_properties,\n      const Properties \nmedia_properties)\n\n\n\n\n\n\n\n\nMembers:\n\n\n\n\n\n\n\n\nMember\n\n\nData Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\njob_name \n\n\nconst string  \n\n\nA specific name given to the job by the OpenMPF framework. This value may be used, for example, for logging and debugging purposes.\n\n\n\n\n\n\ndata_uri \n\n\nconst string  \n\n\nThe URI of the input media file to be processed. Currently, this is a file path. For example, \"/opt/mpf/share/remote-media/test-file.avi\".\n\n\n\n\n\n\njob_properties \n\n\nconst Properties \n\n\nContains a map of \nstring, string\n which represents the property name and the property value. The key corresponds to the property name specified in the component descriptor file described in \nPackaging and Registering a Component\n. Values are determined when creating a pipeline or when submitting a job. \n Note: The job_properties map may not contain the full set of job properties. For properties not contained in the map, the component must use a default value.\n\n\n\n\n\n\nmedia_properties \n\n\nconst Properties \n\n\nContains a map of \nstring, string\n of metadata about the media associated with the job. The entries in the map vary depending on the type of media. Refer to the type-specific job structures below.\n\n\n\n\n\n\n\n\n\n\n\n\nMPFImageJob\n\n\nExtends \nMPFJob\n\n\nStructure containing data used for detection of objects in an image file.\n\n\n\n\nConstructor(s):\n\n\n\n\n    MPFImageJob(\n        const string \njob_name,\n        const string \ndata_uri,\n        const Properties \njob_properties,\n        const Properties \nmedia_properties)\n\n\n\n\n\n\n\n\nMembers:\n\n\n\n\n\n\n\n\nMember\n\n\nData Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\njob_name\n\n\nconst string \n\n\nSee \nMPFJob.job_name\n for description.\n\n\n\n\n\n\ndata_uri\n\n\nconst string \n\n\nSee \nMPFJob.data_uri\n for description.\n\n\n\n\n\n\njob_properties\n\n\nconst Properties \n\n\nSee \nMPFJob.job_properties\n for description.\n\n\n\n\n\n\nmedia_properties\n\n\nconst Properties \n\n\nSee \nMPFJob.media_properties\n for description.\nThis may include the following key-value pairs:\nROTATION\n : 0, 90, 180, or 270 degrees\nHORIZONTAL_FLIP\n : true if the image is mirrored across the Y-axis, otherwise false\nEXIF_ORIENTATION\n : the standard EXIF orientation tag; a value between 1 and 8\n\n\n\n\n\n\n\n\n\n\n\n\nMPFVideoJob\n\n\nExtends \nMPFJob\n\n\nStructure containing data used for detection of objects in a video file.\n\n\n\n\nConstructor(s):\n\n\n\n\n    MPFVideoJob(\n      const string \njob_name,\n      const string \ndata_uri,\n      int start_frame,\n      int stop_frame,\n      const Properties \njob_properties,\n      const Properties \nmedia_properties)\n\n\n\n\n\n\n\n\nMembers:\n\n\n\n\n\n\n\n\nMember\n\n\nData Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\njob_name\n\n\nconst string \n\n\nSee \nMPFJob.job_name\n for description.\n\n\n\n\n\n\ndata_uri\n\n\nconst string \n\n\nSee \nMPFJob.data_uri\n for description.\n\n\n\n\n\n\nstart_frame\n\n\nconst int\n\n\nThe first frame number (0-based index) of the video that should be processed to look for detections.\n\n\n\n\n\n\nstop_frame\n\n\nconst int\n\n\nThe last frame number (0-based index) of the video that should be processed to look for detections.\n\n\n\n\n\n\njob_properties\n\n\nconst Properties \n\n\nSee \nMPFJob.job_properties\n for description.\n\n\n\n\n\n\nmedia_properties\n\n\nconst Properties \n\n\nSee \nMPFJob.media_properties\n for description.\n \nIncludes the following key-value pairs:\nDURATION\n : length of video in milliseconds\nFPS\n : frames per second (averaged for variable frame rate video)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIMPORTANT:\n For frame intervals greater than 1, the component must look for detections starting with the first frame, and then skip frames as specified by the frame interval, until or before it reaches the stop frame. For example, given a start frame of 0, a stop frame of 99, and a frame interval of 2, then the detection component must look for objects in frames numbered 0, 2, 4, 6, ..., 98.\n\n\n\n\nMPFAudioJob\n\n\nExtends \nMPFJob\n\n\nStructure containing data used for detection of objects in an audio file. Currently, audio files are not logically segmented, so a job will contain the entirety of the audio file.\n\n\n\n\nConstructor(s):\n\n\n\n\n    MPFAudioJob(\n      const string \njob_name,\n      const string \ndata_uri,\n      int start_time,\n      int stop_time,\n      const Properties \njob_properties,\n      const Properties \nmedia_properties)\n\n\n\n\n\n\n\n\nMembers:\n\n\n\n\n\n\n\n\nMember\n\n\nData Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\njob_name\n\n\nconst string \n\n\nSee \nMPFJob.job_name\n for description.\n\n\n\n\n\n\ndata_uri\n\n\nconst string \n\n\nSee \nMPFJob.data_uri\n for description.\n\n\n\n\n\n\nstart_time\n\n\nconst int\n\n\nThe time (0-based index, in milliseconds) associated with the beginning of the segment of the audio file that should be processed to look for detections.\n\n\n\n\n\n\nstop_time\n\n\nconst int\n\n\nThe time (0-based index, in milliseconds) associated with the end of the segment of the audio file that should be processed to look for detections.\n\n\n\n\n\n\njob_properties\n\n\nconst Properties \n\n\nSee \nMPFJob.job_properties\n for description.\n\n\n\n\n\n\nmedia_properties\n\n\nconst Properties \n\n\nSee \nMPFJob.media_properties\n for description.\n \nIncludes the following key-value pair:\nDURATION\n : length of audio file in milliseconds\n\n\n\n\n\n\n\n\n\n\n\n\nDetection Job Result Classes\n\n\nMPFImageLocation\n\n\nStructure used to store the location of detected objects in a image file.\n\n\n\n\nConstructor(s):\n\n\n\n\n    MPFImageLocation()\n    MPFImageLocation(\n      int x_left_upper,\n      int y_left_upper,\n      int width,\n      int height,\n      float confidence = -1,\n      const Properties \ndetection_properties = {})\n\n\n\n\n\n\n\n\nMembers:\n\n\n\n\n\n\n\n\nMember\n\n\nData Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nx_left_upper\n\n\nint\n\n\nUpper left X coordinate of the detected object.\n\n\n\n\n\n\ny_left_upper\n\n\nint\n\n\nUpper left Y coordinate of the detected object.\n\n\n\n\n\n\nwidth\n\n\nint\n\n\nThe width of the detected object. If the detection consists of the entire image, use 0.\n\n\n\n\n\n\nheight\n\n\nint\n\n\nThe height of the detected object. If the detection consists of the entire image, use 0.\n\n\n\n\n\n\nconfidence\n\n\nfloat\n\n\nRepresents the \"quality\" of the detection. The range depends on the detection algorithm. 0.0 is lowest quality. Higher values are higher quality. Using a standard range of [0.0 - 1.0] is advised. If the component is unable to supply a confidence value, it should return -1.0.\n\n\n\n\n\n\ndetection_properties\n\n\nProperties \n\n\nOptional additional information about the detected object. There is no restriction on the keys or the number of entries that can be added to the detection_properties map. For best practice, keys should be in all CAPS.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEXAMPLE - Using detection_properties\n: A component that performs generic object classification could add an entry to the detection_properties which corresponds to the type of object detected.\n\n\nSource:\n\n\n\n\nMPFImageLocation detection;\ndetection.x_left_upper = 0;\ndetection.y_left_upper = 0;\ndetection.width = 0;\ndetection.height = 0;\ndetection.confidence = probability;\ndetection.detection_properties[\nCLASSIFICATION\n] = \nbackpack\n;\n\n\n\n\nMPFVideoTrack\n\n\nStructure used to store the location of detected objects in a video file.\n\n\n\n\nConstructor:\n\n\n\n\n    MPFVideoTrack()\n    MPFVideoTrack(\n      int start_frame,\n      int stop_frame,\n      float confidence = -1,\n      map\nint, MPFImageLocation\n frame_locations,\n      const Properties \ndetection_properties = {})\n\n\n\n\n\n\n\n\nMembers:\n\n\n\n\n\n\n\n\nMember\n\n\nData Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nstart_frame\n\n\nint\n\n\nThe first frame number (0-based index) that contained the detected object.\n\n\n\n\n\n\nstop_frame\n\n\nint\n\n\nThe last frame number (0-based index) that contained the detected object.\n\n\n\n\n\n\nframe_locations\n\n\nmap\nint, MPFImageLocation\n\n\nA map of individual detections. The key for each map entry is the frame number where the detection was generated, and the value is a \nMPFImageLocation\n calculated as if that frame was a still image. Note that a key-value pair is \nnot\n required for every frame between the track start frame and track stop frame.\n\n\n\n\n\n\nconfidence\n\n\nfloat\n\n\nRepresents the \"quality\" of the detection. The range depends on the detection algorithm. 0.0 is lowest quality. Higher values are higher quality. Using a standard range of [0.0 - 1.0] is advised. If the component is unable to supply a confidence value, it should return -1.0.\n\n\n\n\n\n\ndetection_properties\n\n\nProperties \n\n\nOptional additional information about the detected object. There is no restriction on the keys or the number of entries that can be added to the detection_properties map. For best practice, keys should be in all CAPS.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEXAMPLE - Using detection_properties\n: A component that detects text could add an entry to the detection_properties map where the key is \nTRANSCRIPTION\n and the value is a string representing the text found in the video segment.\n\nc++\nMPFImageLocation detection;\ndetection.x_left_upper = 10;\ndetection.y_left_upper = 40;\ndetection.width = 500;\ndetection.height = 600;\ndetection.detection_properties[\"TRANSCRIPTION\"] = \"RE5ULTS FR0M A TEXT DETECTER\";\n\n\n\n\nMPFAudioTrack\n\n\nStructure used to store the location of detected objects in an audio file.\n\n\n\n\nConstructor(s):\n\n\n\n\n    MPFAudioTrack()\n    MPFAudioTrack(\n      int start_time,\n      int stop_time,\n      float confidence = -1,\n      const Properties \ndetection_properties = {})\n\n\n\n\n\n\n\n\nMembers:\n\n\n\n\n\n\n\n\nMember\n\n\nData Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nstart_time\n\n\nint\n\n\nThe time (0-based index, in ms) when the audio detection event started.\n\n\n\n\n\n\nstop_time\n\n\nint\n\n\nThe time (0-based index, in ms) when the audio detection event stopped.\n\n\n\n\n\n\nconfidence\n\n\nfloat\n\n\nRepresents the \"quality\" of the detection. The range depends on the detection algorithm. 0.0 is lowest quality. Higher values are higher quality. Using a standard range of [0.0 - 1.0] is advised. If the component is unable to supply a confidence value, it should return -1.0.\n\n\n\n\n\n\ndetection_properties\n\n\nProperties \n\n\nOptional additional information about the detection. There is no restriction on the keys or the number of entries that can be added to the detection_properties map. For best practice, keys should be in all CAPS.\n\n\n\n\n\n\n\n\n\n\n\n\nEnumeration Types\n\n\nMPFDetectionError\n\n\nEnum used to indicate the status of a \nGetDetections\n call. A component is not required to support all error types.\n\n\n\n\n\n\n\n\nENUM\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nMPF_DETECTION_SUCCESS\n\n\nThe execution of any component function has completed normally with no errors.\n\n\n\n\n\n\nMPF_OTHER_DETECTION_ERROR_TYPE\n\n\nThe component function has failed for a reason that is not captured by any of the other error codes.\n\n\n\n\n\n\nMPF_DETECTION_NOT_INITIALIZED\n\n\nThe initialization of the component, or the initialization of any of its dependencies, has failed for any reason.\n\n\n\n\n\n\nMPF_UNRECOGNIZED_DATA_TYPE\n\n\nThe media data type received by a component is not one of the values contained in the MPFDetectionDataType enum.  Note that this failure is normally caught by the component executable, before a job is passed to the component logic.\n\n\n\n\n\n\nMPF_UNSUPPORTED_DATA_TYPE\n\n\nThe job passed to a component requests processing of a job of an unsupported type. For instance, a component that is only capable of processing audio files should return this error code if a video or image job request is received.\n\n\n\n\n\n\nMPF_INVALID_DATAFILE_URI\n\n\nThe string containing the URI location of the input data file is invalid or empty.\n\n\n\n\n\n\nMPF_COULD_NOT_OPEN_DATAFILE\n\n\nThe data file to be processed could not be opened for any reason, such as a permissions failure, or an unreachable URI.\n\n\n\n\n\n\nMPF_COULD_NOT_READ_DATAFILE\n\n\nThere is a failure reading data from a successfully opened input data file.\n\n\n\n\n\n\nMPF_FILE_WRITE_ERROR\n\n\nThe component received a failure for any reason when attempting to write to a file.\n\n\n\n\n\n\nMPF_IMAGE_READ_ERROR\n\n\nThe component failed to read the image provided by the URI. For example, it might indicate the failure of a call to \nMPFImageReader::GetImage()\n, or \ncv::imread()\n.\n\n\n\n\n\n\nMPF_BAD_FRAME_SIZE\n\n\nThe frame data retrieved has an incorrect or invalid frame size. For example, if a call to \ncv::imread()\n returns a frame of data with either the number of rows or columns less than or equal to 0.\n\n\n\n\n\n\nMPF_BOUNDING_BOX_SIZE_ERROR\n\n\nThe calculation of a detection location bounding box has failed. For example, a component may be using an external library to detect objects, but the bounding box returned by that library lies partially outside the frame boundaries.\n\n\n\n\n\n\nMPF_INVALID_FRAME_INTERVAL\n\n\nAn invalid or unsupported frame interval was received.\n\n\n\n\n\n\nMPF_INVALID_START_FRAME\n\n\nThe component received an invalid start frame number. For example, if the start frame is less than zero, or greater than the stop frame, this error code should be used.\n\n\n\n\n\n\nMPF_INVALID_STOP_FRAME\n\n\nThe component receives an invalid stop frame number. For example, if the stop frame is less than the start frame, or greater than the number of the last frame in a video segment, this error code should be used.\n\n\n\n\n\n\nMPF_DETECTION_FAILED\n\n\nGeneral failure of a detection algorithm.  This does not indicate a lack of detections found in the media, but rather a break down in the algorithm that makes it impossible to continue to try to detect objects.\n\n\n\n\n\n\nMPF_DETECTION_TRACKING_FAILED\n\n\nGeneral failure of a tracking algorithm.  This does not indicate a lack of tracks generated for the media, but rather a break down in the algorithm that makes it impossible to continue to try to track objects.\n\n\n\n\n\n\nMPF_INVALID_PROPERTY\n\n\nThe component received a property that is unrecognized or has an invalid/out-of-bounds value.\n\n\n\n\n\n\nMPF_MISSING_PROPERTY\n\n\nThe component received a job that is missing a required property.\n\n\n\n\n\n\nMPF_JOB_PROPERTY_IS_NOT_INT\n\n\nA job property is supposed to be an integer type, but it is of some other type, such as a boolean or a floating point value.\n\n\n\n\n\n\nMPF_JOB_PROPERTY_IS_NOT_FLOAT\n\n\nA job property is supposed to be a floating point type, but it is of some other type, such as a boolean value.\n\n\n\n\n\n\nMPF_INVALID_ROTATION\n\n\nThe component received a job that requests rotation of the media, but the rotation value given is not in the set of acceptable values.  If the component is using the MPF::COMPONENT::FrameRotator class, the set of acceptable values is {0, 90, 180, 270}.\n\n\n\n\n\n\nMPF_MEMORY_ALLOCATION_FAILED\n\n\nThe component failed to allocate memory for any reason.\n\n\n\n\n\n\n\n\nUtility Classes\n\n\nFor convenience, the OpenMPF provides the \nMPFImageReader\n (\nsource\n) and \nMPFVideoCapture\n (\nsource\n) utility classes to perform horizontal flipping, rotation, and cropping to a region of interest. Note, that when using these classes, the component will also need to utilize the class to perform a reverse transform to convert the transformed pixel coordinates back to the original (e.g. pre-flipped, pre-rotated, and pre-cropped) coordinate space.\n\n\nC++ Component Build Environment\n\n\nA C++ component library must be built for the same C++ compiler and Linux version that is used by the OpenMPF Component Executable. This is to ensure compatibility between the executable and the library functions at the Application Binary Interface (ABI) level. At this writing, the OpenMPF runs on CentOS 7.2-1511 (kernel version 3.10.0-327), and the OpenMPF C++ component executable is built with g++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-4).\n\n\nComponents should be supplied as a tar file, which includes not only the component library, but any other libraries or files needed for execution. This includes all other non-standard libraries used by the component (aside from the standard Linux and C++ libraries), and any configuration or data files.\n\n\nComponent Development Best Practices\n\n\nSingle-threaded Operation\n\n\nImplementations are encouraged to operate in single-threaded mode. OpenMPF will parallelize components through multiple instantiations of the component, each running as a separate service.\n\n\nStateless Behavior\n\n\nOpenMPF components should be stateless in operation and give identical output for a provided input (i.e. when processing the same \nMPFJob\n).\n\n\nComponent Packaging\n\n\nIt is recommended that C++ components are organized according to the following directory structure:\n\n\ncomponentName\n\u251c\u2500\u2500 config - Logging and other component-specific configuration\n\u251c\u2500\u2500 descriptor\n\u2502   \u2514\u2500\u2500 descriptor.json\n\u2514\u2500\u2500 lib\n    \u2514\u2500\u2500libComponentName.so - Compiled component library\n\n\n\n\nOnce built, components should be packaged into a .tar.gz containing the contents of the directory shown above.\n\n\nLogging\n\n\nIt is recommended to use \nApache log4cxx\n for OpenMPF Component logging.\n\n\nNote that multiple instances of the same component can log to the same file. Also, logging content can span multiple lines.\n\n\nLog files should be output to:\n\n${MPF_LOG_PATH}/${THIS_MPF_NODE}/log/\ncomponentName\n.log\n\n\nEach log statement must take the form:\n\nDATE TIME LEVEL CONTENT\n\n\nThe following log LEVELs are supported:\n\nFATAL, ERROR, WARN,  INFO,  DEBUG, TRACE\n.\n\n\nFor example:\n\n2016-02-09 13:42:42,341 INFO - Starting sample-component: [  OK  ]\n\n\nThe following configuration can be used to match the format of other OpenMPF logs:\n\n\nlog4j:configuration xmlns:log4j=\nhttp://jakarta.apache.org/log4j/\n\n\n  \n!-- Output the log message to log file--\n\n  \nappender name=\nSAMPLECOMPONENT-FILE\n class=\norg.apache.log4j.DailyRollingFileAppender\n\n    \nparam name=\nfile\n value=\n${MPF_LOG_PATH}/${THIS_MPF_NODE}/log/\ncomponentName\n.log\n /\n\n    \nparam name=\nDatePattern\n value=\n'.'yyyy-MM-dd\n /\n\n    \nlayout class=\norg.apache.log4j.PatternLayout\n\n      \nparam name=\nConversionPattern\n value=\n%d %p [%t] %c{36}:%L - %m%n\n /\n\n    \n/layout\n\n  \n/appender\n\n\n  \nlogger name= \nSampleComponent\n additivity=\nfalse\n\n    \nlevel value=\nINFO\n/\n\n    \nappender-ref ref=\nSAMPLECOMPONENT-FILE\n/\n\n  \n/logger\n\n\n\n/log4j:configuration", 
            "title": "C++ Component API"
        }, 
        {
            "location": "/CPP-Component-API/#c-component-api-overview", 
            "text": "In OpenMPF, a  component  is a plugin that receives jobs (containing media), processes that  media, and returns results.  The OpenMPF Component API currently supports the development of  detection components , which are used detect objects in image, video, or audio files.  Using this API, detection components can be built to provide:   Detection (Localizing an object)  Tracking (Localizing an object across multiple frames)  Classification (Detecting the type of object and optionally localizing that object)  Transcription (Detecting speech and transcribing it into text)", 
            "title": "C++ Component API Overview"
        }, 
        {
            "location": "/CPP-Component-API/#how-components-integrate-into-openmpf", 
            "text": "Components are integrated into OpenMPF through the use of OpenMPF's  Component Executable . Developers create component libraries that encapsulate the component detection logic. Each instance of the Component Executable loads one these libraries and uses it to service job requests sent by the OpenMPF Workflow Manager (WFM).  The Component Executable:   Receives and parses job requests from the WFM  Invokes functions on the component library to obtain detection results  Populates and sends the respective responses to the WFM   The basic psuedocode for the Component Executable is as follows:  component- SetRunDirectory(...)\ncomponent- Init()\nwhile (true) {\n  job = ReceiveJob()\n  if (component- Supports(job.data_type))\n    component- GetDetections(...) // Component logic does the work here\n  SendJobResponse()\n}\ncomponent- Close()  Each instance of a Component Executable runs as a separate process.  The Component Executable receives and parses requests from the WFM, invokes functions on the Component Logic to get detection objects, and subsequently populates responses with the component output and sends them to the WFM.  A component developer implements a detection component by extending  MPFDetectionComponent .  As an alternative to extending  MPFDetectionComponent  directly, a developer may extend one of several convenience adapter classes provided by OpenMPF. See  Convenience Adapters  for more information.", 
            "title": "How Components Integrate into OpenMPF"
        }, 
        {
            "location": "/CPP-Component-API/#getting-started", 
            "text": "The quickest way to get started with the OpenMPF Component API is to first read the  OpenMPF Component API Overview  and then  review the source  for example OpenMPF C++ detection components.  Detection components are implemented by:   Extending  MPFDetectionComponent .  Building the component into a shared object library. (See  HelloWorldComponent CMakeLists.txt ).  Packaging the component into an OpenMPF-compliant .tar.gz file. (See  Component Packaging ).  Registering the component with OpenMPF (see  Packaging and Registering a Component ).", 
            "title": "Getting Started"
        }, 
        {
            "location": "/CPP-Component-API/#openmpf-api-specification", 
            "text": "The figure below presents a high-level component diagram of the OpenMPF API:   The API consists of  Component Interfaces , which provide interfaces and abstract classes for developing components;  Job Definitions , which define the work to be performed by a component;  Job Results , which define the results generated by the component;  Component Adapters , which provide default implementations of several of the  MPFDetectionComponent  interface; and  Component Utilities , which perform actions such as image rotation, and cropping.  Component Interface   MPFComponent  - Abstract base class for components.   Detection Component Interface   MPFDetectionComponent  extends  MPFComponent  - Abstract class that should be extended by all OpenMPF detection components.   Job Definitions  The following data structures contain details about a specific job (work unit):   MPFImageJob  extends  MPFJob  MPFVideoJob  extends  MPFJob  MPFAudioJob  extends  MPFJob   Job Results  The following classes define the results of a component's processing:   MPFImageLocation  MPFVideoTrack  MPFAudioTrack   Components must also include two  Component Factory Functions .", 
            "title": "OpenMPF API Specification"
        }, 
        {
            "location": "/CPP-Component-API/#openmpf-component-api", 
            "text": "The  MPFComponent  class is the abstract base class utilized by all OpenMPF components.  See the latest source here.   IMPORTANT:  This interface should not be directly implemented, because no mechanism exists for launching components based off of it. Currently, the only supported type of component is detection, and all components should instead extend  MPFDetectionComponent .", 
            "title": "OpenMPF Component API"
        }, 
        {
            "location": "/CPP-Component-API/#init", 
            "text": "The component should perform all initialization operations in the  Init  member function. Init  will be called once by the OpenMPF Component Executable before any other member functions.   Function Definition: bool Init()  Parameters: none  Returns: (bool) Return true if initialization is successful, otherwise return false.  Example:   bool SampleComponent::Init() {\n  // Get component paths\n  string run_dir = GetRunDirectory();\n  string plugin_path = run_dir +  /SampleComponent ;\n  string config_path = plugin_path +  /config ;\n\n  // Setup logger, load data models, etc.\n\n  return true;\n}", 
            "title": "Init()"
        }, 
        {
            "location": "/CPP-Component-API/#close", 
            "text": "The component should perform all shutdown operations in the  Close  member function. Close  will be called once by the OpenMPF Component Executable prior to component shutdown.  This method is called before the component instance is deleted (see  Component Factory Functions ).   Function Definition: bool Close()  Parameters: none  Returns: (bool) Return true if successful, otherwise return false.  Example:       bool SampleComponent::Close() {\n        // Free memory, etc.\n        return true;\n    }", 
            "title": "Close()"
        }, 
        {
            "location": "/CPP-Component-API/#getcomponenttype", 
            "text": "The GetComponentType() member function allows the OpenMPF Component API to determine the component \"type.\" Currently  MPF_DETECTION_COMPONENT  is the only supported component type. APIs for other component types may be developed in the future.   Function Definition: MPFComponentType GetComponentType()  Parameters: none  Returns: (MPFComponentType) Currently,  MPF_DETECTION_COMPONENT  is the only supported return value.  Example:       MPFComponentType SampleComponent::GetComponentType() {\n        return MPF_DETECTION_COMPONENT;\n    };", 
            "title": "GetComponentType()"
        }, 
        {
            "location": "/CPP-Component-API/#getrundirectory", 
            "text": "Returns the value of the private  run_directory  data member which contains the full path of the parent folder above where the component is installed. This parent folder is also known as the plugin folder.   Function Definition: string GetRunDirectory()  Parameters: none  Returns: (string) Full path of the parent folder above where the component is installed.  Sample Usage:       string run_dir = GetRunDirectory();\n    string plugin_path = run_dir +  /SampleComponent ;\n    string config_path = plugin_path +  /config ;\n    string logconfig_file = config_path +  /Log4cxxConfig.xml ;", 
            "title": "GetRunDirectory()"
        }, 
        {
            "location": "/CPP-Component-API/#setrundirectorystring", 
            "text": "Sets the value of the private  run_directory  data member which contains the full path of the parent folder above where the component is installed.   Function Definition: void SetRunDirectory(const string  run_dir)   Parameters:     Parameter  Data Type  Description      run_dir  const string   Full path of the parent folder above where the component is installed.       Returns: void     IMPORTANT:   SetRunDirectory  is called by the Component Executable to set the correct path. This function should not be called within your implementation.", 
            "title": "SetRunDirectory(string)"
        }, 
        {
            "location": "/CPP-Component-API/#component-factory-functions", 
            "text": "Every detection component must include the following macros in its implementation:  MPF_COMPONENT_CREATOR(TYPENAME);  MPF_COMPONENT_DELETER();  The creator macro takes the  TYPENAME  of the detection component (for example, \u201cHelloWorldComponent\u201d). This macro creates the factory function that the OpenMPF Component Executable will call in order to instantiate the detection component. The creation function is called once, to obtain an instance of the component, after the component library has been loaded into memory.  The deleter macro creates the factory function that the Component Executable will use to delete that instance of the detection component. These macros must be used outside of a class declaration, preferably at the bottom or top of a component header file.  Example:  // Note: Do not put the TypeName/Class Name in quotes\nMPF_COMPONENT_CREATOR(ComponentNameHere);\nMPF_COMPONENT_DELETER();", 
            "title": "Component Factory Functions"
        }, 
        {
            "location": "/CPP-Component-API/#openmpf-detection-component-api", 
            "text": "The  MPFDetectionComponent  class is the abstract class utilized by all OpenMPF detection components. This class provides functions for developers to integrate detection logic into OpenMPF.  See the latest source here.   IMPORTANT:  Each detection component must implement all of the  GetDetections()  functions or extend from a superclass which provides implementations for them (see  convenience adapters ).  If your component does not support a particular data type, it should simply: return MPF_UNSUPPORTED_DATA_TYPE;", 
            "title": "OpenMPF Detection Component API"
        }, 
        {
            "location": "/CPP-Component-API/#convenience-adapters", 
            "text": "As an alternative to extending  MPFDetectionComponent  directly, developers may extend one of several convenience adapter classes provided by OpenMPF.  These adapters provide default implementations of several methods in  MPFDetectionComponent  and ensure that the component's logic properly extends from the Component API. This enables developers to concentrate on implementation of the detection algorithm.  The following adapters are provided:   Image Detection ( source )  Video Detection ( source )  Image and Video Detection ( source )  Audio Detection ( source )  Audio and Video Detection ( source )    Example: Creating Adaptors to Perform Naive Tracking: \nA simple detector that operates on videos may simply go through the video frame-by-frame, extract each frame\u2019s data, and perform detections on that data as though it were processing a new unrelated image each time. As each frame is processed, one or more  MPFImageLocations  are generated.  Generally, it is preferred that a detection component that supports  VIDEO  data is able to perform tracking across video frames to appropriately correlate  MPFImageLocation  detections across frames.  An adapter could be developed to perform simple tracking. This would correlate  MPFImageLocation  detections across frames by na\u00efvely looking for bounding box regions in each contiguous frame that overlap by a given threshold such as 50%.", 
            "title": "Convenience Adapters"
        }, 
        {
            "location": "/CPP-Component-API/#detection-component-interface", 
            "text": "", 
            "title": "Detection Component Interface"
        }, 
        {
            "location": "/CPP-Component-API/#supportsmpfdetectiondatatype", 
            "text": "Returns true or false depending on the data type is supported or not.   Function Definition: bool Supports(MPFDetectionDataType data_type)   Parameters:     Parameter  Data Type  Description      data_type  MPFDetectionDataType  Component should only return true for IMAGE, VIDEO, and/or AUDIO.       Returns: (bool) True if the component supports the data type, otherwise false.   Example:       // Sample component that supports only image and video files\n    bool SampleComponent::Supports(MPFDetectionDataType data_type) {\n        return data_type == MPFDetectionDataType::IMAGE || data_type == MPFDetectionDataType::VIDEO;\n    }", 
            "title": "Supports(MPFDetectionDataType)"
        }, 
        {
            "location": "/CPP-Component-API/#getdetectiontype", 
            "text": "Returns the type of object detected by the component.   Function Definition: string GetDetectionType()   Parameters: None    Returns: (string) The type of object detected by the component. Should be in all CAPS. Examples include:  FACE ,  MOTION ,  PERSON ,  SPEECH ,  CLASS  (for object classification), or  TEXT .   Example:       string SampleComponent::GetDetectionType() {\n        return  FACE ;\n    }", 
            "title": "GetDetectionType()"
        }, 
        {
            "location": "/CPP-Component-API/#getdetectionsmpfimagejob", 
            "text": "Used to detect objects in an image file. The MPFImageJob structure contains the data_uri specifying the location of the image file.  Currently, the data_uri is always a local file path. For example, \"/opt/mpf/share/remote-media/test-file.jpg\". This is because all media is copied to the OpenMPF server before the job is executed.   Function Definition:       MPFDetectionError GetDetections(const MPFImageJob  job, vector MPFImageLocation   locations)    Parameters:     Parameter  Data Type  Description      job  const MPFImageJob   Structure containing details about the work to be performed. See  MPFImageJob    locations  vector MPFImageLocation    The  MPFImageLocation  data for each detected object.       Returns:  MPFDetectionError   Example:       MPFDetectionError SampleComponent::GetDetections(const MPFImageJob  job, vector MPFImageLocation   locations) {\n        // Parse job\n        // Generate image locations\n        return MPF_DETECTION_SUCCESS;\n    }", 
            "title": "GetDetections(MPFImageJob \u2026)"
        }, 
        {
            "location": "/CPP-Component-API/#getdetectionsmpfvideojob", 
            "text": "Used to detect objects in a video file. Prior to being sent to the component, videos are split into logical \"segments\" of video data and each segment (containing a range of frames) is assigned to a different job. Components are not guaranteed to receive requests in any order. For example, the first request processed by a component might receive a request for frames 300-399 of a Video A, while the next request may cover frames 900-999 of a Video B.   Function Definition:       MPFDetectionError getDetections(const MPFVideoJob  job, vector MPFVideoTrack  tracks);    Parameters:     Parameter  Data Type  Description      job  const MPFVideoJob   Structure containing details about the work to be performed. See  MPFVideoJob    tracks  vector MPFVideoTrack    The  MPFVideoTrack  data for each detected object.       Returns:  MPFDetectionError   Example:       MPFDetectionError SampleComponent::GetDetections(const MPFAudioJob  job, vector MPFAudioTrack   tracks) {\n        // Parse job\n        // Generate tracks\n        return MPF_DETECTION_SUCCESS;\n    }", 
            "title": "GetDetections(MPFVideoJob \u2026)"
        }, 
        {
            "location": "/CPP-Component-API/#getdetectionsmpfaudiojob", 
            "text": "Used to detect objects in an audio file. Currently, audio files are not logically segmented, so a job will contain the entirety of the audio file.   Function Definition:       MPFDetectionError GetDetections(const MPFAudioJob  job, vector MPFAudioTrack   tracks)    Parameters:     Parameter  Data Type  Description      job  const MPFAudioJob   Structure containing details about the work to be performed. See  MPFAudioJob    tracks  vector MPFAudioTrack    The  MPFAudioTrack  data for each detected object       Returns:  MPFDetectionError   Example:       MPFDetectionError GetDetections(const MPFAudioJob  job, vector MPFAudioTrack   tracks) {\n        // Parse job\n        // Generate tracks\n        return MPF_DETECTION_SUCCESS;\n    }", 
            "title": "GetDetections(MPFAudioJob \u2026)"
        }, 
        {
            "location": "/CPP-Component-API/#detection-job-data-structures", 
            "text": "The  MPFDetectionComponent  data structures contain details about a specific job (work unit):   MPFImageJob  extends  MPFJob  MPFVideoJob  extends  MPFJob  MPFAudioJob  extends  MPFJob   The following data structures contain details about detection results:   MPFImageLocation  MPFVideoTrack  MPFAudioTrack", 
            "title": "Detection Job Data Structures"
        }, 
        {
            "location": "/CPP-Component-API/#mpfjob", 
            "text": "Structure containing information about about a job to be performed on a piece of media.   Constructor(s):       MPFJob(\n      const string  job_name,\n      const string  data_uri,\n      const Properties  job_properties,\n      const Properties  media_properties)    Members:     Member  Data Type  Description      job_name   const string    A specific name given to the job by the OpenMPF framework. This value may be used, for example, for logging and debugging purposes.    data_uri   const string    The URI of the input media file to be processed. Currently, this is a file path. For example, \"/opt/mpf/share/remote-media/test-file.avi\".    job_properties   const Properties   Contains a map of  string, string  which represents the property name and the property value. The key corresponds to the property name specified in the component descriptor file described in  Packaging and Registering a Component . Values are determined when creating a pipeline or when submitting a job.   Note: The job_properties map may not contain the full set of job properties. For properties not contained in the map, the component must use a default value.    media_properties   const Properties   Contains a map of  string, string  of metadata about the media associated with the job. The entries in the map vary depending on the type of media. Refer to the type-specific job structures below.", 
            "title": "MPFJob"
        }, 
        {
            "location": "/CPP-Component-API/#mpfimagejob", 
            "text": "Extends  MPFJob  Structure containing data used for detection of objects in an image file.   Constructor(s):       MPFImageJob(\n        const string  job_name,\n        const string  data_uri,\n        const Properties  job_properties,\n        const Properties  media_properties)    Members:     Member  Data Type  Description      job_name  const string   See  MPFJob.job_name  for description.    data_uri  const string   See  MPFJob.data_uri  for description.    job_properties  const Properties   See  MPFJob.job_properties  for description.    media_properties  const Properties   See  MPFJob.media_properties  for description. This may include the following key-value pairs: ROTATION  : 0, 90, 180, or 270 degrees HORIZONTAL_FLIP  : true if the image is mirrored across the Y-axis, otherwise false EXIF_ORIENTATION  : the standard EXIF orientation tag; a value between 1 and 8", 
            "title": "MPFImageJob"
        }, 
        {
            "location": "/CPP-Component-API/#mpfvideojob", 
            "text": "Extends  MPFJob  Structure containing data used for detection of objects in a video file.   Constructor(s):       MPFVideoJob(\n      const string  job_name,\n      const string  data_uri,\n      int start_frame,\n      int stop_frame,\n      const Properties  job_properties,\n      const Properties  media_properties)    Members:     Member  Data Type  Description      job_name  const string   See  MPFJob.job_name  for description.    data_uri  const string   See  MPFJob.data_uri  for description.    start_frame  const int  The first frame number (0-based index) of the video that should be processed to look for detections.    stop_frame  const int  The last frame number (0-based index) of the video that should be processed to look for detections.    job_properties  const Properties   See  MPFJob.job_properties  for description.    media_properties  const Properties   See  MPFJob.media_properties  for description.   Includes the following key-value pairs: DURATION  : length of video in milliseconds FPS  : frames per second (averaged for variable frame rate video)        IMPORTANT:  For frame intervals greater than 1, the component must look for detections starting with the first frame, and then skip frames as specified by the frame interval, until or before it reaches the stop frame. For example, given a start frame of 0, a stop frame of 99, and a frame interval of 2, then the detection component must look for objects in frames numbered 0, 2, 4, 6, ..., 98.", 
            "title": "MPFVideoJob"
        }, 
        {
            "location": "/CPP-Component-API/#mpfaudiojob", 
            "text": "Extends  MPFJob  Structure containing data used for detection of objects in an audio file. Currently, audio files are not logically segmented, so a job will contain the entirety of the audio file.   Constructor(s):       MPFAudioJob(\n      const string  job_name,\n      const string  data_uri,\n      int start_time,\n      int stop_time,\n      const Properties  job_properties,\n      const Properties  media_properties)    Members:     Member  Data Type  Description      job_name  const string   See  MPFJob.job_name  for description.    data_uri  const string   See  MPFJob.data_uri  for description.    start_time  const int  The time (0-based index, in milliseconds) associated with the beginning of the segment of the audio file that should be processed to look for detections.    stop_time  const int  The time (0-based index, in milliseconds) associated with the end of the segment of the audio file that should be processed to look for detections.    job_properties  const Properties   See  MPFJob.job_properties  for description.    media_properties  const Properties   See  MPFJob.media_properties  for description.   Includes the following key-value pair: DURATION  : length of audio file in milliseconds", 
            "title": "MPFAudioJob"
        }, 
        {
            "location": "/CPP-Component-API/#detection-job-result-classes", 
            "text": "", 
            "title": "Detection Job Result Classes"
        }, 
        {
            "location": "/CPP-Component-API/#mpfimagelocation", 
            "text": "Structure used to store the location of detected objects in a image file.   Constructor(s):       MPFImageLocation()\n    MPFImageLocation(\n      int x_left_upper,\n      int y_left_upper,\n      int width,\n      int height,\n      float confidence = -1,\n      const Properties  detection_properties = {})    Members:     Member  Data Type  Description      x_left_upper  int  Upper left X coordinate of the detected object.    y_left_upper  int  Upper left Y coordinate of the detected object.    width  int  The width of the detected object. If the detection consists of the entire image, use 0.    height  int  The height of the detected object. If the detection consists of the entire image, use 0.    confidence  float  Represents the \"quality\" of the detection. The range depends on the detection algorithm. 0.0 is lowest quality. Higher values are higher quality. Using a standard range of [0.0 - 1.0] is advised. If the component is unable to supply a confidence value, it should return -1.0.    detection_properties  Properties   Optional additional information about the detected object. There is no restriction on the keys or the number of entries that can be added to the detection_properties map. For best practice, keys should be in all CAPS.        EXAMPLE - Using detection_properties : A component that performs generic object classification could add an entry to the detection_properties which corresponds to the type of object detected.  Source:   MPFImageLocation detection;\ndetection.x_left_upper = 0;\ndetection.y_left_upper = 0;\ndetection.width = 0;\ndetection.height = 0;\ndetection.confidence = probability;\ndetection.detection_properties[ CLASSIFICATION ] =  backpack ;", 
            "title": "MPFImageLocation"
        }, 
        {
            "location": "/CPP-Component-API/#mpfvideotrack", 
            "text": "Structure used to store the location of detected objects in a video file.   Constructor:       MPFVideoTrack()\n    MPFVideoTrack(\n      int start_frame,\n      int stop_frame,\n      float confidence = -1,\n      map int, MPFImageLocation  frame_locations,\n      const Properties  detection_properties = {})    Members:     Member  Data Type  Description      start_frame  int  The first frame number (0-based index) that contained the detected object.    stop_frame  int  The last frame number (0-based index) that contained the detected object.    frame_locations  map int, MPFImageLocation  A map of individual detections. The key for each map entry is the frame number where the detection was generated, and the value is a  MPFImageLocation  calculated as if that frame was a still image. Note that a key-value pair is  not  required for every frame between the track start frame and track stop frame.    confidence  float  Represents the \"quality\" of the detection. The range depends on the detection algorithm. 0.0 is lowest quality. Higher values are higher quality. Using a standard range of [0.0 - 1.0] is advised. If the component is unable to supply a confidence value, it should return -1.0.    detection_properties  Properties   Optional additional information about the detected object. There is no restriction on the keys or the number of entries that can be added to the detection_properties map. For best practice, keys should be in all CAPS.        EXAMPLE - Using detection_properties : A component that detects text could add an entry to the detection_properties map where the key is  TRANSCRIPTION  and the value is a string representing the text found in the video segment. c++\nMPFImageLocation detection;\ndetection.x_left_upper = 10;\ndetection.y_left_upper = 40;\ndetection.width = 500;\ndetection.height = 600;\ndetection.detection_properties[\"TRANSCRIPTION\"] = \"RE5ULTS FR0M A TEXT DETECTER\";", 
            "title": "MPFVideoTrack"
        }, 
        {
            "location": "/CPP-Component-API/#mpfaudiotrack", 
            "text": "Structure used to store the location of detected objects in an audio file.   Constructor(s):       MPFAudioTrack()\n    MPFAudioTrack(\n      int start_time,\n      int stop_time,\n      float confidence = -1,\n      const Properties  detection_properties = {})    Members:     Member  Data Type  Description      start_time  int  The time (0-based index, in ms) when the audio detection event started.    stop_time  int  The time (0-based index, in ms) when the audio detection event stopped.    confidence  float  Represents the \"quality\" of the detection. The range depends on the detection algorithm. 0.0 is lowest quality. Higher values are higher quality. Using a standard range of [0.0 - 1.0] is advised. If the component is unable to supply a confidence value, it should return -1.0.    detection_properties  Properties   Optional additional information about the detection. There is no restriction on the keys or the number of entries that can be added to the detection_properties map. For best practice, keys should be in all CAPS.", 
            "title": "MPFAudioTrack"
        }, 
        {
            "location": "/CPP-Component-API/#enumeration-types", 
            "text": "", 
            "title": "Enumeration Types"
        }, 
        {
            "location": "/CPP-Component-API/#mpfdetectionerror", 
            "text": "Enum used to indicate the status of a  GetDetections  call. A component is not required to support all error types.     ENUM  Description      MPF_DETECTION_SUCCESS  The execution of any component function has completed normally with no errors.    MPF_OTHER_DETECTION_ERROR_TYPE  The component function has failed for a reason that is not captured by any of the other error codes.    MPF_DETECTION_NOT_INITIALIZED  The initialization of the component, or the initialization of any of its dependencies, has failed for any reason.    MPF_UNRECOGNIZED_DATA_TYPE  The media data type received by a component is not one of the values contained in the MPFDetectionDataType enum.  Note that this failure is normally caught by the component executable, before a job is passed to the component logic.    MPF_UNSUPPORTED_DATA_TYPE  The job passed to a component requests processing of a job of an unsupported type. For instance, a component that is only capable of processing audio files should return this error code if a video or image job request is received.    MPF_INVALID_DATAFILE_URI  The string containing the URI location of the input data file is invalid or empty.    MPF_COULD_NOT_OPEN_DATAFILE  The data file to be processed could not be opened for any reason, such as a permissions failure, or an unreachable URI.    MPF_COULD_NOT_READ_DATAFILE  There is a failure reading data from a successfully opened input data file.    MPF_FILE_WRITE_ERROR  The component received a failure for any reason when attempting to write to a file.    MPF_IMAGE_READ_ERROR  The component failed to read the image provided by the URI. For example, it might indicate the failure of a call to  MPFImageReader::GetImage() , or  cv::imread() .    MPF_BAD_FRAME_SIZE  The frame data retrieved has an incorrect or invalid frame size. For example, if a call to  cv::imread()  returns a frame of data with either the number of rows or columns less than or equal to 0.    MPF_BOUNDING_BOX_SIZE_ERROR  The calculation of a detection location bounding box has failed. For example, a component may be using an external library to detect objects, but the bounding box returned by that library lies partially outside the frame boundaries.    MPF_INVALID_FRAME_INTERVAL  An invalid or unsupported frame interval was received.    MPF_INVALID_START_FRAME  The component received an invalid start frame number. For example, if the start frame is less than zero, or greater than the stop frame, this error code should be used.    MPF_INVALID_STOP_FRAME  The component receives an invalid stop frame number. For example, if the stop frame is less than the start frame, or greater than the number of the last frame in a video segment, this error code should be used.    MPF_DETECTION_FAILED  General failure of a detection algorithm.  This does not indicate a lack of detections found in the media, but rather a break down in the algorithm that makes it impossible to continue to try to detect objects.    MPF_DETECTION_TRACKING_FAILED  General failure of a tracking algorithm.  This does not indicate a lack of tracks generated for the media, but rather a break down in the algorithm that makes it impossible to continue to try to track objects.    MPF_INVALID_PROPERTY  The component received a property that is unrecognized or has an invalid/out-of-bounds value.    MPF_MISSING_PROPERTY  The component received a job that is missing a required property.    MPF_JOB_PROPERTY_IS_NOT_INT  A job property is supposed to be an integer type, but it is of some other type, such as a boolean or a floating point value.    MPF_JOB_PROPERTY_IS_NOT_FLOAT  A job property is supposed to be a floating point type, but it is of some other type, such as a boolean value.    MPF_INVALID_ROTATION  The component received a job that requests rotation of the media, but the rotation value given is not in the set of acceptable values.  If the component is using the MPF::COMPONENT::FrameRotator class, the set of acceptable values is {0, 90, 180, 270}.    MPF_MEMORY_ALLOCATION_FAILED  The component failed to allocate memory for any reason.", 
            "title": "MPFDetectionError"
        }, 
        {
            "location": "/CPP-Component-API/#utility-classes", 
            "text": "For convenience, the OpenMPF provides the  MPFImageReader  ( source ) and  MPFVideoCapture  ( source ) utility classes to perform horizontal flipping, rotation, and cropping to a region of interest. Note, that when using these classes, the component will also need to utilize the class to perform a reverse transform to convert the transformed pixel coordinates back to the original (e.g. pre-flipped, pre-rotated, and pre-cropped) coordinate space.", 
            "title": "Utility Classes"
        }, 
        {
            "location": "/CPP-Component-API/#c-component-build-environment", 
            "text": "A C++ component library must be built for the same C++ compiler and Linux version that is used by the OpenMPF Component Executable. This is to ensure compatibility between the executable and the library functions at the Application Binary Interface (ABI) level. At this writing, the OpenMPF runs on CentOS 7.2-1511 (kernel version 3.10.0-327), and the OpenMPF C++ component executable is built with g++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-4).  Components should be supplied as a tar file, which includes not only the component library, but any other libraries or files needed for execution. This includes all other non-standard libraries used by the component (aside from the standard Linux and C++ libraries), and any configuration or data files.", 
            "title": "C++ Component Build Environment"
        }, 
        {
            "location": "/CPP-Component-API/#component-development-best-practices", 
            "text": "", 
            "title": "Component Development Best Practices"
        }, 
        {
            "location": "/CPP-Component-API/#single-threaded-operation", 
            "text": "Implementations are encouraged to operate in single-threaded mode. OpenMPF will parallelize components through multiple instantiations of the component, each running as a separate service.", 
            "title": "Single-threaded Operation"
        }, 
        {
            "location": "/CPP-Component-API/#stateless-behavior", 
            "text": "OpenMPF components should be stateless in operation and give identical output for a provided input (i.e. when processing the same  MPFJob ).", 
            "title": "Stateless Behavior"
        }, 
        {
            "location": "/CPP-Component-API/#component-packaging", 
            "text": "It is recommended that C++ components are organized according to the following directory structure:  componentName\n\u251c\u2500\u2500 config - Logging and other component-specific configuration\n\u251c\u2500\u2500 descriptor\n\u2502   \u2514\u2500\u2500 descriptor.json\n\u2514\u2500\u2500 lib\n    \u2514\u2500\u2500libComponentName.so - Compiled component library  Once built, components should be packaged into a .tar.gz containing the contents of the directory shown above.", 
            "title": "Component Packaging"
        }, 
        {
            "location": "/CPP-Component-API/#logging", 
            "text": "It is recommended to use  Apache log4cxx  for OpenMPF Component logging.  Note that multiple instances of the same component can log to the same file. Also, logging content can span multiple lines.  Log files should be output to: ${MPF_LOG_PATH}/${THIS_MPF_NODE}/log/ componentName .log  Each log statement must take the form: DATE TIME LEVEL CONTENT  The following log LEVELs are supported: FATAL, ERROR, WARN,  INFO,  DEBUG, TRACE .  For example: 2016-02-09 13:42:42,341 INFO - Starting sample-component: [  OK  ]  The following configuration can be used to match the format of other OpenMPF logs:  log4j:configuration xmlns:log4j= http://jakarta.apache.org/log4j/ \n\n   !-- Output the log message to log file-- \n   appender name= SAMPLECOMPONENT-FILE  class= org.apache.log4j.DailyRollingFileAppender \n     param name= file  value= ${MPF_LOG_PATH}/${THIS_MPF_NODE}/log/ componentName .log  / \n     param name= DatePattern  value= '.'yyyy-MM-dd  / \n     layout class= org.apache.log4j.PatternLayout \n       param name= ConversionPattern  value= %d %p [%t] %c{36}:%L - %m%n  / \n     /layout \n   /appender \n\n   logger name=  SampleComponent  additivity= false \n     level value= INFO / \n     appender-ref ref= SAMPLECOMPONENT-FILE / \n   /logger  /log4j:configuration", 
            "title": "Logging"
        }, 
        {
            "location": "/Java-Component-API/", 
            "text": "NOTICE:\n This software (or technical data) was produced for the U.S. Government under contract, and is subject to the Rights in Data-General Clause 52.227-14, Alt. IV (DEC 2007). Copyright 2017 The MITRE Corporation. All Rights Reserved.\n\n\n\n\nJava Component API Overview\n\n\nIn OpenMPF, a \ncomponent\n is a plugin that receives jobs (containing media), processes that  media, and returns results.\n\n\nThe OpenMPF Component API currently supports the development of \ndetection components\n, which are used detect objects in image, video, or audio files.\n\n\nUsing this API, detection components can be built to provide:\n\n\n\n\nDetection (Localizing an object)\n\n\nTracking (Localizing an object across multiple frames)\n\n\nClassification (Detecting the type of object and optionally localizing that object)\n\n\nTranscription (Detecting speech and transcribing it into text)\n\n\n\n\nHow Components Integrate into OpenMPF\n\n\nComponents are integrated into OpenMPF through the use of OpenMPF's \nComponent Executor\n. Developers create component libraries that encapsulate the component detection logic. Each instance of the Component Executor loads one of these libraries and uses it to service job requests sent by the OpenMPF Workflow Manager (WFM).\n\n\nThe Component Executor:\n\n\n\n\nReceives and parses job requests from the WFM\n\n\nInvokes methods on the component library to obtain detection results\n\n\nPopulates and sends the respective responses to the WFM\n\n\n\n\nThe basic psuedocode for the Component Executor is as follows:\n\n\ncomponent.setRunDirectory(...)\ncomponent.init()\nwhile (true) {\n  job = ReceiveJob()\n  if (component.supports(job.dataType))\n    component.getDetections(...) // Component does the work here\n}\ncomponent.close()\n\n\n\n\nEach instance of a Component Executor runs as a separate process.\n\n\nThe Component Executor receives and parses requests from the WFM, invokes methods on the Component Logic to get detection objects, and subsequently populates responses with the component output and sends them to the WFM.\n\n\nA component developer implements a detection component by extending \nMPFDetectionComponentBase\n.\n\n\nAs an alternative to extending \nMPFDetectionComponentBase\n directly, a developer may extend one of several convenience adapter classes provided by OpenMPF. See \nConvenience Adapters\n for more information.\n\n\nGetting Started\n\n\nThe quickest way to get started with the OpenMPF Component API is to first read the \nOpenMPF Component API Overview\n. Example components are currently in development. These examples will provide a template for getting started.\n\n\nDetection components are implemented by:\n\n\n\n\nExtending \nMPFDetectionComponentBase\n.\n\n\nBuilding the component into a jar. (TODO: reference example).\n\n\nPackaging the component into an OpenMPF-compliant .tar.gz file. (See \nComponent Packaging\n).\n\n\nRegistering the component with OpenMPF (see \nPackaging and Registering a Component\n).\n\n\n\n\nOpenMPF API Specification\n\n\nThe figure below presents a high-level component diagram of the OpenMPF API:\n\n\n\n\nThe API consists of \nComponent Interfaces\n, which provide interfaces and abstract classes for developing components; \nJob Definitions\n, which define the work to be performed by a component; and \nJob Results\n, which define the results generated by the component; and \nComponent Adapters\n, which provide default implementations of several of the \nMPFDetectionComponentInterface\n methods (examples shown; TODO: implement these). In the future, the API will also include \nComponent Utilities\n, which perform actions such as image flipping, rotation, and cropping.\n\n\nComponent Interfaces\n\n\n\n\nMPFComponentInterface\n - Baseline interface for all potential components.\n\n\nMPFComponentBase\n - An abstract baseline for components. Provides default implementations for \nMPFComponentInterface\n.\n\n\n\n\nDetection Component Interfaces\n\n\n\n\nMPFDetectionComponentInterface\n - Baseline interface for detection components.\n\n\nMPFDetectionComponentBase\n - An abstract baseline for detection components. Provides default implementations for  \nMPFDetectionComponentInterface\n.\n\n\n\n\nJob Definitions\n\n\nThe following classes define the details about a specific job (work unit):\n\n\n\n\nMPFImageJob\n extends \nMPFJob\n\n\nMPFVideoJob\n extends \nMPFJob\n\n\nMPFAudioJob\n extends \nMPFJob\n\n\n\n\nJob Results\n\n\nThe following classes define the results of a component's processing:\n\n\n\n\nMPFImageLocation\n\n\nMPFVideoTrack\n\n\nMPFAudioTrack\n\n\n\n\nOpenMPF Component API\n\n\nThe OpenMPF Component class structure consists of:\n\n\n\n\nMPFComponentInterface\n - Baseline interface for all potential components.\n\n\nMPFComponentBase\n - An abstract baseline for components. Provides default implementations for \nMPFComponentInterface\n.\n\n\n\n\n\n\nIMPORTANT:\n This interface and abstract class should not be directly implemented, because no mechanism exists for launching components based off of it. Instead, it defines the contract that all types of components must follow. Currently, the only supported type of component is \"DETECTION\", and all components should extend \nMPFDetectionComponentBase\n\n\n\n\nSee the latest source here.\n\n\ninit()\n\n\nPerforms any necessary startup tasks for the component. This will be executed once, on component startup, and not for every job.\n\n\n\n\nMethod Definition:\n\npublic void init()\n\n\nParameters: none\n\n\nReturns: N/A\n\n\nExample:\n\n\n\n\npublic void init() {\n  // Setup logger, Load data models, etc.\n}\n\n\n\n\nclose()\n\n\nPerforms any necessary shutdown tasks for the component. This will be executed once, on component shutdown, and not for every job.\n\n\n\n\nMethod Definition:\n\npublic void close()\n\n\nParameters: none\n\n\nReturns: N/A\n\n\nExample:\n\n\n\n\npublic void close() {\n    // Close file handlers, etc.\n}\n\n\n\n\ngetComponentType()\n\n\nAllows the Component API to determine the component \"type.\" Currently \nDETECTION\n is the only supported component type.\n\n\n\n\nMethod Definition:\n\npublic MPFComponentType getComponentType()\n\n\nParameters: none\n\n\nReturns: (MPFComponentType) Currently, \nDETECTION\n is the only supported return value.\n\n\nExample:\n\n\n\n\npublic MPFComponentType getComponentType() {\n    return MPFComponentType.DETECTION;\n}\n\n\n\n\ngetRunDirectory()\n\n\nReturns the full path of the parent folder above where the component is installed.\n\n\n\n\nMethod Definition:\n\npublic String getRunDirectory()\n\n\nParameters: none\n\n\nReturns: (string) Full path of the parent folder above where the component is installed.\n\n\nSample Usage:\n\n\n\n\n\n\n\n\n\nsetRunDirectory(String)\n\n\nSets the value to the full path of the parent folder above where the component is installed.\n\n\n\n\nMethod Definition:\n\npublic void setRunDirectory(String runDirectory);\n\n\nParameters:\n\n\n\n\n\n\n\n\n\n\nParameter\n\n\nData Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nrunDirectory\n\n\nString\n\n\nFull path of the parent folder above where the component is installed.\n\n\n\n\n\n\n\n\n\n\nReturns: void\n\n\n\n\n\n\nIMPORTANT:\n \nsetRunDirectory\n is called by the Component Executor to set the correct path. It is not necessary to call this method in your component implementation.\n\n\n\n\nOpenMPF Detection Component API\n\n\nThe \nMPFDetectionComponentInterface\n must be utilized by all MPF detection components.\n\n\nEvery Java detection component must define a \ncomponent\n class which implements the MPFComponentInterface. This is typically performed by extending \nMPFDetectionComponentBase\n which extends \nMPFComponentBase\n and implements \nMPFDetectionComponentInterface\n.\n\n\nTo designate the component class, every Java detection component should include an applicationContext.xml which defines the \ncomponent\n bean.  The \ncomponent\n bean class must implement \nMPFDetectionComponentInterface\n.\n\n\n\n\nIMPORTANT:\n Each detection component must implement all of the \ngetDetections()\n methods or extend from a superclass which provides implementations for them (see \nconvenience adapters\n).\n\n\nIf your component does not support a particular data type, it should simply:\n\n\nthrow new MPFComponentDetectionError(MPFDetectionError.MPF_UNSUPPORTED_DATA_TYPE);\n\n\n\n\nConvenience Adapters\n\n\nAs an alternative to extending \nMPFDetectionComponentBase\n directly, developers may extend a convenience adapter classes provided by OpenMPF.\n\n\nThese adapters provide default implementations of several methods in \nMPFDetectionComponentInterface\n and ensure that the component's logic properly extends from the Component API. This enables developers to concentrate on implementation of the detection algorithm.\n\n\nThe following adapter is provided:\n\n\n\n\nAudio And Video Detection Component Adapter (\nsource\n)\n\n\n\n\n\n\nExample: Using Adaptors to Provide Simple AudioVisual Handling:\n\nMany components designed to work on audio files, such as speech detection, are relevant to video files as well.  Some of the tools for these components, however, only function on audio files (such as .wav, .mp3) and not video files (.avi, .mov, etc).\n\n\nThe \nMPFAudioAndVideoDetectionComponentAdapter\n adapter class implements the \ngetDetections(MPFVideoJob)\n method by translating the video request into an audio request.  It builds a temporary audio file by ripping the audio from the video media input, translates the \nMPFVideoJob\n into an \nMPFAudioJob\n, and invokes \ngetDetections(MPFAudioJob)\n on the generated file.  Once processing is done, the adapter translates the \nMPFAudioTrack\n list into an \nMPFVideoTrack\n list.\n\n\nSince only audio and video files are relevant to this adapter, it provides a default implementation of the \ngetDetections(MPFImageJob)\n method which throws \nnew MPFComponentDetectionError(MPFDetectionError.MPF_UNSUPPORTED_DATA_TYPE)\n.\n\n\nThe Sphinx speech detection component uses this adapter to run Sphinx speech detection on video files.  Other components that need to process video files as audio may also use the adapter.\n\n\n\n\nDetection Component Interface\n\n\nsupports(MPFDataType)\n\n\nReturns the supported data types of the component.\n\n\n\n\nMethod Definition:\n\npublic boolean supports(MPFDataType dataType)\n\n\nParameters:\n\n\n\n\n\n\n\n\n\n\nParameter\n\n\nData Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ndataType\n\n\nMPFDataType\n\n\nThe data type to verify. Component should only return true for IMAGE, VIDEO, and/or AUDIO.\n\n\n\n\n\n\n\n\n\n\nReturns: (boolean) True if the component supports the data type, otherwise false.\n\n\nExample:\n\n\n\n\n// Sample Component that supports only image and video files\npublic boolean supports(MPFDataType dataType) {\n    return dataType == MPFDataType.IMAGE || dataType == MPFDataType.VIDEO;\n}\n\n\n\n\ngetDetectionType()\n\n\nReturns the type of object detected by the component.\n\n\n\n\nMethod Definition:\n\npublic String getDetectionType()\n\n\n\n\nParameters: none\n\n\n\n\n\n\nReturns:\n\n\n\n\n\n\n\n\n\n\n\n\nData Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nString\n\n\nThe type of object detected by the component. Should be in all CAPS. Examples include: \nFACE\n, \nMOTION\n, \nPERSON\n, \nSPEECH\n, \nCLASS\n (for object classification), or \nTEXT\n.\n\n\n\n\n\n\n\n\n\n\nExample:\n\n\n\n\npublic String getDetectionType() {\n    return \nFACE\n;\n}\n\n\n\n\ngetDetections(MPFImageJob job)\n\n\nUsed to detect objects in image files. The MPFImageJob structure contains the URI specifying the location of the image file.\n\n\nCurrently, the dataUri is always a local file path. For example, \"/opt/mpf/share/remote-media/test-file.jpg\". This is because all media is copied to the OpenMPF server before the job is executed.\n\n\n\n\nMethod Definition:\n\n\n\n\npublic List\nMPFImageLocation\n getDetections(MPFImageJob job)\n  throws MPFComponentDetectionError;\n\n\n\n\n\n\nParameters:\n\n\n\n\n\n\n\n\n\n\nParameter\n\n\nData Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\njob\n\n\nMPFImageJob\n\n\nStructure containing details about the work to be performed. See \nMPFImageJob\n\n\n\n\n\n\n\n\n\n\nReturns:\n\n\n\n\n\n\n\n\n\n\nData Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nList\nMPFImageLocation\n\n\nThe \nMPFImageLocation\n data for each detected object.\n\n\n\n\n\n\n\n\n\n\nExample:\n\n\n\n\npublic List\nMPFImageLocation\n getDetections(MPFImageJob job)\n  throws MPFComponentDetectionError {\n    // Component logic to generate image locations\n}\n\n\n\n\ngetDetections(MPFVideoJob job)\n\n\nUsed to detect objects in a video.\n\n\nPrior to being sent to the component, videos are split into logical \"segments\" of video data and each segment (containing a range of frames) is assigned to a different job. Components are not guaranteed to receive requests in any order. For example, the first request processed by a component might receive a request for frames 300-399 of a Video A, while the next request may cover frames 900-999 of a Video B.\n\n\n\n\nMethod Definition:\n\n\n\n\npublic List\nMPFVideoTrack\n getDetections(MPFVideoJob job)\n  throws MPFComponentDetectionError;\n\n\n\n\n\n\nParameters:\n\n\n\n\n\n\n\n\n\n\nParameter\n\n\nData Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\njob\n\n\nMPFVideoJob\n\n\nStructure containing details about the work to be performed. See \nMPFVideoJob\n\n\n\n\n\n\n\n\n\n\nReturns:\n\n\n\n\n\n\n\n\n\n\nData Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nList\nMPFVideoTrack\n\n\nThe \nMPFVideoTrack\n data for each detected object.\n\n\n\n\n\n\n* Example:\n\n\n\n\n\n\n\n\n\n\npublic List\nMPFVideoTrack\n getDetections(MPFVideoJob job)\n  throws MPFComponentDetectionError {\n    // Component logic to generate video tracks\n}\n\n\n\n\ngetDetections(MPFAudioJob job)\n\n\nUsed to detect objects in audio files. Currently, audio files are not logically segmented, so a job will contain the entirety of the audio file.\n\n\n\n\nMethod Definition:\n\n\n\n\npublic List\nMPFAudioTrack\n getDetections(MPFAudioJob job)\n  throws MPFComponentDetectionError;\n\n\n\n\n\n\nParameters:\n\n\n\n\n\n\n\n\n\n\nParameter\n\n\nData Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\njob\n\n\nMPFAudioJob\n\n\nStructure containing details about the work to be performed. See \nMPFAudioJob\n\n\n\n\n\n\n\n\n\n\nReturns:\n\n\n\n\n\n\n\n\n\n\nData Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nList\nMPFAudioTrack\n\n\nThe \nMPFAudioTrack\n data for each detected object\n\n\n\n\n\n\n\n\n\n\nExample:\n\n\n\n\npublic List\nMPFAudioTrack\n getDetections(MPFAudioJob job)\n  throws MPFComponentDetectionError {\n    // Component logic to generate audio tracks\n}\n\n\n\n\nMPFComponentDetectionError\n\n\nAn exception that occurs in a component.  The exception must contain a reference to a valid \nMPFDetectionError\n.\n\n\n\n\nConstructor:\n\n\n\n\npublic MPFComponentDetectionError (\n    MPFDetectionError error,\n    String msg,\n    Exception e\n)\n\n\n\n\n\n\nParameters:\n\n\n\n\n\n\n\n\n\n\nParameter\n\n\nData Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nerror\n\n\nMPFDetectionError\n\n\nThe type of error generated by the component. See \nMPFDetectionError\n.\n\n\n\n\n\n\nmsg\n\n\nString\n\n\nThe detail message (which is saved for later retrieval by the \nThrowable.getMessage()\n method).\n\n\n\n\n\n\ne\n\n\nException\n\n\nThe cause (which is saved for later retrieval by the \nThrowable.getCause()\n method). A null value is permitted.\n\n\n\n\n\n\n\n\nDetection Job Classes\n\n\nThe \nMPFDetectionComponent\n data structures contain details about a specific job (work unit):\n\n\n\n\nMPFImageJob\n extends \nMPFJob\n\n\nMPFVideoJob\n extends \nMPFJob\n\n\nMPFAudioJob\n extends \nMPFJob\n\n\n\n\nThe following data structures contain details about detection results:\n\n\n\n\nMPFImageLocation\n\n\nMPFVideoTrack\n\n\nMPFAudioTrack\n\n\n\n\nMPFJob\n\n\nStructure containing data used for detection of objects.\n\n\n\n\nConstructor:\n\n\n\n\nprotected MPFJob(\n    String jobName,\n    String dataUri,\n    final Map\nString, String\n jobProperties,\n    final Map\nString, String\n mediaProperties\n)\n\n\n\n\n\n\nMembers:\n\n\n\n\n\n\n\n\n\n\nMember\n\n\nData Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\njobName \n\n\nString\n\n\nA specific name given to the job by the OpenMPF Framework. This value may be used, for example, for logging and debugging purposes.\n\n\n\n\n\n\ndataUri \n\n\nString\n\n\nThe URI of the input media file to be processed. Currently, this is a file path. For example, \"/opt/mpf/share/remote-media/test-file.avi\".\n\n\n\n\n\n\njobProperties \n\n\nMap\n<String\n, String>\n\n\nThe key corresponds to the property name specified in the component descriptor file described in \"Installing and Registering a Component\". Values are determined by an end user when creating a pipeline. \n Note: Only those property values specified by the user will be in the jobProperties map; for properties not contained in the map, the component must use a default value.\n\n\n\n\n\n\nmediaProperties \n\n\nMap\n<String\n, String>\n\n\nMetadata about the media associated with the job. The key is the property name and value is the property value. The entries in the map vary depend on the job type. They are defined in the specific Job's API description.\n\n\n\n\n\n\n\n\nMPFImageJob\n\n\nExtends \nMPFJob\n\n\nStructure containing data used for detection of objects in image files.\n\n\n\n\nConstructor:\n\n\n\n\npublic MPFImageJob(\n    String jobName,\n    String dataUri,\n    final Map\nString, String\n jobProperties,\n    final Map \nString, String\n mediaProperties)\n\n\n\n\n\n\nMembers:\n\n\n\n\n\n\n\n\n\n\nMember\n\n\nData Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\njobName\n\n\nString\n\n\nSee \nMPFJob.jobName\n for description.\n\n\n\n\n\n\ndataUri\n\n\nString\n\n\nSee \nMPFJob.dataUri\n for description.\n\n\n\n\n\n\njobProperties\n\n\nMap\n<String\n, String>\n\n\nSee \nMPFJob.jobProperties\n for description.\n\n\n\n\n\n\nmediaProperties\n\n\nMap\n<String\n, String>\n\n\nSee \nMPFJob.mediaProperties\n for description.\nThis may include the following key-value pairs:\nROTATION\n : 0, 90, 180, or 270 degrees\nHORIZONTAL_FLIP\n : true if the image is mirrored across the Y-axis, otherwise false\nEXIF_ORIENTATION\n : the standard EXIF orientation tag; a value between 1 and 8\n\n\n\n\n\n\n\n\nMPFVideoJob\n\n\nExtends \nMPFJob\n\n\nStructure containing data used for detection of objects in video files.\n\n\n\n\nConstructor:\n\n\n\n\npublic MPFVideoJob(\n    String jobName,\n    String dataUri,\n    final Map\nString, String\n jobProperties,\n    final Map\nString, String\n mediaProperties,\n    int startFrame,\n    int stopFrame)\n\n\n\n\n\n\nMembers:\n\n\n\n\n\n\n\n\n\n\nMember\n\n\nData Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\njobName\n\n\nString\n\n\nSee \nMPFJob.jobName\n for description.\n\n\n\n\n\n\ndataUri\n\n\nString\n\n\nSee \nMPFJob.dataUri\n for description.\n\n\n\n\n\n\nstartFrame\n\n\nint\n\n\nThe first frame number (0-based index) of the video that should be processed to look for detections.\n\n\n\n\n\n\nstopFrame\n\n\nint\n\n\nThe last frame number (0-based index) of the video that should be processed to look for detections.\n\n\n\n\n\n\njobProperties\n\n\nMap\n<String\n, String>\n\n\nSee \nMPFJob.jobProperties\n for description.\n\n\n\n\n\n\nmediaProperties\n\n\nMap\n<String\n, String>\n\n\nSee \nMPFJob.mediaProperties\n for description.\n \nIncludes the following key-value pairs:\nDURATION\n : length of video in milliseconds\nFPS\n : frames per second (averaged for variable frame rate video)\n\n\n\n\n\n\n\n\n\n\nIMPORTANT:\n For frame intervals greater than 1, the component must look for detections starting with the first frame, and then skip frames as specified by the frame interval, until or before it reaches the stop frame. For example, given a start frame of 0, a stop frame of 99, and a frame interval of 2, then the detection component must look for objects in frames numbered 0, 2, 4, 6, ..., 98.\n\n\n\n\nMPFAudioJob\n\n\nExtends \nMPFJob\n\n\nStructure containing data used for detection of objects in video files.\n\n\n\n\nConstructor:\n\n\n\n\nMPFAudioJob()\npublic MPFAudioJob(\n    String jobName,\n    String dataUri,\n    final Map\nString, String\n jobProperties,\n    final Map\nString, String\n mediaProperties,\n    int startTime,\n    int stopTime)\n\n\n\n\n\n\nMembers:\n\n\n\n\n\n\n\n\n\n\nMember\n\n\nData Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\njobName\n\n\nString\n\n\nSee \nMPFJob.jobName\n for description.\n\n\n\n\n\n\ndataUri\n\n\nString\n\n\nSee \nMPFJob.dataUri\n for description.\n\n\n\n\n\n\nstartTime\n\n\nint\n\n\nThe time (0-based index, in ms) associated with the beginning of the segment of the audio file that should be processed to look for detections.\n\n\n\n\n\n\nstopTime\n\n\nint\n\n\nThe time (0-based index, in ms) associated with the end of the segment of the audio file that should be processed to look for detections.\n\n\n\n\n\n\njobProperties\n\n\nMap\n<String\n, String>\n\n\nSee \nMPFJob.jobProperties\n for description.\n\n\n\n\n\n\nmediaProperties\n\n\nMap\n<String\n, String>\n\n\nSee \nMPFJob.mediaProperties\n for description.\n \nIncludes the following key-value pair:\nDURATION\n : length of audio file in milliseconds\n\n\n\n\n\n\n\n\nDetection Job Result Classes\n\n\nMPFImageLocation\n\n\nStructure used to store the location of detected objects in an image.\n\n\n\n\nConstructor:\n\n\n\n\npublic MPFImageLocation(\n        int xLeftUpper,\n        int yLeftUpper,\n        int width,\n        int height,\n        float confidence,\n        Map\nString, String\n detectionProperties\n)\n\n\n\n\n\n\nMembers:\n\n\n\n\n\n\n\n\n\n\nMember\n\n\nData Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nxLeftUpper\n\n\nint\n\n\nUpper left X coordinate of the detected object.\n\n\n\n\n\n\nyLeftUpper\n\n\nint\n\n\nUpper left Y coordinate of the detected object.\n\n\n\n\n\n\nwidth\n\n\nint\n\n\nThe width of the detected object. If the detection consists of the entire image, use 0.\n\n\n\n\n\n\nheight\n\n\nint\n\n\nThe height of the detected object. If the detection consists of the entire image, use 0.\n\n\n\n\n\n\nconfidence\n\n\nfloat\n\n\nRepresents the \"quality\" of the detection. The range depends on the detection algorithm. 0.0 is lowest quality. Higher values are higher quality. Using a standard range of [0.0 - 1.0] is advised. If the component is unable to supply a confidence value, it should return -1.0.\n\n\n\n\n\n\ndetectionProperties\n\n\nMap\n<String\n, String>\n\n\nOptional additional information about the detected object. There is no restriction on the keys or the number of entries that can be added to the Properties map. For best practice, keys should be in all CAPS.\n\n\n\n\n\n\n\n\n\n\nEXAMPLE - Using detectionProperties\n: A component that performs generic object classification could add an entry to the detectionProperties where the key is \nCLASSIFICATION\n and the value is a string corresponding to the type of object detected.\n\n\n\n\nMPFVideoTrack\n\n\nStructure used to store the location of detected objects in an image.\n\n\n\n\nConstructor:\n\n\n\n\npublic MPFVideoTrack(\n  int startFrame,\n  int stopFrame,\n  Map\nInteger, MPFImageLocation\n frameLocations,\n  float confidence,\n  Map\nString, String\n detectionProperties\n)\n\n\n\n\n\n\nMembers:\n\n\n\n\n\n\n\n\n\n\nMember\n\n\nData Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nstartFrame\n\n\nint\n\n\nThe first frame number (0-based index) that contained the detected object.\n\n\n\n\n\n\nstopFrame\n\n\nint\n\n\nThe last frame number (0-based index) that contained the detected object.\n\n\n\n\n\n\nframeLocations\n\n\nMap\n<Integer\n, MPFImageLocation>\n\n\nA map of individual detections. The key for each map entry is the frame number where the detection was generated, and the value is a \nMPFImageLocation\n calculated as if that frame was a still image. Note that a key-value pair is \nnot\n required for every frame between the track start frame and track stop frame. In some cases, frames are deliberately skipped, as when a FRAME_INTERVAL \n 1 is specified\n\n\n\n\n\n\nconfidence\n\n\nfloat\n\n\nRepresents the \"quality\" of the detection. The range depends on the detection algorithm. 0.0 is lowest quality. Higher values are higher quality. Using a standard range of [0.0 - 1.0] is advised. If the component is unable to supply a confidence value, it should return -1.0.\n\n\n\n\n\n\ndetectionProperties\n\n\nMap\n<String\n, String>\n\n\nOptional additional information about the detected object. There is no restriction on the keys or the number of entries that can be added to the Properties map. For best practice, keys should be in all CAPS.\n\n\n\n\n\n\n\n\n\n\nEXAMPLE - Using detectionProperties\n: A component that detects text could add an entry to the detectionProperties map where the key is \nTRANSCRIPTION\n and the value is a string representing the text found in the video segment.\n\n\n\n\nMPFAudioTrack\n\n\nStructure used to store the location of detected objects in an image.\n\n\n\n\nConstructor:\n\n\n\n\npublic MPFAudioTrack(\n  int startTime,\n  int stopTime,\n  float confidence,\n  Map\nString, String\n detectionProperties\n)\n\n\n\n\n\n\nMembers:\n\n\n\n\n\n\n\n\n\n\nMember\n\n\nData Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nstartTime\n\n\nint\n\n\nThe time (0-based index, in ms) when the audio detection event started.\n\n\n\n\n\n\nstopTime\n\n\nint\n\n\nThe time (0-based index, in ms) when the audio detection event stopped.\n\n\n\n\n\n\nconfidence\n\n\nfloat\n\n\nRepresents the \"quality\" of the detection. The range depends on the detection algorithm. 0.0 is lowest quality. Higher values are higher quality. Using a standard range of [0.0 - 1.0] is advised. If the component is unable to supply a confidence value, it should return -1.0.\n\n\n\n\n\n\ndetectionProperties\n\n\nProperties\n\n\nOptional additional information about the detection. There is no restriction on the keys or the number of entries that can be added to the Properties map. For best practice, keys should be in all CAPS.\n\n\n\n\n\n\n\n\nEnumeration Types\n\n\nMPFDetectionError\n\n\nEnum used to indicate the status of \ngetDetections\n in a \nMPFComponentDetectionError\n. A component is not required to support all error types.\n\n\n\n\n\n\n\n\nENUM\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nMPF_DETECTION_SUCCESS\n\n\nThe execution of any component method has completed normally with no errors.\n\n\n\n\n\n\nMPF_OTHER_DETECTION_ERROR_TYPE\n\n\nThe component method has failed for a reason that is not captured by any of the other error codes.\n\n\n\n\n\n\nMPF_DETECTION_NOT_INITIALIZED\n\n\nThe initialization of the component, or the initialization of any of its dependencies, has failed for any reason.\n\n\n\n\n\n\nMPF_UNRECOGNIZED_DATA_TYPE\n\n\nThe media data type received by a component is not one of the values contained in the \nMPFDataType\n enum.  Note that this failure is normally caught by the component executor before a job is passed to the component logic.\n\n\n\n\n\n\nMPF_UNSUPPORTED_DATA_TYPE\n\n\nThe job passed to a component requests processing of a job of an unsupported type. For instance, a component that is only capable of processing audio files should return this error code if a video or image job request is received.\n\n\n\n\n\n\nMPF_INVALID_DATAFILE_URI\n\n\nThe string containing the URI location of the input data file is invalid or empty.\n\n\n\n\n\n\nMPF_COULD_NOT_OPEN_DATAFILE\n\n\nThe data file to be processed could not be opened for any reason, such as a permissions failure, or an unreachable URI.\n\n\n\n\n\n\nMPF_COULD_NOT_READ_DATAFILE\n\n\nThere is a failure reading data from a successfully opened input data file.\n\n\n\n\n\n\nMPF_FILE_WRITE_ERROR\n\n\nThe component received a failure for any reason when attempting to write to a file.\n\n\n\n\n\n\nMPF_IMAGE_READ_ERROR\n\n\nThe component failed to read the image provided by the URI.\n\n\n\n\n\n\nMPF_BAD_FRAME_SIZE\n\n\nThe frame data retrieved has an incorrect or invalid frame size.\n\n\n\n\n\n\nMPF_BOUNDING_BOX_SIZE_ERROR\n\n\nThe calculation of a detection location bounding box has failed. For example, a component may be using an external library to detect objects, but the bounding box returned by that library lies partially outside the frame boundaries.\n\n\n\n\n\n\nMPF_INVALID_FRAME_INTERVAL\n\n\nAn invalid or unsupported frame interval was received.\n\n\n\n\n\n\nMPF_INVALID_START_FRAME\n\n\nThe component received an invalid start frame number. For example, if the start frame is less than zero, or greater than the stop frame, this error code should be used.\n\n\n\n\n\n\nMPF_INVALID_STOP_FRAME\n\n\nThe component receives an invalid stop frame number. For example, if the stop frame is less than the start frame, or greater than the number of the last frame in a video segment, this error code should be used.\n\n\n\n\n\n\nMPF_DETECTION_TRACKING_FAILED\n\n\nGeneral failure of a tracking algorithm.  This does not indicate a lack of tracks generated for the media, but rather a break down in the algorithm that makes it impossible to continue to try to track objects.\n\n\n\n\n\n\nMPF_INVALID_PROPERTY\n\n\nThe component received a property that is unrecognized or has an invalid/out-of-bounds value.\n\n\n\n\n\n\nMPF_MISSING_PROPERTY\n\n\nThe component received a job that is missing a required property.\n\n\n\n\n\n\nMPF_JOB_PROPERTY_IS_NOT_INT\n\n\nA job property is supposed to be an integer type, but it is of some other type, such as a boolean or a floating point value.\n\n\n\n\n\n\nMPF_JOB_PROPERTY_IS_NOT_FLOAT\n\n\nA job property is supposed to be a floating point type, but it is of some other type, such as a boolean value.\n\n\n\n\n\n\nMPF_INVALID_ROTATION\n\n\nThe component received a job that requests rotation of the media, but the rotation value given is not in the set of acceptable values.  The set of acceptable values is {0, 90, 180, 270}.\n\n\n\n\n\n\nMPF_MEMORY_ALLOCATION_FAILED\n\n\nThe component failed to allocate memory for any reason.\n\n\n\n\n\n\nMPF_DETECTION_FAILED\n\n\nGeneral failure of a detection algorithm.  This does not indicate a lack of detections found in the media, but rather a break down in the algorithm that makes it impossible to continue to try to detect objects.\n\n\n\n\n\n\n\n\nUtility Classes\n\n\nTODO\n\n\nJava Component Build Environment\n\n\nA Java Component must be built using a version of the Java SDK that is compatible with the one used to build the Java Component Executor. The OpenMPF Java Component Executor is currently built using Java version 1.8.0_60-b27. In general, the Java SDK is backwards compatible.\n\n\nComponents should be supplied as a tar file, which includes not only the component library, but any other libraries or files needed for execution. This includes all other non-standard libraries used by the component (aside from the standard Linux and Java SDK libraries), and any configuration or data files.\n\n\nComponent Development Best Practices\n\n\nSingle-threaded Operation\n\n\nImplementations are encouraged to operate in single-threaded mode. OpenMPF will parallelize components through multiple instantiations of the component, each running as a separate service.\n\n\nStateless Behavior\n\n\nOpenMPF components should be stateless in operation and give identical output for a provided input (i.e. when processing the same \nMPFJob\n).\n\n\nComponent Packaging\n\n\nIt is recommended that Java components are organized according to the following directory structure:\n\n\ncomponentName\n\u251c\u2500\u2500 config - Other component-specific configuration\n\u251c\u2500\u2500 descriptor\n\u2502   \u2514\u2500\u2500 descriptor.json\n\u2514\u2500\u2500 lib - All libraries required by the component\n\u2514\u2500\u2500 libComponentName.jar - Compiled component library\n\u2514\u2500\u2500 logback.xml - Logging configuration file\n\n\n\n\nOnce built, components should be packaged into a .tar.gz containing the contents of the directory shown above.\n\n\nLogging\n\n\nIt is recommended to use \nslf4j\n with \nlogback\n for OpenMPF Java Component logging. Multiple instances of the same component can log to the same file. Logging content can span multiple lines.\n\n\nLog files should be output to:\n\n${MPF_LOG_PATH}/${THIS_MPF_NODE}/log/\ncomponentName\n.log\n\n\nEach log statement must take the form:\n\nDATE TIME LEVEL CONTENT\n\n\nThe following log LEVELs are supported:\n \nFATAL, ERROR, WARN,  INFO,  DEBUG, TRACE\n.\n\n\nFor example:\n\n2016-02-09 13:42:42,341 INFO - Starting sample-component: [  OK  ]\n\n\nThe following logback configuration can be used to match the format of other OpenMPF logs:\n\n\nconfiguration\n\n    \nstatusListener class=\nch.qos.logback.core.status.NopStatusListener\n /\n\n    \nif condition='isNull(\nsampleComponentLogFile\n)' \n\n        \nthen\n\n            \nproperty name=\nsampleComponentLogFile\n value=\n${MPF_LOG_PATH}/${THIS_MPF_NODE}/log/sample-component-detection.log\n /\n\n        \n/then\n\n    \n/if\n\n\n    \n!-- Logging configuration --\n\n    \nappender name=\nSTDOUT-INFO\n class=\nch.qos.logback.core.ConsoleAppender\n\n        \nTarget\nSystem.out\n/Target\n\n        \nfilter class=\nch.qos.logback.classic.filter.LevelFilter\n\n            \nlevel\nINFO\n/level\n\n            \nonMatch\nACCEPT\n/onMatch\n\n            \nonMismatch\nDENY\n/onMismatch\n\n        \n/filter\n\n        \nencoder\n\n            \npattern\n%d %p [%thread] %logger{36} - %msg%n\n/pattern\n\n        \n/encoder\n\n    \n/appender\n\n    \n!-- send everything to stdout --\n\n    \nappender name=\nSTDOUT-DEBUG\n class=\nch.qos.logback.core.ConsoleAppender\n\n        \nTarget\nSystem.out\n/Target\n\n        \nencoder\n\n            \npattern\n%d %p [%thread] %logger{36} - %msg%n\n/pattern\n\n        \n/encoder\n\n    \n/appender\n\n    \n!-- send WARN and ERROR to STDERR --\n\n    \nappender name=\nSTDERR-WARN\n class=\nch.qos.logback.core.ConsoleAppender\n\n        \nTarget\nSystem.err\n/Target\n\n        \n!-- deny all events with a level below WARN, that is INFO, TRACE, and DEBUG --\n\n        \nfilter class=\nch.qos.logback.classic.filter.ThresholdFilter\n\n            \nlevel\nWARN\n/level\n\n        \n/filter\n\n        \nencoder\n\n            \npattern\n%d %p [%thread] %logger{36} - %msg%n\n/pattern\n\n        \n/encoder\n\n    \n/appender\n\n\n    \nappender name=\nSAMPLE-COMPONENT-DETECTION\n class=\nch.qos.logback.core.rolling.RollingFileAppender\n\n        \nfile\n${sampleComponentLogFile}\n/file\n\n        \nrollingPolicy class=\nch.qos.logback.core.rolling.TimeBasedRollingPolicy\n\n            \nfileNamePattern\n${sampleComponentLogFile}.%d{yyyy-MM-dd}.%i\n/fileNamePattern\n\n            \ntimeBasedFileNamingAndTriggeringPolicy class=\nch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\n\n                \nmaxFileSize\n50MB\n/maxFileSize\n\n            \n/timeBasedFileNamingAndTriggeringPolicy\n\n        \n/rollingPolicy\n\n        \nencoder\n\n            \npattern\n%d %p [%thread] %logger{36} - %msg%n\n/pattern\n\n        \n/encoder\n\n    \n/appender\n\n\n    \nlogger name=\norg.dstovall\n level=\nWARN\n/\n\n    \nlogger name=\norg.springframework.context.annotation\n level=\nWARN\n/\n\n    \nlogger name=\norg.springframework.beans.factory\n level=\nWARN\n/\n\n    \nlogger name=\norg.apache.xbean.spring\n level=\nWARN\n/\n\n    \nlogger name=\norg.mitre\n level=\nINFO\n/\n\n\n    \nroot level=\nINFO\n\n        \nappender-ref ref=\nSTDERR-WARN\n /\n\n        \nappender-ref ref=\nSAMPLE-COMPONENT-DETECTION\n/\n\n    \n/root\n\n\n/configuration", 
            "title": "Java Component API"
        }, 
        {
            "location": "/Java-Component-API/#java-component-api-overview", 
            "text": "In OpenMPF, a  component  is a plugin that receives jobs (containing media), processes that  media, and returns results.  The OpenMPF Component API currently supports the development of  detection components , which are used detect objects in image, video, or audio files.  Using this API, detection components can be built to provide:   Detection (Localizing an object)  Tracking (Localizing an object across multiple frames)  Classification (Detecting the type of object and optionally localizing that object)  Transcription (Detecting speech and transcribing it into text)", 
            "title": "Java Component API Overview"
        }, 
        {
            "location": "/Java-Component-API/#how-components-integrate-into-openmpf", 
            "text": "Components are integrated into OpenMPF through the use of OpenMPF's  Component Executor . Developers create component libraries that encapsulate the component detection logic. Each instance of the Component Executor loads one of these libraries and uses it to service job requests sent by the OpenMPF Workflow Manager (WFM).  The Component Executor:   Receives and parses job requests from the WFM  Invokes methods on the component library to obtain detection results  Populates and sends the respective responses to the WFM   The basic psuedocode for the Component Executor is as follows:  component.setRunDirectory(...)\ncomponent.init()\nwhile (true) {\n  job = ReceiveJob()\n  if (component.supports(job.dataType))\n    component.getDetections(...) // Component does the work here\n}\ncomponent.close()  Each instance of a Component Executor runs as a separate process.  The Component Executor receives and parses requests from the WFM, invokes methods on the Component Logic to get detection objects, and subsequently populates responses with the component output and sends them to the WFM.  A component developer implements a detection component by extending  MPFDetectionComponentBase .  As an alternative to extending  MPFDetectionComponentBase  directly, a developer may extend one of several convenience adapter classes provided by OpenMPF. See  Convenience Adapters  for more information.", 
            "title": "How Components Integrate into OpenMPF"
        }, 
        {
            "location": "/Java-Component-API/#getting-started", 
            "text": "The quickest way to get started with the OpenMPF Component API is to first read the  OpenMPF Component API Overview . Example components are currently in development. These examples will provide a template for getting started.  Detection components are implemented by:   Extending  MPFDetectionComponentBase .  Building the component into a jar. (TODO: reference example).  Packaging the component into an OpenMPF-compliant .tar.gz file. (See  Component Packaging ).  Registering the component with OpenMPF (see  Packaging and Registering a Component ).", 
            "title": "Getting Started"
        }, 
        {
            "location": "/Java-Component-API/#openmpf-api-specification", 
            "text": "The figure below presents a high-level component diagram of the OpenMPF API:   The API consists of  Component Interfaces , which provide interfaces and abstract classes for developing components;  Job Definitions , which define the work to be performed by a component; and  Job Results , which define the results generated by the component; and  Component Adapters , which provide default implementations of several of the  MPFDetectionComponentInterface  methods (examples shown; TODO: implement these). In the future, the API will also include  Component Utilities , which perform actions such as image flipping, rotation, and cropping.  Component Interfaces   MPFComponentInterface  - Baseline interface for all potential components.  MPFComponentBase  - An abstract baseline for components. Provides default implementations for  MPFComponentInterface .   Detection Component Interfaces   MPFDetectionComponentInterface  - Baseline interface for detection components.  MPFDetectionComponentBase  - An abstract baseline for detection components. Provides default implementations for   MPFDetectionComponentInterface .   Job Definitions  The following classes define the details about a specific job (work unit):   MPFImageJob  extends  MPFJob  MPFVideoJob  extends  MPFJob  MPFAudioJob  extends  MPFJob   Job Results  The following classes define the results of a component's processing:   MPFImageLocation  MPFVideoTrack  MPFAudioTrack", 
            "title": "OpenMPF API Specification"
        }, 
        {
            "location": "/Java-Component-API/#openmpf-component-api", 
            "text": "The OpenMPF Component class structure consists of:   MPFComponentInterface  - Baseline interface for all potential components.  MPFComponentBase  - An abstract baseline for components. Provides default implementations for  MPFComponentInterface .    IMPORTANT:  This interface and abstract class should not be directly implemented, because no mechanism exists for launching components based off of it. Instead, it defines the contract that all types of components must follow. Currently, the only supported type of component is \"DETECTION\", and all components should extend  MPFDetectionComponentBase   See the latest source here.", 
            "title": "OpenMPF Component API"
        }, 
        {
            "location": "/Java-Component-API/#init", 
            "text": "Performs any necessary startup tasks for the component. This will be executed once, on component startup, and not for every job.   Method Definition: public void init()  Parameters: none  Returns: N/A  Example:   public void init() {\n  // Setup logger, Load data models, etc.\n}", 
            "title": "init()"
        }, 
        {
            "location": "/Java-Component-API/#close", 
            "text": "Performs any necessary shutdown tasks for the component. This will be executed once, on component shutdown, and not for every job.   Method Definition: public void close()  Parameters: none  Returns: N/A  Example:   public void close() {\n    // Close file handlers, etc.\n}", 
            "title": "close()"
        }, 
        {
            "location": "/Java-Component-API/#getcomponenttype", 
            "text": "Allows the Component API to determine the component \"type.\" Currently  DETECTION  is the only supported component type.   Method Definition: public MPFComponentType getComponentType()  Parameters: none  Returns: (MPFComponentType) Currently,  DETECTION  is the only supported return value.  Example:   public MPFComponentType getComponentType() {\n    return MPFComponentType.DETECTION;\n}", 
            "title": "getComponentType()"
        }, 
        {
            "location": "/Java-Component-API/#getrundirectory", 
            "text": "Returns the full path of the parent folder above where the component is installed.   Method Definition: public String getRunDirectory()  Parameters: none  Returns: (string) Full path of the parent folder above where the component is installed.  Sample Usage:", 
            "title": "getRunDirectory()"
        }, 
        {
            "location": "/Java-Component-API/#setrundirectorystring", 
            "text": "Sets the value to the full path of the parent folder above where the component is installed.   Method Definition: public void setRunDirectory(String runDirectory);  Parameters:      Parameter  Data Type  Description      runDirectory  String  Full path of the parent folder above where the component is installed.      Returns: void    IMPORTANT:   setRunDirectory  is called by the Component Executor to set the correct path. It is not necessary to call this method in your component implementation.", 
            "title": "setRunDirectory(String)"
        }, 
        {
            "location": "/Java-Component-API/#openmpf-detection-component-api", 
            "text": "The  MPFDetectionComponentInterface  must be utilized by all MPF detection components.  Every Java detection component must define a  component  class which implements the MPFComponentInterface. This is typically performed by extending  MPFDetectionComponentBase  which extends  MPFComponentBase  and implements  MPFDetectionComponentInterface .  To designate the component class, every Java detection component should include an applicationContext.xml which defines the  component  bean.  The  component  bean class must implement  MPFDetectionComponentInterface .   IMPORTANT:  Each detection component must implement all of the  getDetections()  methods or extend from a superclass which provides implementations for them (see  convenience adapters ).  If your component does not support a particular data type, it should simply:  throw new MPFComponentDetectionError(MPFDetectionError.MPF_UNSUPPORTED_DATA_TYPE);", 
            "title": "OpenMPF Detection Component API"
        }, 
        {
            "location": "/Java-Component-API/#convenience-adapters", 
            "text": "As an alternative to extending  MPFDetectionComponentBase  directly, developers may extend a convenience adapter classes provided by OpenMPF.  These adapters provide default implementations of several methods in  MPFDetectionComponentInterface  and ensure that the component's logic properly extends from the Component API. This enables developers to concentrate on implementation of the detection algorithm.  The following adapter is provided:   Audio And Video Detection Component Adapter ( source )    Example: Using Adaptors to Provide Simple AudioVisual Handling: \nMany components designed to work on audio files, such as speech detection, are relevant to video files as well.  Some of the tools for these components, however, only function on audio files (such as .wav, .mp3) and not video files (.avi, .mov, etc).  The  MPFAudioAndVideoDetectionComponentAdapter  adapter class implements the  getDetections(MPFVideoJob)  method by translating the video request into an audio request.  It builds a temporary audio file by ripping the audio from the video media input, translates the  MPFVideoJob  into an  MPFAudioJob , and invokes  getDetections(MPFAudioJob)  on the generated file.  Once processing is done, the adapter translates the  MPFAudioTrack  list into an  MPFVideoTrack  list.  Since only audio and video files are relevant to this adapter, it provides a default implementation of the  getDetections(MPFImageJob)  method which throws  new MPFComponentDetectionError(MPFDetectionError.MPF_UNSUPPORTED_DATA_TYPE) .  The Sphinx speech detection component uses this adapter to run Sphinx speech detection on video files.  Other components that need to process video files as audio may also use the adapter.", 
            "title": "Convenience Adapters"
        }, 
        {
            "location": "/Java-Component-API/#detection-component-interface", 
            "text": "", 
            "title": "Detection Component Interface"
        }, 
        {
            "location": "/Java-Component-API/#supportsmpfdatatype", 
            "text": "Returns the supported data types of the component.   Method Definition: public boolean supports(MPFDataType dataType)  Parameters:      Parameter  Data Type  Description      dataType  MPFDataType  The data type to verify. Component should only return true for IMAGE, VIDEO, and/or AUDIO.      Returns: (boolean) True if the component supports the data type, otherwise false.  Example:   // Sample Component that supports only image and video files\npublic boolean supports(MPFDataType dataType) {\n    return dataType == MPFDataType.IMAGE || dataType == MPFDataType.VIDEO;\n}", 
            "title": "supports(MPFDataType)"
        }, 
        {
            "location": "/Java-Component-API/#getdetectiontype", 
            "text": "Returns the type of object detected by the component.   Method Definition: public String getDetectionType()   Parameters: none    Returns:       Data Type  Description      String  The type of object detected by the component. Should be in all CAPS. Examples include:  FACE ,  MOTION ,  PERSON ,  SPEECH ,  CLASS  (for object classification), or  TEXT .      Example:   public String getDetectionType() {\n    return  FACE ;\n}", 
            "title": "getDetectionType()"
        }, 
        {
            "location": "/Java-Component-API/#getdetectionsmpfimagejob-job", 
            "text": "Used to detect objects in image files. The MPFImageJob structure contains the URI specifying the location of the image file.  Currently, the dataUri is always a local file path. For example, \"/opt/mpf/share/remote-media/test-file.jpg\". This is because all media is copied to the OpenMPF server before the job is executed.   Method Definition:   public List MPFImageLocation  getDetections(MPFImageJob job)\n  throws MPFComponentDetectionError;   Parameters:      Parameter  Data Type  Description      job  MPFImageJob  Structure containing details about the work to be performed. See  MPFImageJob      Returns:      Data Type  Description      List MPFImageLocation  The  MPFImageLocation  data for each detected object.      Example:   public List MPFImageLocation  getDetections(MPFImageJob job)\n  throws MPFComponentDetectionError {\n    // Component logic to generate image locations\n}", 
            "title": "getDetections(MPFImageJob job)"
        }, 
        {
            "location": "/Java-Component-API/#getdetectionsmpfvideojob-job", 
            "text": "Used to detect objects in a video.  Prior to being sent to the component, videos are split into logical \"segments\" of video data and each segment (containing a range of frames) is assigned to a different job. Components are not guaranteed to receive requests in any order. For example, the first request processed by a component might receive a request for frames 300-399 of a Video A, while the next request may cover frames 900-999 of a Video B.   Method Definition:   public List MPFVideoTrack  getDetections(MPFVideoJob job)\n  throws MPFComponentDetectionError;   Parameters:      Parameter  Data Type  Description      job  MPFVideoJob  Structure containing details about the work to be performed. See  MPFVideoJob      Returns:      Data Type  Description      List MPFVideoTrack  The  MPFVideoTrack  data for each detected object.    * Example:      public List MPFVideoTrack  getDetections(MPFVideoJob job)\n  throws MPFComponentDetectionError {\n    // Component logic to generate video tracks\n}", 
            "title": "getDetections(MPFVideoJob job)"
        }, 
        {
            "location": "/Java-Component-API/#getdetectionsmpfaudiojob-job", 
            "text": "Used to detect objects in audio files. Currently, audio files are not logically segmented, so a job will contain the entirety of the audio file.   Method Definition:   public List MPFAudioTrack  getDetections(MPFAudioJob job)\n  throws MPFComponentDetectionError;   Parameters:      Parameter  Data Type  Description      job  MPFAudioJob  Structure containing details about the work to be performed. See  MPFAudioJob      Returns:      Data Type  Description      List MPFAudioTrack  The  MPFAudioTrack  data for each detected object      Example:   public List MPFAudioTrack  getDetections(MPFAudioJob job)\n  throws MPFComponentDetectionError {\n    // Component logic to generate audio tracks\n}", 
            "title": "getDetections(MPFAudioJob job)"
        }, 
        {
            "location": "/Java-Component-API/#mpfcomponentdetectionerror", 
            "text": "An exception that occurs in a component.  The exception must contain a reference to a valid  MPFDetectionError .   Constructor:   public MPFComponentDetectionError (\n    MPFDetectionError error,\n    String msg,\n    Exception e\n)   Parameters:      Parameter  Data Type  Description      error  MPFDetectionError  The type of error generated by the component. See  MPFDetectionError .    msg  String  The detail message (which is saved for later retrieval by the  Throwable.getMessage()  method).    e  Exception  The cause (which is saved for later retrieval by the  Throwable.getCause()  method). A null value is permitted.", 
            "title": "MPFComponentDetectionError"
        }, 
        {
            "location": "/Java-Component-API/#detection-job-classes", 
            "text": "The  MPFDetectionComponent  data structures contain details about a specific job (work unit):   MPFImageJob  extends  MPFJob  MPFVideoJob  extends  MPFJob  MPFAudioJob  extends  MPFJob   The following data structures contain details about detection results:   MPFImageLocation  MPFVideoTrack  MPFAudioTrack", 
            "title": "Detection Job Classes"
        }, 
        {
            "location": "/Java-Component-API/#mpfjob", 
            "text": "Structure containing data used for detection of objects.   Constructor:   protected MPFJob(\n    String jobName,\n    String dataUri,\n    final Map String, String  jobProperties,\n    final Map String, String  mediaProperties\n)   Members:      Member  Data Type  Description      jobName   String  A specific name given to the job by the OpenMPF Framework. This value may be used, for example, for logging and debugging purposes.    dataUri   String  The URI of the input media file to be processed. Currently, this is a file path. For example, \"/opt/mpf/share/remote-media/test-file.avi\".    jobProperties   Map <String , String>  The key corresponds to the property name specified in the component descriptor file described in \"Installing and Registering a Component\". Values are determined by an end user when creating a pipeline.   Note: Only those property values specified by the user will be in the jobProperties map; for properties not contained in the map, the component must use a default value.    mediaProperties   Map <String , String>  Metadata about the media associated with the job. The key is the property name and value is the property value. The entries in the map vary depend on the job type. They are defined in the specific Job's API description.", 
            "title": "MPFJob"
        }, 
        {
            "location": "/Java-Component-API/#mpfimagejob", 
            "text": "Extends  MPFJob  Structure containing data used for detection of objects in image files.   Constructor:   public MPFImageJob(\n    String jobName,\n    String dataUri,\n    final Map String, String  jobProperties,\n    final Map  String, String  mediaProperties)   Members:      Member  Data Type  Description      jobName  String  See  MPFJob.jobName  for description.    dataUri  String  See  MPFJob.dataUri  for description.    jobProperties  Map <String , String>  See  MPFJob.jobProperties  for description.    mediaProperties  Map <String , String>  See  MPFJob.mediaProperties  for description. This may include the following key-value pairs: ROTATION  : 0, 90, 180, or 270 degrees HORIZONTAL_FLIP  : true if the image is mirrored across the Y-axis, otherwise false EXIF_ORIENTATION  : the standard EXIF orientation tag; a value between 1 and 8", 
            "title": "MPFImageJob"
        }, 
        {
            "location": "/Java-Component-API/#mpfvideojob", 
            "text": "Extends  MPFJob  Structure containing data used for detection of objects in video files.   Constructor:   public MPFVideoJob(\n    String jobName,\n    String dataUri,\n    final Map String, String  jobProperties,\n    final Map String, String  mediaProperties,\n    int startFrame,\n    int stopFrame)   Members:      Member  Data Type  Description      jobName  String  See  MPFJob.jobName  for description.    dataUri  String  See  MPFJob.dataUri  for description.    startFrame  int  The first frame number (0-based index) of the video that should be processed to look for detections.    stopFrame  int  The last frame number (0-based index) of the video that should be processed to look for detections.    jobProperties  Map <String , String>  See  MPFJob.jobProperties  for description.    mediaProperties  Map <String , String>  See  MPFJob.mediaProperties  for description.   Includes the following key-value pairs: DURATION  : length of video in milliseconds FPS  : frames per second (averaged for variable frame rate video)      IMPORTANT:  For frame intervals greater than 1, the component must look for detections starting with the first frame, and then skip frames as specified by the frame interval, until or before it reaches the stop frame. For example, given a start frame of 0, a stop frame of 99, and a frame interval of 2, then the detection component must look for objects in frames numbered 0, 2, 4, 6, ..., 98.", 
            "title": "MPFVideoJob"
        }, 
        {
            "location": "/Java-Component-API/#mpfaudiojob", 
            "text": "Extends  MPFJob  Structure containing data used for detection of objects in video files.   Constructor:   MPFAudioJob()\npublic MPFAudioJob(\n    String jobName,\n    String dataUri,\n    final Map String, String  jobProperties,\n    final Map String, String  mediaProperties,\n    int startTime,\n    int stopTime)   Members:      Member  Data Type  Description      jobName  String  See  MPFJob.jobName  for description.    dataUri  String  See  MPFJob.dataUri  for description.    startTime  int  The time (0-based index, in ms) associated with the beginning of the segment of the audio file that should be processed to look for detections.    stopTime  int  The time (0-based index, in ms) associated with the end of the segment of the audio file that should be processed to look for detections.    jobProperties  Map <String , String>  See  MPFJob.jobProperties  for description.    mediaProperties  Map <String , String>  See  MPFJob.mediaProperties  for description.   Includes the following key-value pair: DURATION  : length of audio file in milliseconds", 
            "title": "MPFAudioJob"
        }, 
        {
            "location": "/Java-Component-API/#detection-job-result-classes", 
            "text": "", 
            "title": "Detection Job Result Classes"
        }, 
        {
            "location": "/Java-Component-API/#mpfimagelocation", 
            "text": "Structure used to store the location of detected objects in an image.   Constructor:   public MPFImageLocation(\n        int xLeftUpper,\n        int yLeftUpper,\n        int width,\n        int height,\n        float confidence,\n        Map String, String  detectionProperties\n)   Members:      Member  Data Type  Description      xLeftUpper  int  Upper left X coordinate of the detected object.    yLeftUpper  int  Upper left Y coordinate of the detected object.    width  int  The width of the detected object. If the detection consists of the entire image, use 0.    height  int  The height of the detected object. If the detection consists of the entire image, use 0.    confidence  float  Represents the \"quality\" of the detection. The range depends on the detection algorithm. 0.0 is lowest quality. Higher values are higher quality. Using a standard range of [0.0 - 1.0] is advised. If the component is unable to supply a confidence value, it should return -1.0.    detectionProperties  Map <String , String>  Optional additional information about the detected object. There is no restriction on the keys or the number of entries that can be added to the Properties map. For best practice, keys should be in all CAPS.      EXAMPLE - Using detectionProperties : A component that performs generic object classification could add an entry to the detectionProperties where the key is  CLASSIFICATION  and the value is a string corresponding to the type of object detected.", 
            "title": "MPFImageLocation"
        }, 
        {
            "location": "/Java-Component-API/#mpfvideotrack", 
            "text": "Structure used to store the location of detected objects in an image.   Constructor:   public MPFVideoTrack(\n  int startFrame,\n  int stopFrame,\n  Map Integer, MPFImageLocation  frameLocations,\n  float confidence,\n  Map String, String  detectionProperties\n)   Members:      Member  Data Type  Description      startFrame  int  The first frame number (0-based index) that contained the detected object.    stopFrame  int  The last frame number (0-based index) that contained the detected object.    frameLocations  Map <Integer , MPFImageLocation>  A map of individual detections. The key for each map entry is the frame number where the detection was generated, and the value is a  MPFImageLocation  calculated as if that frame was a still image. Note that a key-value pair is  not  required for every frame between the track start frame and track stop frame. In some cases, frames are deliberately skipped, as when a FRAME_INTERVAL   1 is specified    confidence  float  Represents the \"quality\" of the detection. The range depends on the detection algorithm. 0.0 is lowest quality. Higher values are higher quality. Using a standard range of [0.0 - 1.0] is advised. If the component is unable to supply a confidence value, it should return -1.0.    detectionProperties  Map <String , String>  Optional additional information about the detected object. There is no restriction on the keys or the number of entries that can be added to the Properties map. For best practice, keys should be in all CAPS.      EXAMPLE - Using detectionProperties : A component that detects text could add an entry to the detectionProperties map where the key is  TRANSCRIPTION  and the value is a string representing the text found in the video segment.", 
            "title": "MPFVideoTrack"
        }, 
        {
            "location": "/Java-Component-API/#mpfaudiotrack", 
            "text": "Structure used to store the location of detected objects in an image.   Constructor:   public MPFAudioTrack(\n  int startTime,\n  int stopTime,\n  float confidence,\n  Map String, String  detectionProperties\n)   Members:      Member  Data Type  Description      startTime  int  The time (0-based index, in ms) when the audio detection event started.    stopTime  int  The time (0-based index, in ms) when the audio detection event stopped.    confidence  float  Represents the \"quality\" of the detection. The range depends on the detection algorithm. 0.0 is lowest quality. Higher values are higher quality. Using a standard range of [0.0 - 1.0] is advised. If the component is unable to supply a confidence value, it should return -1.0.    detectionProperties  Properties  Optional additional information about the detection. There is no restriction on the keys or the number of entries that can be added to the Properties map. For best practice, keys should be in all CAPS.", 
            "title": "MPFAudioTrack"
        }, 
        {
            "location": "/Java-Component-API/#enumeration-types", 
            "text": "", 
            "title": "Enumeration Types"
        }, 
        {
            "location": "/Java-Component-API/#mpfdetectionerror", 
            "text": "Enum used to indicate the status of  getDetections  in a  MPFComponentDetectionError . A component is not required to support all error types.     ENUM  Description      MPF_DETECTION_SUCCESS  The execution of any component method has completed normally with no errors.    MPF_OTHER_DETECTION_ERROR_TYPE  The component method has failed for a reason that is not captured by any of the other error codes.    MPF_DETECTION_NOT_INITIALIZED  The initialization of the component, or the initialization of any of its dependencies, has failed for any reason.    MPF_UNRECOGNIZED_DATA_TYPE  The media data type received by a component is not one of the values contained in the  MPFDataType  enum.  Note that this failure is normally caught by the component executor before a job is passed to the component logic.    MPF_UNSUPPORTED_DATA_TYPE  The job passed to a component requests processing of a job of an unsupported type. For instance, a component that is only capable of processing audio files should return this error code if a video or image job request is received.    MPF_INVALID_DATAFILE_URI  The string containing the URI location of the input data file is invalid or empty.    MPF_COULD_NOT_OPEN_DATAFILE  The data file to be processed could not be opened for any reason, such as a permissions failure, or an unreachable URI.    MPF_COULD_NOT_READ_DATAFILE  There is a failure reading data from a successfully opened input data file.    MPF_FILE_WRITE_ERROR  The component received a failure for any reason when attempting to write to a file.    MPF_IMAGE_READ_ERROR  The component failed to read the image provided by the URI.    MPF_BAD_FRAME_SIZE  The frame data retrieved has an incorrect or invalid frame size.    MPF_BOUNDING_BOX_SIZE_ERROR  The calculation of a detection location bounding box has failed. For example, a component may be using an external library to detect objects, but the bounding box returned by that library lies partially outside the frame boundaries.    MPF_INVALID_FRAME_INTERVAL  An invalid or unsupported frame interval was received.    MPF_INVALID_START_FRAME  The component received an invalid start frame number. For example, if the start frame is less than zero, or greater than the stop frame, this error code should be used.    MPF_INVALID_STOP_FRAME  The component receives an invalid stop frame number. For example, if the stop frame is less than the start frame, or greater than the number of the last frame in a video segment, this error code should be used.    MPF_DETECTION_TRACKING_FAILED  General failure of a tracking algorithm.  This does not indicate a lack of tracks generated for the media, but rather a break down in the algorithm that makes it impossible to continue to try to track objects.    MPF_INVALID_PROPERTY  The component received a property that is unrecognized or has an invalid/out-of-bounds value.    MPF_MISSING_PROPERTY  The component received a job that is missing a required property.    MPF_JOB_PROPERTY_IS_NOT_INT  A job property is supposed to be an integer type, but it is of some other type, such as a boolean or a floating point value.    MPF_JOB_PROPERTY_IS_NOT_FLOAT  A job property is supposed to be a floating point type, but it is of some other type, such as a boolean value.    MPF_INVALID_ROTATION  The component received a job that requests rotation of the media, but the rotation value given is not in the set of acceptable values.  The set of acceptable values is {0, 90, 180, 270}.    MPF_MEMORY_ALLOCATION_FAILED  The component failed to allocate memory for any reason.    MPF_DETECTION_FAILED  General failure of a detection algorithm.  This does not indicate a lack of detections found in the media, but rather a break down in the algorithm that makes it impossible to continue to try to detect objects.", 
            "title": "MPFDetectionError"
        }, 
        {
            "location": "/Java-Component-API/#utility-classes", 
            "text": "TODO", 
            "title": "Utility Classes"
        }, 
        {
            "location": "/Java-Component-API/#java-component-build-environment", 
            "text": "A Java Component must be built using a version of the Java SDK that is compatible with the one used to build the Java Component Executor. The OpenMPF Java Component Executor is currently built using Java version 1.8.0_60-b27. In general, the Java SDK is backwards compatible.  Components should be supplied as a tar file, which includes not only the component library, but any other libraries or files needed for execution. This includes all other non-standard libraries used by the component (aside from the standard Linux and Java SDK libraries), and any configuration or data files.", 
            "title": "Java Component Build Environment"
        }, 
        {
            "location": "/Java-Component-API/#component-development-best-practices", 
            "text": "", 
            "title": "Component Development Best Practices"
        }, 
        {
            "location": "/Java-Component-API/#single-threaded-operation", 
            "text": "Implementations are encouraged to operate in single-threaded mode. OpenMPF will parallelize components through multiple instantiations of the component, each running as a separate service.", 
            "title": "Single-threaded Operation"
        }, 
        {
            "location": "/Java-Component-API/#stateless-behavior", 
            "text": "OpenMPF components should be stateless in operation and give identical output for a provided input (i.e. when processing the same  MPFJob ).", 
            "title": "Stateless Behavior"
        }, 
        {
            "location": "/Java-Component-API/#component-packaging", 
            "text": "It is recommended that Java components are organized according to the following directory structure:  componentName\n\u251c\u2500\u2500 config - Other component-specific configuration\n\u251c\u2500\u2500 descriptor\n\u2502   \u2514\u2500\u2500 descriptor.json\n\u2514\u2500\u2500 lib - All libraries required by the component\n\u2514\u2500\u2500 libComponentName.jar - Compiled component library\n\u2514\u2500\u2500 logback.xml - Logging configuration file  Once built, components should be packaged into a .tar.gz containing the contents of the directory shown above.", 
            "title": "Component Packaging"
        }, 
        {
            "location": "/Java-Component-API/#logging", 
            "text": "It is recommended to use  slf4j  with  logback  for OpenMPF Java Component logging. Multiple instances of the same component can log to the same file. Logging content can span multiple lines.  Log files should be output to: ${MPF_LOG_PATH}/${THIS_MPF_NODE}/log/ componentName .log  Each log statement must take the form: DATE TIME LEVEL CONTENT  The following log LEVELs are supported:\n  FATAL, ERROR, WARN,  INFO,  DEBUG, TRACE .  For example: 2016-02-09 13:42:42,341 INFO - Starting sample-component: [  OK  ]  The following logback configuration can be used to match the format of other OpenMPF logs:  configuration \n     statusListener class= ch.qos.logback.core.status.NopStatusListener  / \n     if condition='isNull( sampleComponentLogFile )'  \n         then \n             property name= sampleComponentLogFile  value= ${MPF_LOG_PATH}/${THIS_MPF_NODE}/log/sample-component-detection.log  / \n         /then \n     /if \n\n     !-- Logging configuration -- \n     appender name= STDOUT-INFO  class= ch.qos.logback.core.ConsoleAppender \n         Target System.out /Target \n         filter class= ch.qos.logback.classic.filter.LevelFilter \n             level INFO /level \n             onMatch ACCEPT /onMatch \n             onMismatch DENY /onMismatch \n         /filter \n         encoder \n             pattern %d %p [%thread] %logger{36} - %msg%n /pattern \n         /encoder \n     /appender \n     !-- send everything to stdout -- \n     appender name= STDOUT-DEBUG  class= ch.qos.logback.core.ConsoleAppender \n         Target System.out /Target \n         encoder \n             pattern %d %p [%thread] %logger{36} - %msg%n /pattern \n         /encoder \n     /appender \n     !-- send WARN and ERROR to STDERR -- \n     appender name= STDERR-WARN  class= ch.qos.logback.core.ConsoleAppender \n         Target System.err /Target \n         !-- deny all events with a level below WARN, that is INFO, TRACE, and DEBUG -- \n         filter class= ch.qos.logback.classic.filter.ThresholdFilter \n             level WARN /level \n         /filter \n         encoder \n             pattern %d %p [%thread] %logger{36} - %msg%n /pattern \n         /encoder \n     /appender \n\n     appender name= SAMPLE-COMPONENT-DETECTION  class= ch.qos.logback.core.rolling.RollingFileAppender \n         file ${sampleComponentLogFile} /file \n         rollingPolicy class= ch.qos.logback.core.rolling.TimeBasedRollingPolicy \n             fileNamePattern ${sampleComponentLogFile}.%d{yyyy-MM-dd}.%i /fileNamePattern \n             timeBasedFileNamingAndTriggeringPolicy class= ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP \n                 maxFileSize 50MB /maxFileSize \n             /timeBasedFileNamingAndTriggeringPolicy \n         /rollingPolicy \n         encoder \n             pattern %d %p [%thread] %logger{36} - %msg%n /pattern \n         /encoder \n     /appender \n\n     logger name= org.dstovall  level= WARN / \n     logger name= org.springframework.context.annotation  level= WARN / \n     logger name= org.springframework.beans.factory  level= WARN / \n     logger name= org.apache.xbean.spring  level= WARN / \n     logger name= org.mitre  level= INFO / \n\n     root level= INFO \n         appender-ref ref= STDERR-WARN  / \n         appender-ref ref= SAMPLE-COMPONENT-DETECTION / \n     /root  /configuration", 
            "title": "Logging"
        }, 
        {
            "location": "/Packaging-and-Registering-a-Component/", 
            "text": "NOTICE:\n This software (or technical data) was produced for the U.S. Government under contract, and is subject to the Rights in Data-General Clause 52.227-14, Alt. IV (DEC 2007). Copyright 2017 The MITRE Corporation. All Rights Reserved.\n\n\n\n\nComponent Descriptor Overview\n\n\nIn order to registered within OpenMPF, each component must provide a JavaScript Object Notation (JSON) descriptor file which provides contextual information about the component.\n\n\nThis file must be named \"descriptor.json\".\n\n\nFor an example, please see: \nHello World JSON Descriptor\n\n\nComponent Descriptor Data Elements\n\n\nContained within the JSON file should be the following elements:\n\n\ncomponentName\n\n\nRequired.\n\n\nContains the component\u2019s name. Should follow CamelCaseFormat.\n\n\nExample:\n\n\"componentName\" : \"SampleComponent\"\n\n\ncomponentVersion\n\n\nRequired.\n\n\nContains the component\u2019s version. Does not need to match the \ncomponentAPIVersion\n.\n\n\nExample:\n\n\"componentVersion\" : \"0.1.0\"\n\n\ncomponentAPIVersion\n\n\nRequired.\n\n\nContains the version of the MPF Component API that the component was built with.\n\n\nExample:\n\n\"middlewareVersion\" :  \"0.9.0\"\n\n\nsourceLanguage\n\n\nRequired.\n\n\nContains the language the component is coded in. Should be either \u201cjava\u201d or \u201cc++\u201d.\n\n\nExample:\n\n\"sourceLanguage\" : \"c++\"\n\n\npathName\n\n\nRequired.\n\n\nFor C++ components, this contains the name of the Component Executable that will be used to run the component. Generally, this is \namq_detection_component\n (where \u201camq\u201d stands for ActiveMQ) for all C++ detection components.\n\n\nFor Java components, this contains the path to the jar which contains the component implementation.\n\n\nExample (C++):\n\n\"pathName\" : \"amq_detection_component\"\n\n\nExample (Java):\n\n\"pathName\" : \"sample-component-0.1.0.jar\"\n\n\nlaunchArgs\n\n\nC++: Required.\nJava: Required; can be empty.\n\n\nHolds the command line arguments in string format that should be passed to the Component Executable when it is launched.\n\n\nFor C++ detection components the one and only argument should be the full path to the Component Logic shared object library. The library must reside in a location that is accessible by each of the machines on which the component is deployed.\n\n\nFor Java detection components, this can be empty.\n\n\nExample (C++):\n\n\"launchArgs\" : [\"${MPF_HOME}/plugins/SampleComponent/lib/libsampleComponent.so\"]\n\n\nExample (Java):\n\n\"launchArgs\" : []\n\n\nenvironmentVariables\n\n\nRequired; can be empty.\n\n\nDefines a collection of environment variables that will be set when executing the MPF Component Executable.\n\n\nContains the following sub-fields:\n\n\n\n\n\n\nname:\n\n  Name of the environment variable.\n\n\n\n\n\n\nvalue:\n\n  Value of the environment variable.\n  Note that value can be a list of values separated by \u201c:\u201d.\n\n\n\n\n\n\nsep:\n\n  The \nsep\n field (short for \u201cseparator\u201d) should be set to \u201cnull\u201d or \u201c:\u201d. When set to \u201cnull,\u201d the content of the environment variable specified by \nname\n is the content of \nvalue\n; for an existing variable, its former value will be replaced, otherwise, a new variable will be created and assigned this value. When set to \u201c:\u201d any prior value of the environment variable is retained and the content of \nvalue\n is simply appended to the end after a \u201c:\u201d character.\n\n\n\n\n\n\n\n\nIMPORTANT\n: For C++ components, the LD_LIBRARY_PATH needs to be set in order for the Component Executable to load the component\u2019s shared object library as well as any dependent libraries installed with the component. The usual form of the LD_LIBRARY_PATH variable should be \n${MPF_HOME}/plugins/\ncomponentName\n/lib/\n. Additional directories can be appended after a \u201c:\u201d delimiter.\n\n\n\n\nExample:\n\n\nenvironmentVariables\n: [\n    {\n      \nname\n: \nLD_LIBRARY_PATH\n,\n      \nvalue\n: \n${MPF_HOME}/plugins/SampleComponent/lib\n,\n      \nsep\n: \n:\n\n    }\n  ]\n\n\n\n\nalgorithm\n\n\nRequired.\n\n\nSpecifies information about the component\u2019s algorithm.\n\n\nContains the following sub-fields:\n* \nname:\n\n  Required. Contains the algorithm\u2019s name. Should be unique and all CAPS.\n\n\n\n\n\n\ndescription:\n\n  Required. Contains a brief description of the algorithm.\n\n\n\n\n\n\ndetectionType:\n\n  Required. Defines the type of entity associated with the algorithm. For example: \nCLASS\n, \nFACE\n, \nMOTION\n, \nPERSON\n, \nSPEECH\n, or \nTEXT\n.\n\n\n\n\n\n\nactionType:\n\n  Required. Defines the type of processing that the algorithm performs. Must be set to \nDETECTION\n.\n\n\n\n\n\n\nrequiresCollection:\n\n  Required, can be empty. Contains the state(s) that must be produced by previous algorithms in the pipeline.\n  \nThis value should be empty \nunless\n the component depends on the results of another algorithm.\n\n\n\n\n\n\nprovidesCollection:\n\n\n\n\n\n\nContains the following sub-fields:\n  * \nstates:\n Required. Contains the state(s) that the algorithm provides.\n  Should contain the following values:\n    * \nDETECTION\n\n    * \nDETECTION_TYPE\n, where \nTYPE\n is the \nalgorithm.detectionType\n\n    * \nDETECTION_TYPE_ALGORITHM\n, where \nTYPE\n is the value of \nalgorithm.detectionType\n and \nALGORITHM\n is the value of \nalgorithm.name\n\n    Example:\n      \n\"states\": [\n        \"DETECTION\",\n        \"DETECTION_FACE\",\n        \"DETECTION_FACE_SAMPLECOMPONENT\"]\n\n\n\n\nproperties:\n\n  Required; can be empty. Declares a list of the configurable properties that the algorithm exposes.\n  Contains the following sub-fields:\n\n\nname:\n\n  Required.\n\n\ntype:\n\n  Required.\n  \nBOOLEAN\n, \nFLOAT\n, \nDOUBLE\n, \nINT\n, \nLONG\n, or \nSTRING\n.\n\n\ndefaultValue:\n\n  Required.\n  Must be provided in order to create a default action associated with the algorithm, where an action is a specific instance of an algorithm configured with a set of property values.\n\n\ndescription:\n\n  Required.\n  Description of the property. By convention, the default value for a property should be described in its description text.\n\n\n\n\n\n\n\n\nactions\n\n\nOptional.\n\n\nActions are used in the development of pipelines. Provides a list of custom actions that will be added during component registration.\n\n\n\n\nNOTE:\n For convenience, a default action will be created upon component registration if this element is not provided in the descriptor file.\n\n\n\n\nContains the following sub-fields:\n\n\n\n\n\n\nname:\n\n  Required. Contains the action\u2019s name. Must be unique among all actions, including those that already exist on the system and those specified in this descriptor.\n\n\n\n\n\n\ndescription:\n\n  Required. Contains a brief description of the action.\n\n\n\n\n\n\nalgorithm:\n\n  Required. Contains the name of the algorithm for this action. The algorithm must either already exist on the system or be defined in this descriptor.\n\n\n\n\n\n\nproperties:\n\n  Optional. List of properties that will be passed to the algorithm. Each property has an associated name and value sub-field, which are both required. Name must be one of the properties specified in the algorithm definition for this action.\n\n\n\n\n\n\nExample:\n\n\nactions\n: [\n  {\n    \nname\n: \nSAMPLE COMPONENT FACE DETECTION ACTION\n,\n    \ndescription\n: \nExecutes the sample component face detection algorithm using the default parameters.\n,\n    \nalgorithm\n: \nSAMPLECOMPONENT\n,\n    \nproperties\n: []\n  }\n]\n\n\n\n\ntasks\n\n\nOptional.\n\n\nA list of custom tasks that will be added during component registration.\n\n\n\n\nNOTE:\n For convenience, a default task will be created upon component registration if this element is not provided in the descriptor file.\n\n\n\n\nContains the following sub-fields:\n\n\n\n\n\n\nname:\n\n  Required. Contains the task's name. Must be unique among all tasks, including those that already exist on the system and those specified in this descriptor.\n\n\n\n\n\n\ndescription:\n\n  Required. Contains a brief description of the task.\n\n\n\n\n\n\nactions:\n\n  Required. Minimum length is 1. Contains the names of the actions that this task uses. Actions must either already exist on the system or be defined in this descriptor.\n\n\n\n\n\n\nExample:\n\n\ntasks\n: [\n  {\n    \nname\n: \nSAMPLE COMPONENT FACE DETECTION TASK\n,\n    \ndescription\n: \nPerforms sample component face detection.\n,\n    \nactions\n: [\n      \nSAMPLE COMPONENT FACE DETECTION ACTION\n\n    ]\n  }\n]\n\n\n\n\npipelines\n\n\nOptional.\n\n\nA list of custom pipelines that will be added during component registration.\n\n\n\n\nNOTE:\n For convenience, a default pipeline will be created upon component registration if this element is not provided in the descriptor file.\n\n\n\n\nContains the following sub-fields:\n\n\n\n\n\n\nname:\n\n  Required. Contains the pipeline's name. Must be unique among all pipelines, including those that already exist on the system and those specified in this descriptor.\n\n\n\n\n\n\ndescription:\n\n  Required. Contains a brief description of the pipeline.\n\n\n\n\n\n\ntasks:\n\n  Required. Minimum length is 1. Contains the names of the tasks that this pipeline uses. Tasks must either already exist on the system or be defined in this descriptor.\n\n\n\n\n\n\nExample:\n\n\npipelines\n: [\n  {\n    \nname\n: \nSAMPLE COMPONENT FACE DETECTION PIPELINE\n,\n    \ndescription\n: \nPerforms sample component face detection.\n,\n    \ntasks\n: [\n      \nSAMPLE COMPONENT FACE DETECTION TASK\n\n    ]\n  }\n]\n\n\n\n\nPackaging a Component\n\n\nOnce the descriptor file is complete, the next step is to compile your component source code, and finally, create a .tar.gz package containing the descriptor file, component library, and all other necessary files.\n\n\nThe package should contain a top-level directory with a unique name that will (hopefully) not conflict with existing component packages that have already been developed. The top-level directory name should be the same as the \ncomponentName\n.\n\n\nWithin the top-level directory there must be a directory named \u201cdescriptor\u201d with the descriptor JSON file in it. The name of the file must be \u201cdescriptor.json\u201d.\n\n\nExample:\n\n\n//sample-component-0.1.0-tar.gz contents\nSampleComponent/\n  config/\n  descriptor/\n    descriptor.json\n  lib/\n\n\n\n\nInstalling and registering a component\n\n\nThe Component Registration web page, located in the Admin section of the MPF web user interface, can be used to upload and register the component.\n\n\nDrag and drop the .tar.gz file containing the component onto the dropzone area of that page. The component will automatically be uploaded and registered.\n\n\nUpon successful registration, the component will be available for deployment onto MPF nodes via the Node Configuration web page and \n/rest/nodes/config\n end point.\n\n\nIf the descriptor contains custom actions, tasks, or pipelines, then they will be automatically added to the system upon registration.\n\n\n\n\nNOTE:\n If the descriptor does not contain custom actions, tasks, or pipelines, then a default action, task, and pipeline will be generated and added to the system.\n\n\nThe default action will use the component\u2019s algorithm with its default property value settings.\nThe default task will use the default action.\nThe default pipeline will use the default task. This will only be generated if the algorithm does not specify any \nrequiresCollection\n states.\n\n\n\n\nUnregistering a component\n\n\nA component can be unregistered by using the remove button on the Component Registration page.\n\n\nDuring unregistration, all services, algorithms, actions, tasks, and pipelines associated with the component are deleted. Additionally, all actions, tasks, and pipelines that depend on these elements are removed.", 
            "title": "Packaging and Registering a Component"
        }, 
        {
            "location": "/Packaging-and-Registering-a-Component/#component-descriptor-overview", 
            "text": "In order to registered within OpenMPF, each component must provide a JavaScript Object Notation (JSON) descriptor file which provides contextual information about the component.  This file must be named \"descriptor.json\".  For an example, please see:  Hello World JSON Descriptor", 
            "title": "Component Descriptor Overview"
        }, 
        {
            "location": "/Packaging-and-Registering-a-Component/#component-descriptor-data-elements", 
            "text": "Contained within the JSON file should be the following elements:", 
            "title": "Component Descriptor Data Elements"
        }, 
        {
            "location": "/Packaging-and-Registering-a-Component/#componentname", 
            "text": "Required.  Contains the component\u2019s name. Should follow CamelCaseFormat.  Example: \"componentName\" : \"SampleComponent\"", 
            "title": "componentName"
        }, 
        {
            "location": "/Packaging-and-Registering-a-Component/#componentversion", 
            "text": "Required.  Contains the component\u2019s version. Does not need to match the  componentAPIVersion .  Example: \"componentVersion\" : \"0.1.0\"", 
            "title": "componentVersion"
        }, 
        {
            "location": "/Packaging-and-Registering-a-Component/#componentapiversion", 
            "text": "Required.  Contains the version of the MPF Component API that the component was built with.  Example: \"middlewareVersion\" :  \"0.9.0\"", 
            "title": "componentAPIVersion"
        }, 
        {
            "location": "/Packaging-and-Registering-a-Component/#sourcelanguage", 
            "text": "Required.  Contains the language the component is coded in. Should be either \u201cjava\u201d or \u201cc++\u201d.  Example: \"sourceLanguage\" : \"c++\"", 
            "title": "sourceLanguage"
        }, 
        {
            "location": "/Packaging-and-Registering-a-Component/#pathname", 
            "text": "Required.  For C++ components, this contains the name of the Component Executable that will be used to run the component. Generally, this is  amq_detection_component  (where \u201camq\u201d stands for ActiveMQ) for all C++ detection components.  For Java components, this contains the path to the jar which contains the component implementation.  Example (C++): \"pathName\" : \"amq_detection_component\"  Example (Java): \"pathName\" : \"sample-component-0.1.0.jar\"", 
            "title": "pathName"
        }, 
        {
            "location": "/Packaging-and-Registering-a-Component/#launchargs", 
            "text": "C++: Required.\nJava: Required; can be empty.  Holds the command line arguments in string format that should be passed to the Component Executable when it is launched.  For C++ detection components the one and only argument should be the full path to the Component Logic shared object library. The library must reside in a location that is accessible by each of the machines on which the component is deployed.  For Java detection components, this can be empty.  Example (C++): \"launchArgs\" : [\"${MPF_HOME}/plugins/SampleComponent/lib/libsampleComponent.so\"]  Example (Java): \"launchArgs\" : []", 
            "title": "launchArgs"
        }, 
        {
            "location": "/Packaging-and-Registering-a-Component/#environmentvariables", 
            "text": "Required; can be empty.  Defines a collection of environment variables that will be set when executing the MPF Component Executable.  Contains the following sub-fields:    name: \n  Name of the environment variable.    value: \n  Value of the environment variable.\n  Note that value can be a list of values separated by \u201c:\u201d.    sep: \n  The  sep  field (short for \u201cseparator\u201d) should be set to \u201cnull\u201d or \u201c:\u201d. When set to \u201cnull,\u201d the content of the environment variable specified by  name  is the content of  value ; for an existing variable, its former value will be replaced, otherwise, a new variable will be created and assigned this value. When set to \u201c:\u201d any prior value of the environment variable is retained and the content of  value  is simply appended to the end after a \u201c:\u201d character.     IMPORTANT : For C++ components, the LD_LIBRARY_PATH needs to be set in order for the Component Executable to load the component\u2019s shared object library as well as any dependent libraries installed with the component. The usual form of the LD_LIBRARY_PATH variable should be  ${MPF_HOME}/plugins/ componentName /lib/ . Additional directories can be appended after a \u201c:\u201d delimiter.   Example:  environmentVariables : [\n    {\n       name :  LD_LIBRARY_PATH ,\n       value :  ${MPF_HOME}/plugins/SampleComponent/lib ,\n       sep :  : \n    }\n  ]", 
            "title": "environmentVariables"
        }, 
        {
            "location": "/Packaging-and-Registering-a-Component/#algorithm", 
            "text": "Required.  Specifies information about the component\u2019s algorithm.  Contains the following sub-fields:\n*  name: \n  Required. Contains the algorithm\u2019s name. Should be unique and all CAPS.    description: \n  Required. Contains a brief description of the algorithm.    detectionType: \n  Required. Defines the type of entity associated with the algorithm. For example:  CLASS ,  FACE ,  MOTION ,  PERSON ,  SPEECH , or  TEXT .    actionType: \n  Required. Defines the type of processing that the algorithm performs. Must be set to  DETECTION .    requiresCollection: \n  Required, can be empty. Contains the state(s) that must be produced by previous algorithms in the pipeline.\n   This value should be empty  unless  the component depends on the results of another algorithm.    providesCollection:    Contains the following sub-fields:\n  *  states:  Required. Contains the state(s) that the algorithm provides.\n  Should contain the following values:\n    *  DETECTION \n    *  DETECTION_TYPE , where  TYPE  is the  algorithm.detectionType \n    *  DETECTION_TYPE_ALGORITHM , where  TYPE  is the value of  algorithm.detectionType  and  ALGORITHM  is the value of  algorithm.name \n    Example:\n       \"states\": [\n        \"DETECTION\",\n        \"DETECTION_FACE\",\n        \"DETECTION_FACE_SAMPLECOMPONENT\"]   properties: \n  Required; can be empty. Declares a list of the configurable properties that the algorithm exposes.\n  Contains the following sub-fields:  name: \n  Required.  type: \n  Required.\n   BOOLEAN ,  FLOAT ,  DOUBLE ,  INT ,  LONG , or  STRING .  defaultValue: \n  Required.\n  Must be provided in order to create a default action associated with the algorithm, where an action is a specific instance of an algorithm configured with a set of property values.  description: \n  Required.\n  Description of the property. By convention, the default value for a property should be described in its description text.", 
            "title": "algorithm"
        }, 
        {
            "location": "/Packaging-and-Registering-a-Component/#actions", 
            "text": "Optional.  Actions are used in the development of pipelines. Provides a list of custom actions that will be added during component registration.   NOTE:  For convenience, a default action will be created upon component registration if this element is not provided in the descriptor file.   Contains the following sub-fields:    name: \n  Required. Contains the action\u2019s name. Must be unique among all actions, including those that already exist on the system and those specified in this descriptor.    description: \n  Required. Contains a brief description of the action.    algorithm: \n  Required. Contains the name of the algorithm for this action. The algorithm must either already exist on the system or be defined in this descriptor.    properties: \n  Optional. List of properties that will be passed to the algorithm. Each property has an associated name and value sub-field, which are both required. Name must be one of the properties specified in the algorithm definition for this action.    Example:  actions : [\n  {\n     name :  SAMPLE COMPONENT FACE DETECTION ACTION ,\n     description :  Executes the sample component face detection algorithm using the default parameters. ,\n     algorithm :  SAMPLECOMPONENT ,\n     properties : []\n  }\n]", 
            "title": "actions"
        }, 
        {
            "location": "/Packaging-and-Registering-a-Component/#tasks", 
            "text": "Optional.  A list of custom tasks that will be added during component registration.   NOTE:  For convenience, a default task will be created upon component registration if this element is not provided in the descriptor file.   Contains the following sub-fields:    name: \n  Required. Contains the task's name. Must be unique among all tasks, including those that already exist on the system and those specified in this descriptor.    description: \n  Required. Contains a brief description of the task.    actions: \n  Required. Minimum length is 1. Contains the names of the actions that this task uses. Actions must either already exist on the system or be defined in this descriptor.    Example:  tasks : [\n  {\n     name :  SAMPLE COMPONENT FACE DETECTION TASK ,\n     description :  Performs sample component face detection. ,\n     actions : [\n       SAMPLE COMPONENT FACE DETECTION ACTION \n    ]\n  }\n]", 
            "title": "tasks"
        }, 
        {
            "location": "/Packaging-and-Registering-a-Component/#pipelines", 
            "text": "Optional.  A list of custom pipelines that will be added during component registration.   NOTE:  For convenience, a default pipeline will be created upon component registration if this element is not provided in the descriptor file.   Contains the following sub-fields:    name: \n  Required. Contains the pipeline's name. Must be unique among all pipelines, including those that already exist on the system and those specified in this descriptor.    description: \n  Required. Contains a brief description of the pipeline.    tasks: \n  Required. Minimum length is 1. Contains the names of the tasks that this pipeline uses. Tasks must either already exist on the system or be defined in this descriptor.    Example:  pipelines : [\n  {\n     name :  SAMPLE COMPONENT FACE DETECTION PIPELINE ,\n     description :  Performs sample component face detection. ,\n     tasks : [\n       SAMPLE COMPONENT FACE DETECTION TASK \n    ]\n  }\n]", 
            "title": "pipelines"
        }, 
        {
            "location": "/Packaging-and-Registering-a-Component/#packaging-a-component", 
            "text": "Once the descriptor file is complete, the next step is to compile your component source code, and finally, create a .tar.gz package containing the descriptor file, component library, and all other necessary files.  The package should contain a top-level directory with a unique name that will (hopefully) not conflict with existing component packages that have already been developed. The top-level directory name should be the same as the  componentName .  Within the top-level directory there must be a directory named \u201cdescriptor\u201d with the descriptor JSON file in it. The name of the file must be \u201cdescriptor.json\u201d.  Example:  //sample-component-0.1.0-tar.gz contents\nSampleComponent/\n  config/\n  descriptor/\n    descriptor.json\n  lib/", 
            "title": "Packaging a Component"
        }, 
        {
            "location": "/Packaging-and-Registering-a-Component/#installing-and-registering-a-component", 
            "text": "The Component Registration web page, located in the Admin section of the MPF web user interface, can be used to upload and register the component.  Drag and drop the .tar.gz file containing the component onto the dropzone area of that page. The component will automatically be uploaded and registered.  Upon successful registration, the component will be available for deployment onto MPF nodes via the Node Configuration web page and  /rest/nodes/config  end point.  If the descriptor contains custom actions, tasks, or pipelines, then they will be automatically added to the system upon registration.   NOTE:  If the descriptor does not contain custom actions, tasks, or pipelines, then a default action, task, and pipeline will be generated and added to the system.  The default action will use the component\u2019s algorithm with its default property value settings.\nThe default task will use the default action.\nThe default pipeline will use the default task. This will only be generated if the algorithm does not specify any  requiresCollection  states.", 
            "title": "Installing and registering a component"
        }, 
        {
            "location": "/Packaging-and-Registering-a-Component/#unregistering-a-component", 
            "text": "A component can be unregistered by using the remove button on the Component Registration page.  During unregistration, all services, algorithms, actions, tasks, and pipelines associated with the component are deleted. Additionally, all actions, tasks, and pipelines that depend on these elements are removed.", 
            "title": "Unregistering a component"
        }, 
        {
            "location": "/REST-API/", 
            "text": "The OpenMPF REST API is provided by Swagger and is available within the OpenMPF Workflow Manager server.\n\n\nA static version of the API is available here:\n\nOpenMPF REST API", 
            "title": "REST API"
        }, 
        {
            "location": "/Workflow-Manager/", 
            "text": "NOTICE:\n This software (or technical data) was produced for the U.S. Government under contract, and is subject to the Rights in Data-General Clause 52.227-14, Alt. IV (DEC 2007). Copyright 2017 The MITRE Corporation. All Rights Reserved.\n\n\n\n\nWorkflow Manager Overview\n\n\nThe OpenMPF consists of three major pieces:\n\n\n\n\nA collection of \nComponents\n which process media\n\n\nA \nNode Manager\n, which launches and monitors running components in the system\n\n\nThe \nWorkflow Manager\n (WFM), which allows for the creation of jobs and manages the flow through active components\n\n\n\n\nThese pieces are supported by a number of modules which provide shared functionality, as shown in the dependency diagram below:\n\n\n\n\nThere are three general functional areas in the WFM:\n\n\n\n\nThe \nControllers\n are the primary entry point, accepting REST requests which trigger actions by the WFM\n\n\nThe \nWFM Services\n, which handle administrative tasks such as pipeline creation, node management, and log retrieval\n\n\nJob Management\n, which uses Camel routes to pass a job through the levels of processing\n\n\n\n\nThere are two different databases used by the WFM:\n\n\n\n\nA \nMySQL database\n stores persistent data about jobs. This data includes:\n\n\nThe job ID\n\n\nThe start and stop time of the job\n\n\nThe exit status of the job\n\n\nJob priority\n\n\nJob input/outputs\n\n\n\n\n\n\nA \nRedis database\n for storing transient data that is only necessary while the job is being run. Some of this data is used to generate the output which will later be persisted in long-term storage, and some is a temporary duplication of previously persisted data in active memory to avoid race conditions. This data includes:\n\n\nJob and media properties\n\n\nDetections\n\n\nTracks\n\n\nPipeline/Track/Action/Algorithm data duplicated from the system at job start time\n\n\nREST Callback information\n\n\n\n\n\n\n\n\nThe diagram below shows the functional areas of the WFM, the databases used by the WFM, and communication with components:\n\n\n\n\nControllers / Services\n\n\nThe controllers are all located  \nhere\n.\n\n\nEvery controller provides a collection of REST endpoints which allow access either to a WFM service or to the job management flow. Only the JobController enters the job management flow.\n\n\nBasic Controllers\n\n\nThe table below lists the basic controllers:\n\n\n\n\n\n\n\n\nController Class\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nAdminLogsController\n\n\nAccesses the log content via REST\n\n\n\n\n\n\nAdminErrorsController\n\n\nGets admin errors\n\n\n\n\n\n\nAdminPropertySettingsController\n\n\nAllows access and modification of system properties\n\n\n\n\n\n\nAdminStatisticsController\n\n\nGenerates job statistics\n\n\n\n\n\n\nAtmosphereController\n\n\nUses Atmosphere to manage server-side push\n\n\n\n\n\n\nBootoutController\n\n\nHandles bootouts when a second session is opened by the same user\n\n\n\n\n\n\nHomeController\n\n\nManages index page and version information\n\n\n\n\n\n\nLoginController\n\n\nManages login/logout and authentication\n\n\n\n\n\n\nServerMediaController\n\n\nEnables selection and deselection of files at a directory level\n\n\n\n\n\n\nSystemMessageController\n\n\nManages system level messages, such as notifying users that a server restart is needed\n\n\n\n\n\n\nTimeoutController\n\n\nManages session timeouts\n\n\n\n\n\n\n\n\nThe following sections list the rest of the constrollers in more detail.\n\n\nAdminComponentRegistrationController\n\n\nComponents in the OpenMPF are uploaded as tar.gz packages containing all necessary component data. For more information on components, read \nOpenMPF Component API Overview\n.\n\n\nThe \nAdminComponentRegistrationController\n provides endpoints which allow:\n\n\n\n\nAccess to current component information\n\n\nUpload of new components\n\n\nRegistration and unregistration of components (note that components must be registered to be included in pipelines)\n\n\nDeletion of components\n\n\n\n\nJobController\n\n\nA job is a specific pipeline's tasks and actions applied to a set of media. The \nJobController\n allows:\n\n\n\n\nAccess to information about jobs in the system\n\n\nCreation of new jobs\n\n\nCancellation of existing jobs\n\n\nDownload of job output data\n\n\nResubmission of jobs (regardless of initial job status)\n\n\n\n\nMarkupController\n\n\nMarkup files are copies of the initial media input to a job with detections visually highlighted in the image or video frames. The \nMarkupController\n can provide lists of available Markup files, or it can download a specific file.\n\n\nMediaController\n\n\nThe \nMediaController\n enables upload and organization of media files within the WFM. It provides endpoints for media upload, and also for creation of folders to organize media files in the system. At this time, there are no endpoints which allow for deletion or reorganization of media files, since all media is shared by all users.\n\n\nNodeController\n\n\nThe OpenMPF uses multiple hosts to enable scalability and parallel processing. The \nNodeController\n provides access to host information and allows components to be deployed on nodes. One or more components can be installed on a node. The same component can be installed on multiple nodes. Each node can manage one or more services for each component.\n\n\nThe \nNodeController\n provides host information and component service deployment status. It also provides an endpoint to deploy a service on a node and an endpoint to stop a service.\n\n\nFor more information on nodes, please read the \nNode Configuration and Status\n section in the Admin Guide.\n\n\nPipelineController\n\n\nThe \nPipeline Controller\n allows for the creation, retrieval, and deletion of pipelines or any of their constituent parts. While actions, tasks, and pipelines may not be directly modified, they may be deleted and recreated.\n\n\nFor more information on pipelines, please read the \nCreate Custom Pipelines\n section in the User Guide.\n\n\nJob Management\n\n\nThe request to create a job begins at the \nJobController\n. From there, it is transformed and passed through multiple flows on its way to the component services. These services process the job then return information to the WFM for JSON output generation.\n\n\nThe diagram below shows the sequence of WFM operations. It does not show the ActiveMQ messages that are sent to and from the component services.\n\n\n\n\nAfter the job request is validated and saved to the MySQL database, it passes through multiple Apache Camel routes, each of which checks that the job is still valid (with no fatal errors or cancellations), and then invokes a series of transformations and processors specific to the route.\n\n\nApache Camel\n is an open-source framework that allows developers to build rule-based routing engines. Within the OpenMPF, we use a \nJava DSL\n to define the routes. Every route functions independently, and communication between the routes is URI-based. The OpenMPF uses ActiveMQ to handle its message traffic.\n\n\nJob Creator Route\n\n\nThe \nJob Creator Route\n sets up the job in memory. By the time this route is invoked, the job has been persisted in the permanent MySQL database. The Job Creator Route sets up the transient objects in Redis that will be used for aggregating job data across pipeline stages. By the time this route exits, the particulars of the pipeline and job request will be stored in Redis.\n\n\nMedia Retriever Route\n\n\nThe \nMedia Retriever Route\n ensures that the media for the job can all be found and accessed. It stores the media information on the server to ensure continued access.\n\n\nMedia Inspection Route\n\n\nThe \nMedia Inspection Route\n splits a single job with multiple media inputs into separate messages, one for each piece of media. For each piece of media, it collects metadata about the media, including MIME type, duration, frame rate, and orientation data.\n\n\nJob Router Route\n\n\nThe \nJob Router Route\n uses the pipeline's flow to create the messages that are sent to the components. For large media files, it splits the job into smaller sub-jobs by logically breaking the media up into segments. Each segment has a start point and an end point (specified as a frame or time offset).\n\n\nThis route compiles properties for the job, media, and algorithm, and determines the next component that needs to be invoked. It then marshals the job into a serialized protobuf format and sends the message off to the component for processing.\n\n\nUnlike Job Creation, Media Retriever, and Media Inspection, this route may be invoked multiple times as future routes redirect back to the Job Router so that the job can be processed by the next component in the pipeline.\n\n\nDetection Response Route\n\n\nThe \nDetection Response Route\n is the re-entry point to the WFM. It unmarshals the protobuf responses, converts them into the Track and Detection objects used within the WFM, and stores them in the Redis database. Over multiple calls to the DetectionResponseProcessor, all data is eventually added into the transient Job object.\n\n\nStage Response Aggregation Route\n\n\nThe \nStage Response Aggregation Route\n is the exit point for the response processors. It waits until all the sub-job responses have been retrieved for the current stage of the pipeline, then it invokes the Job Router Route to see if any additional processing needs to be done.\n\n\nMarkup Response Route\n\n\nMarkup files are copies of the initial media input to a job with any detections visually highlighted in the image. The \nMarkup Response Route\n persists the locations of these markup files in the MySQL database.\n\n\nJob Completed Route\n\n\nOnce the Job is completed, the \nJob Completed Route\n converts the aggregated transient data structure into a JSON output format. It then clears out any lingering transient objects, updates the final job status, and sends the output object to anything that needs to access it.", 
            "title": "Workflow Manager"
        }, 
        {
            "location": "/Workflow-Manager/#workflow-manager-overview", 
            "text": "The OpenMPF consists of three major pieces:   A collection of  Components  which process media  A  Node Manager , which launches and monitors running components in the system  The  Workflow Manager  (WFM), which allows for the creation of jobs and manages the flow through active components   These pieces are supported by a number of modules which provide shared functionality, as shown in the dependency diagram below:   There are three general functional areas in the WFM:   The  Controllers  are the primary entry point, accepting REST requests which trigger actions by the WFM  The  WFM Services , which handle administrative tasks such as pipeline creation, node management, and log retrieval  Job Management , which uses Camel routes to pass a job through the levels of processing   There are two different databases used by the WFM:   A  MySQL database  stores persistent data about jobs. This data includes:  The job ID  The start and stop time of the job  The exit status of the job  Job priority  Job input/outputs    A  Redis database  for storing transient data that is only necessary while the job is being run. Some of this data is used to generate the output which will later be persisted in long-term storage, and some is a temporary duplication of previously persisted data in active memory to avoid race conditions. This data includes:  Job and media properties  Detections  Tracks  Pipeline/Track/Action/Algorithm data duplicated from the system at job start time  REST Callback information     The diagram below shows the functional areas of the WFM, the databases used by the WFM, and communication with components:", 
            "title": "Workflow Manager Overview"
        }, 
        {
            "location": "/Workflow-Manager/#controllers-services", 
            "text": "The controllers are all located   here .  Every controller provides a collection of REST endpoints which allow access either to a WFM service or to the job management flow. Only the JobController enters the job management flow.", 
            "title": "Controllers / Services"
        }, 
        {
            "location": "/Workflow-Manager/#basic-controllers", 
            "text": "The table below lists the basic controllers:     Controller Class  Description      AdminLogsController  Accesses the log content via REST    AdminErrorsController  Gets admin errors    AdminPropertySettingsController  Allows access and modification of system properties    AdminStatisticsController  Generates job statistics    AtmosphereController  Uses Atmosphere to manage server-side push    BootoutController  Handles bootouts when a second session is opened by the same user    HomeController  Manages index page and version information    LoginController  Manages login/logout and authentication    ServerMediaController  Enables selection and deselection of files at a directory level    SystemMessageController  Manages system level messages, such as notifying users that a server restart is needed    TimeoutController  Manages session timeouts     The following sections list the rest of the constrollers in more detail.", 
            "title": "Basic Controllers"
        }, 
        {
            "location": "/Workflow-Manager/#admincomponentregistrationcontroller", 
            "text": "Components in the OpenMPF are uploaded as tar.gz packages containing all necessary component data. For more information on components, read  OpenMPF Component API Overview .  The  AdminComponentRegistrationController  provides endpoints which allow:   Access to current component information  Upload of new components  Registration and unregistration of components (note that components must be registered to be included in pipelines)  Deletion of components", 
            "title": "AdminComponentRegistrationController"
        }, 
        {
            "location": "/Workflow-Manager/#jobcontroller", 
            "text": "A job is a specific pipeline's tasks and actions applied to a set of media. The  JobController  allows:   Access to information about jobs in the system  Creation of new jobs  Cancellation of existing jobs  Download of job output data  Resubmission of jobs (regardless of initial job status)", 
            "title": "JobController"
        }, 
        {
            "location": "/Workflow-Manager/#markupcontroller", 
            "text": "Markup files are copies of the initial media input to a job with detections visually highlighted in the image or video frames. The  MarkupController  can provide lists of available Markup files, or it can download a specific file.", 
            "title": "MarkupController"
        }, 
        {
            "location": "/Workflow-Manager/#mediacontroller", 
            "text": "The  MediaController  enables upload and organization of media files within the WFM. It provides endpoints for media upload, and also for creation of folders to organize media files in the system. At this time, there are no endpoints which allow for deletion or reorganization of media files, since all media is shared by all users.", 
            "title": "MediaController"
        }, 
        {
            "location": "/Workflow-Manager/#nodecontroller", 
            "text": "The OpenMPF uses multiple hosts to enable scalability and parallel processing. The  NodeController  provides access to host information and allows components to be deployed on nodes. One or more components can be installed on a node. The same component can be installed on multiple nodes. Each node can manage one or more services for each component.  The  NodeController  provides host information and component service deployment status. It also provides an endpoint to deploy a service on a node and an endpoint to stop a service.  For more information on nodes, please read the  Node Configuration and Status  section in the Admin Guide.", 
            "title": "NodeController"
        }, 
        {
            "location": "/Workflow-Manager/#pipelinecontroller", 
            "text": "The  Pipeline Controller  allows for the creation, retrieval, and deletion of pipelines or any of their constituent parts. While actions, tasks, and pipelines may not be directly modified, they may be deleted and recreated.  For more information on pipelines, please read the  Create Custom Pipelines  section in the User Guide.", 
            "title": "PipelineController"
        }, 
        {
            "location": "/Workflow-Manager/#job-management", 
            "text": "The request to create a job begins at the  JobController . From there, it is transformed and passed through multiple flows on its way to the component services. These services process the job then return information to the WFM for JSON output generation.  The diagram below shows the sequence of WFM operations. It does not show the ActiveMQ messages that are sent to and from the component services.   After the job request is validated and saved to the MySQL database, it passes through multiple Apache Camel routes, each of which checks that the job is still valid (with no fatal errors or cancellations), and then invokes a series of transformations and processors specific to the route.  Apache Camel  is an open-source framework that allows developers to build rule-based routing engines. Within the OpenMPF, we use a  Java DSL  to define the routes. Every route functions independently, and communication between the routes is URI-based. The OpenMPF uses ActiveMQ to handle its message traffic.", 
            "title": "Job Management"
        }, 
        {
            "location": "/Workflow-Manager/#job-creator-route", 
            "text": "The  Job Creator Route  sets up the job in memory. By the time this route is invoked, the job has been persisted in the permanent MySQL database. The Job Creator Route sets up the transient objects in Redis that will be used for aggregating job data across pipeline stages. By the time this route exits, the particulars of the pipeline and job request will be stored in Redis.", 
            "title": "Job Creator Route"
        }, 
        {
            "location": "/Workflow-Manager/#media-retriever-route", 
            "text": "The  Media Retriever Route  ensures that the media for the job can all be found and accessed. It stores the media information on the server to ensure continued access.", 
            "title": "Media Retriever Route"
        }, 
        {
            "location": "/Workflow-Manager/#media-inspection-route", 
            "text": "The  Media Inspection Route  splits a single job with multiple media inputs into separate messages, one for each piece of media. For each piece of media, it collects metadata about the media, including MIME type, duration, frame rate, and orientation data.", 
            "title": "Media Inspection Route"
        }, 
        {
            "location": "/Workflow-Manager/#job-router-route", 
            "text": "The  Job Router Route  uses the pipeline's flow to create the messages that are sent to the components. For large media files, it splits the job into smaller sub-jobs by logically breaking the media up into segments. Each segment has a start point and an end point (specified as a frame or time offset).  This route compiles properties for the job, media, and algorithm, and determines the next component that needs to be invoked. It then marshals the job into a serialized protobuf format and sends the message off to the component for processing.  Unlike Job Creation, Media Retriever, and Media Inspection, this route may be invoked multiple times as future routes redirect back to the Job Router so that the job can be processed by the next component in the pipeline.", 
            "title": "Job Router Route"
        }, 
        {
            "location": "/Workflow-Manager/#detection-response-route", 
            "text": "The  Detection Response Route  is the re-entry point to the WFM. It unmarshals the protobuf responses, converts them into the Track and Detection objects used within the WFM, and stores them in the Redis database. Over multiple calls to the DetectionResponseProcessor, all data is eventually added into the transient Job object.", 
            "title": "Detection Response Route"
        }, 
        {
            "location": "/Workflow-Manager/#stage-response-aggregation-route", 
            "text": "The  Stage Response Aggregation Route  is the exit point for the response processors. It waits until all the sub-job responses have been retrieved for the current stage of the pipeline, then it invokes the Job Router Route to see if any additional processing needs to be done.", 
            "title": "Stage Response Aggregation Route"
        }, 
        {
            "location": "/Workflow-Manager/#markup-response-route", 
            "text": "Markup files are copies of the initial media input to a job with any detections visually highlighted in the image. The  Markup Response Route  persists the locations of these markup files in the MySQL database.", 
            "title": "Markup Response Route"
        }, 
        {
            "location": "/Workflow-Manager/#job-completed-route", 
            "text": "Once the Job is completed, the  Job Completed Route  converts the aggregated transient data structure into a JSON output format. It then clears out any lingering transient objects, updates the final job status, and sends the output object to anything that needs to access it.", 
            "title": "Job Completed Route"
        }
    ]
}